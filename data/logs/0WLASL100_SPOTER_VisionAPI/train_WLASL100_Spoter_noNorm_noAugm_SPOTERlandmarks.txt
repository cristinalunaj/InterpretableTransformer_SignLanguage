python3 train.py --experiment_name test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks --epochs 350 --lr 0.001 --training_set_path ../spoter/data/WLASL100_train_25fps.csv --validation_set_path ../spoter/data/WLASL100_val_25fps.csv --testing_set_path ../spoter/data/WLASL100_test_25fps.csv --hidden_dim 108 --n_heads 9
Using model originalSpoter
Starting test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks...


... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_0.pth
[1] TRAIN  loss: 4.7092915713869745 acc: 0.0076282940360610264
[1] VALIDATION  acc: 0.032640949554896145

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_1.pth
[2] TRAIN  loss: 4.487707798259433 acc: 0.024965325936199722
[2] VALIDATION  acc: 0.020771513353115726

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_1.pth
[3] TRAIN  loss: 4.327544201263608 acc: 0.027045769764216365
[3] VALIDATION  acc: 0.050445103857566766

[4] TRAIN  loss: 4.2383347607518695 acc: 0.03259361997226075
[4] VALIDATION  acc: 0.03857566765578635

[5] TRAIN  loss: 4.139899967199556 acc: 0.04507628294036061
[5] VALIDATION  acc: 0.04451038575667656

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_1.pth
[6] TRAIN  loss: 4.048298253431069 acc: 0.054785020804438284
[6] VALIDATION  acc: 0.06824925816023739

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_1.pth
[7] TRAIN  loss: 3.9525786246406884 acc: 0.06934812760055478
[7] VALIDATION  acc: 0.0712166172106825

[8] TRAIN  loss: 3.878157783315185 acc: 0.07420249653259361
[8] VALIDATION  acc: 0.0712166172106825

[9] TRAIN  loss: 3.815152061382378 acc: 0.08044382801664356
[9] VALIDATION  acc: 0.05341246290801187

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_1.pth
[10] TRAIN  loss: 3.7456354876662425 acc: 0.07836338418862691
[10] VALIDATION  acc: 0.08902077151335312

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_1.pth
[11] TRAIN  loss: 3.6751354504557487 acc: 0.09500693481276005
[11] VALIDATION  acc: 0.10089020771513353

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_2.pth
[12] TRAIN  loss: 3.6026674598331425 acc: 0.1130374479889043
[12] VALIDATION  acc: 0.10089020771513353

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_2.pth
[13] TRAIN  loss: 3.5154940875327205 acc: 0.1289875173370319
[13] VALIDATION  acc: 0.11275964391691394

[14] TRAIN  loss: 3.46123471405569 acc: 0.1317614424410541
[14] VALIDATION  acc: 0.10089020771513353

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_2.pth
[15] TRAIN  loss: 3.3635148361800615 acc: 0.14840499306518723
[15] VALIDATION  acc: 0.14836795252225518

[16] TRAIN  loss: 3.2920556973237107 acc: 0.1664355062413315
[16] VALIDATION  acc: 0.11275964391691394

[17] TRAIN  loss: 3.211088127137553 acc: 0.18862690707350901
[17] VALIDATION  acc: 0.12759643916913946

[18] TRAIN  loss: 3.1349210056286414 acc: 0.1927877947295423
[18] VALIDATION  acc: 0.142433234421365

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_2.pth
[19] TRAIN  loss: 3.042123363145347 acc: 0.22468793342579751
[19] VALIDATION  acc: 0.1632047477744807

[20] TRAIN  loss: 2.9624863776601797 acc: 0.23647711511789182
[20] VALIDATION  acc: 0.14540059347181009

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_2.pth
[21] TRAIN  loss: 2.895439533354009 acc: 0.2420249653259362
[21] VALIDATION  acc: 0.20474777448071216

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_3.pth
[22] TRAIN  loss: 2.8142005882010217 acc: 0.268377253814147
[22] VALIDATION  acc: 0.2433234421364985

[23] TRAIN  loss: 2.734572836806308 acc: 0.28918169209431344
[23] VALIDATION  acc: 0.2195845697329377

[24] TRAIN  loss: 2.653080714083743 acc: 0.30235783633841884
[24] VALIDATION  acc: 0.1543026706231454

[25] TRAIN  loss: 2.5727058090217896 acc: 0.33703190013869627
[25] VALIDATION  acc: 0.19881305637982197

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_3.pth
[26] TRAIN  loss: 2.5195996492439763 acc: 0.3141470180305132
[26] VALIDATION  acc: 0.27002967359050445

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_3.pth
[27] TRAIN  loss: 2.4317910979487696 acc: 0.34812760055478503
[27] VALIDATION  acc: 0.2789317507418398

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_3.pth
[28] TRAIN  loss: 2.3755115846200394 acc: 0.35159500693481277
[28] VALIDATION  acc: 0.29673590504451036

[29] TRAIN  loss: 2.299509126098824 acc: 0.38072122052704577
[29] VALIDATION  acc: 0.2166172106824926

[30] TRAIN  loss: 2.2250522874223377 acc: 0.4119278779472954
[30] VALIDATION  acc: 0.24629080118694363

[31] TRAIN  loss: 2.1467872860992583 acc: 0.427877947295423
[31] VALIDATION  acc: 0.29080118694362017

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_4.pth
[32] TRAIN  loss: 2.1376148447208365 acc: 0.4077669902912621
[32] VALIDATION  acc: 0.2997032640949555

[33] TRAIN  loss: 2.0203845506112885 acc: 0.45423023578363386
[33] VALIDATION  acc: 0.2997032640949555

[34] TRAIN  loss: 1.9699605454828968 acc: 0.4563106796116505
[34] VALIDATION  acc: 0.28486646884273

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_4.pth
[35] TRAIN  loss: 1.9273173707109796 acc: 0.46601941747572817
[35] VALIDATION  acc: 0.3115727002967359

[36] TRAIN  loss: 1.852784380678413 acc: 0.4868238557558946
[36] VALIDATION  acc: 0.26409495548961426

[37] TRAIN  loss: 1.8025342606152723 acc: 0.5083217753120666
[37] VALIDATION  acc: 0.3026706231454006

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_4.pth
[38] TRAIN  loss: 1.7389635153052794 acc: 0.5353675450762829
[38] VALIDATION  acc: 0.32344213649851633

[39] TRAIN  loss: 1.6786086156669793 acc: 0.5416088765603329
[39] VALIDATION  acc: 0.2997032640949555

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_4.pth
[40] TRAIN  loss: 1.6392462682573128 acc: 0.5540915395284327
[40] VALIDATION  acc: 0.34421364985163205

[41] TRAIN  loss: 1.5702267919709691 acc: 0.5554785020804438
[41] VALIDATION  acc: 0.3086053412462908

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_5.pth
[42] TRAIN  loss: 1.5674587504256223 acc: 0.5464632454923717
[42] VALIDATION  acc: 0.24629080118694363

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_5.pth
[43] TRAIN  loss: 1.4886061543981117 acc: 0.5818307905686546
[43] VALIDATION  acc: 0.3353115727002967

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_5.pth
[44] TRAIN  loss: 1.4524977043420904 acc: 0.5915395284327323
[44] VALIDATION  acc: 0.35311572700296734

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_5.pth
[45] TRAIN  loss: 1.3742469225425 acc: 0.6123439667128987
[45] VALIDATION  acc: 0.37388724035608306

[46] TRAIN  loss: 1.4006538150435501 acc: 0.59500693481276
[46] VALIDATION  acc: 0.3115727002967359

[47] TRAIN  loss: 1.3051688095526293 acc: 0.6255201109570042
[47] VALIDATION  acc: 0.36795252225519287

[48] TRAIN  loss: 1.3071655420155035 acc: 0.6206657420249653
[48] VALIDATION  acc: 0.3353115727002967

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_5.pth
[49] TRAIN  loss: 1.267229074269311 acc: 0.6338418862690708
[49] VALIDATION  acc: 0.3887240356083086

[50] TRAIN  loss: 1.1555317440335013 acc: 0.6629680998613038
[50] VALIDATION  acc: 0.34718100890207715

[51] TRAIN  loss: 1.1425596274869534 acc: 0.6816920943134536
[51] VALIDATION  acc: 0.36795252225519287

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_6.pth
[52] TRAIN  loss: 1.0746888749320163 acc: 0.6858529819694869
[52] VALIDATION  acc: 0.3887240356083086

[53] TRAIN  loss: 1.0722511085163642 acc: 0.6900138696255201
[53] VALIDATION  acc: 0.35311572700296734

[54] TRAIN  loss: 1.0595795116277513 acc: 0.694868238557559
[54] VALIDATION  acc: 0.37091988130563797

[55] TRAIN  loss: 0.9854219126868373 acc: 0.717753120665742
[55] VALIDATION  acc: 0.3827893175074184

[56] TRAIN  loss: 0.9722793739974943 acc: 0.7219140083217753
[56] VALIDATION  acc: 0.3649851632047478

[57] TRAIN  loss: 0.9706337712514608 acc: 0.7038834951456311
[57] VALIDATION  acc: 0.3768545994065282

[58] TRAIN  loss: 0.8780310209088116 acc: 0.7538141470180305
[58] VALIDATION  acc: 0.3798219584569733

[59] TRAIN  loss: 0.8753692675859831 acc: 0.7454923717059639
[59] VALIDATION  acc: 0.37388724035608306

[60] TRAIN  loss: 0.86061369038517 acc: 0.7579750346740638
[60] VALIDATION  acc: 0.3887240356083086

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_6.pth
[61] TRAIN  loss: 0.8526331615778289 acc: 0.7524271844660194
[61] VALIDATION  acc: 0.39762611275964393

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_7.pth
[62] TRAIN  loss: 0.8880999109613478 acc: 0.7399445214979196
[62] VALIDATION  acc: 0.3590504451038576

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_7.pth
[63] TRAIN  loss: 0.8330107525289098 acc: 0.7538141470180305
[63] VALIDATION  acc: 0.39762611275964393

[64] TRAIN  loss: 0.7634170202862267 acc: 0.7780859916782247
[64] VALIDATION  acc: 0.3768545994065282

[65] TRAIN  loss: 0.7582317398663742 acc: 0.7704576976421637
[65] VALIDATION  acc: 0.34421364985163205

[66] TRAIN  loss: 0.6840753381772822 acc: 0.805131761442441
[66] VALIDATION  acc: 0.3916913946587537

[67] TRAIN  loss: 0.6626166847913756 acc: 0.8148404993065187
[67] VALIDATION  acc: 0.35311572700296734

[68] TRAIN  loss: 0.6156283816076936 acc: 0.8300970873786407
[68] VALIDATION  acc: 0.37388724035608306

[69] TRAIN  loss: 0.6120365069266512 acc: 0.826629680998613
[69] VALIDATION  acc: 0.39762611275964393

[70] TRAIN  loss: 0.6686362779108147 acc: 0.8023578363384188
[70] VALIDATION  acc: 0.36795252225519287

[71] TRAIN  loss: 0.6596139201681432 acc: 0.8099861303744799
[71] VALIDATION  acc: 0.34124629080118696

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_8.pth
[72] TRAIN  loss: 0.5129728305451288 acc: 0.8654646324549237
[72] VALIDATION  acc: 0.37388724035608306

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_8.pth
[73] TRAIN  loss: 0.5521253890755273 acc: 0.848127600554785
[73] VALIDATION  acc: 0.3916913946587537

[74] TRAIN  loss: 0.6013773975463715 acc: 0.8349514563106796
[74] VALIDATION  acc: 0.36795252225519287

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_8.pth
[75] TRAIN  loss: 0.5194478183537502 acc: 0.8592233009708737
[75] VALIDATION  acc: 0.39762611275964393

[76] TRAIN  loss: 0.5639262034417448 acc: 0.8425797503467406
[76] VALIDATION  acc: 0.37388724035608306

[77] TRAIN  loss: 0.5737198387084874 acc: 0.8307905686546463
[77] VALIDATION  acc: 0.3293768545994065

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_8.pth
[78] TRAIN  loss: 0.4693288464858371 acc: 0.871012482662968
[78] VALIDATION  acc: 0.4035608308605341

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_8.pth
[79] TRAIN  loss: 0.4427398617840992 acc: 0.8723994452149791
[79] VALIDATION  acc: 0.4065281899109792

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_8.pth
[80] TRAIN  loss: 0.4537206228905462 acc: 0.8800277392510403
[80] VALIDATION  acc: 0.42136498516320475

[81] TRAIN  loss: 0.3902259950056845 acc: 0.8945908460471568
[81] VALIDATION  acc: 0.3916913946587537

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_9.pth
[82] TRAIN  loss: 0.4337438982161409 acc: 0.8751733703190014
[82] VALIDATION  acc: 0.3916913946587537

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_9.pth
[83] TRAIN  loss: 0.4871018867635432 acc: 0.8703190013869625
[83] VALIDATION  acc: 0.39465875370919884

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_9.pth
[84] TRAIN  loss: 0.43844407448344397 acc: 0.8821081830790569
[84] VALIDATION  acc: 0.4065281899109792

[85] TRAIN  loss: 0.3684103362469407 acc: 0.9008321775312067
[85] VALIDATION  acc: 0.3620178041543027

[86] TRAIN  loss: 0.4302401734612418 acc: 0.8723994452149791
[86] VALIDATION  acc: 0.34718100890207715

[87] TRAIN  loss: 0.5750064305598162 acc: 0.8356449375866851
[87] VALIDATION  acc: 0.37091988130563797

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_9.pth
[88] TRAIN  loss: 0.5065935849648143 acc: 0.8543689320388349
[88] VALIDATION  acc: 0.42729970326409494

[89] TRAIN  loss: 0.6355053380211807 acc: 0.8044382801664355
[89] VALIDATION  acc: 0.39465875370919884

[90] TRAIN  loss: 0.32981843908746716 acc: 0.9112343966712899
[90] VALIDATION  acc: 0.37388724035608306

[91] TRAIN  loss: 0.36154677772217325 acc: 0.9147018030513177
[91] VALIDATION  acc: 0.4124629080118694

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_10.pth
[92] TRAIN  loss: 0.27141559397274256 acc: 0.9278779472954231
[92] VALIDATION  acc: 0.34718100890207715

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_10.pth
[93] TRAIN  loss: 0.3391158584264012 acc: 0.9105409153952844
[93] VALIDATION  acc: 0.4035608308605341

[94] TRAIN  loss: 0.24414959113842913 acc: 0.9368932038834952
[94] VALIDATION  acc: 0.37388724035608306

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_10.pth
[95] TRAIN  loss: 0.279806133936863 acc: 0.9292649098474342
[95] VALIDATION  acc: 0.42136498516320475

[96] TRAIN  loss: 0.3135663438654985 acc: 0.9160887656033287
[96] VALIDATION  acc: 0.3916913946587537

[97] TRAIN  loss: 0.40785838167876426 acc: 0.8793342579750347
[97] VALIDATION  acc: 0.35311572700296734

[98] TRAIN  loss: 0.5057746143800099 acc: 0.8592233009708737
[98] VALIDATION  acc: 0.3857566765578635

[99] TRAIN  loss: 0.43647116077161263 acc: 0.871012482662968
[99] VALIDATION  acc: 0.3620178041543027

[100] TRAIN  loss: 0.4555243090027297 acc: 0.8730929264909847
[100] VALIDATION  acc: 0.4035608308605341

[101] TRAIN  loss: 0.26880573939187963 acc: 0.9257975034674064
[101] VALIDATION  acc: 0.3798219584569733

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_11.pth
[102] TRAIN  loss: 0.27028020488013654 acc: 0.926490984743412
[102] VALIDATION  acc: 0.39762611275964393

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_11.pth
[103] TRAIN  loss: 0.19393420060304972 acc: 0.9486823855755895
[103] VALIDATION  acc: 0.43026706231454004

[104] TRAIN  loss: 0.19120638996934913 acc: 0.9528432732316228
[104] VALIDATION  acc: 0.4094955489614243

[105] TRAIN  loss: 0.18918673364879016 acc: 0.9507628294036061
[105] VALIDATION  acc: 0.41543026706231456

[106] TRAIN  loss: 0.2607414542828398 acc: 0.9271844660194175
[106] VALIDATION  acc: 0.4094955489614243

[107] TRAIN  loss: 0.2942942935717607 acc: 0.9112343966712899
[107] VALIDATION  acc: 0.33827893175074186

[108] TRAIN  loss: 0.41374637801745295 acc: 0.8751733703190014
[108] VALIDATION  acc: 0.39762611275964393

[109] TRAIN  loss: 0.21777319063343872 acc: 0.9382801664355063
[109] VALIDATION  acc: 0.3827893175074184

[110] TRAIN  loss: 0.22986444178403545 acc: 0.9389736477115118
[110] VALIDATION  acc: 0.3857566765578635

[111] TRAIN  loss: 0.18244572717805982 acc: 0.9528432732316228
[111] VALIDATION  acc: 0.42136498516320475

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_12.pth
[112] TRAIN  loss: 0.15292355358171042 acc: 0.9576976421636616
[112] VALIDATION  acc: 0.35311572700296734

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_12.pth
[113] TRAIN  loss: 0.2116531239728333 acc: 0.9396671289875174
[113] VALIDATION  acc: 0.3857566765578635

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_12.pth
[114] TRAIN  loss: 0.3630952544107876 acc: 0.9015256588072122
[114] VALIDATION  acc: 0.40059347181008903

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_12.pth
[115] TRAIN  loss: 0.239640822379069 acc: 0.9355062413314841
[115] VALIDATION  acc: 0.41543026706231456

[116] TRAIN  loss: 0.16835064443619713 acc: 0.9549237170596394
[116] VALIDATION  acc: 0.3857566765578635

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_12.pth
[117] TRAIN  loss: 0.1439168068305377 acc: 0.957004160887656
[117] VALIDATION  acc: 0.4391691394658754

[118] TRAIN  loss: 0.29155765737740896 acc: 0.9147018030513177
[118] VALIDATION  acc: 0.41839762611275966

[119] TRAIN  loss: 0.20293592795072965 acc: 0.941747572815534
[119] VALIDATION  acc: 0.37388724035608306

[120] TRAIN  loss: 0.3198496302639303 acc: 0.9153952843273232
[120] VALIDATION  acc: 0.3293768545994065

[121] TRAIN  loss: 0.32405273990059996 acc: 0.9022191400832178
[121] VALIDATION  acc: 0.3857566765578635

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_13.pth
[122] TRAIN  loss: 0.273726187437677 acc: 0.9271844660194175
[122] VALIDATION  acc: 0.35014836795252224

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_13.pth
[123] TRAIN  loss: 0.31222216085160337 acc: 0.9140083217753121
[123] VALIDATION  acc: 0.42729970326409494

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_13.pth
[124] TRAIN  loss: 0.1551500642291026 acc: 0.9604715672676838
[124] VALIDATION  acc: 0.4362017804154303

[125] TRAIN  loss: 0.16528872409102008 acc: 0.9528432732316228
[125] VALIDATION  acc: 0.4332344213649852

[126] TRAIN  loss: 0.16477851929572282 acc: 0.9542302357836339
[126] VALIDATION  acc: 0.41543026706231456

[127] TRAIN  loss: 0.14327908035835932 acc: 0.9583911234396671
[127] VALIDATION  acc: 0.43026706231454004

[128] TRAIN  loss: 0.19028884034829116 acc: 0.9452149791955617
[128] VALIDATION  acc: 0.3649851632047478

[129] TRAIN  loss: 0.21380587056056444 acc: 0.9410540915395285
[129] VALIDATION  acc: 0.43026706231454004

[130] TRAIN  loss: 0.18764206974624617 acc: 0.9466019417475728
[130] VALIDATION  acc: 0.4124629080118694

[131] TRAIN  loss: 0.155999460028271 acc: 0.955617198335645
[131] VALIDATION  acc: 0.4094955489614243

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_14.pth
[132] TRAIN  loss: 0.13552597995817228 acc: 0.963245492371706
[132] VALIDATION  acc: 0.41839762611275966

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_14.pth
[133] TRAIN  loss: 0.13740866924231196 acc: 0.9583911234396671
[133] VALIDATION  acc: 0.43026706231454004

[134] TRAIN  loss: 0.1609388073748492 acc: 0.9535367545076283
[134] VALIDATION  acc: 0.43026706231454004

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_14.pth
[135] TRAIN  loss: 0.11964542595898502 acc: 0.963245492371706
[135] VALIDATION  acc: 0.4332344213649852

[136] TRAIN  loss: 0.1523574854847574 acc: 0.9521497919556172
[136] VALIDATION  acc: 0.4094955489614243

[137] TRAIN  loss: 0.23735352097856685 acc: 0.9278779472954231
[137] VALIDATION  acc: 0.4065281899109792

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_14.pth
[138] TRAIN  loss: 0.13851253527728494 acc: 0.9597780859916782
[138] VALIDATION  acc: 0.4391691394658754

[139] TRAIN  loss: 0.1336250677897861 acc: 0.9590846047156727
[139] VALIDATION  acc: 0.42729970326409494

[140] TRAIN  loss: 0.19530642347869545 acc: 0.9472954230235784
[140] VALIDATION  acc: 0.41543026706231456

[141] TRAIN  loss: 0.12733656726720033 acc: 0.9625520110957004
[141] VALIDATION  acc: 0.42136498516320475

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_15.pth
[142] TRAIN  loss: 0.1976007778445394 acc: 0.9382801664355063
[142] VALIDATION  acc: 0.3620178041543027

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_15.pth
[143] TRAIN  loss: 0.38931531490769244 acc: 0.8897364771151179
[143] VALIDATION  acc: 0.4124629080118694

[144] TRAIN  loss: 0.3460014179698232 acc: 0.897364771151179
[144] VALIDATION  acc: 0.3560830860534125

[145] TRAIN  loss: 0.21540562970071184 acc: 0.9424410540915396
[145] VALIDATION  acc: 0.3293768545994065

[146] TRAIN  loss: 0.22323670544589408 acc: 0.9313453536754508
[146] VALIDATION  acc: 0.3887240356083086

[147] TRAIN  loss: 0.41641297550831924 acc: 0.8793342579750347
[147] VALIDATION  acc: 0.37388724035608306

[148] TRAIN  loss: 0.18975506573837575 acc: 0.9424410540915396
[148] VALIDATION  acc: 0.4094955489614243

[149] TRAIN  loss: 0.16494603294633328 acc: 0.949375866851595
[149] VALIDATION  acc: 0.39762611275964393

[150] TRAIN  loss: 0.1915941307898807 acc: 0.9479889042995839
[150] VALIDATION  acc: 0.39762611275964393

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_15.pth
[151] TRAIN  loss: 0.16640672937099077 acc: 0.9521497919556172
[151] VALIDATION  acc: 0.42433234421364985

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_16.pth
[152] TRAIN  loss: 0.12468173217247606 acc: 0.9590846047156727
[152] VALIDATION  acc: 0.42433234421364985

[153] TRAIN  loss: 0.12017698034314853 acc: 0.9646324549237171
[153] VALIDATION  acc: 0.42136498516320475

[154] TRAIN  loss: 0.11067863118958374 acc: 0.9653259361997226
[154] VALIDATION  acc: 0.4124629080118694

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_16.pth
[155] TRAIN  loss: 0.11080383558826588 acc: 0.9625520110957004
[155] VALIDATION  acc: 0.4332344213649852

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_16.pth
[156] TRAIN  loss: 0.09859394767644594 acc: 0.9680998613037448
[156] VALIDATION  acc: 0.4421364985163205

[157] TRAIN  loss: 0.11045753358340636 acc: 0.9646324549237171
[157] VALIDATION  acc: 0.43026706231454004

[158] TRAIN  loss: 0.11461677634355921 acc: 0.9660194174757282
[158] VALIDATION  acc: 0.39762611275964393

[159] TRAIN  loss: 0.13102859438482425 acc: 0.9604715672676838
[159] VALIDATION  acc: 0.4035608308605341

[160] TRAIN  loss: 0.10879970350580352 acc: 0.9660194174757282
[160] VALIDATION  acc: 0.4035608308605341

[161] TRAIN  loss: 0.10859794992404644 acc: 0.9653259361997226
[161] VALIDATION  acc: 0.41543026706231456

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_17.pth
[162] TRAIN  loss: 0.11662709958824777 acc: 0.9611650485436893
[162] VALIDATION  acc: 0.43026706231454004

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_17.pth
[163] TRAIN  loss: 0.10819987017739562 acc: 0.963245492371706
[163] VALIDATION  acc: 0.4421364985163205

[164] TRAIN  loss: 0.0952451936278375 acc: 0.9694868238557559
[164] VALIDATION  acc: 0.42136498516320475

[165] TRAIN  loss: 0.09206723684639628 acc: 0.9694868238557559
[165] VALIDATION  acc: 0.4332344213649852

[166] TRAIN  loss: 0.10086059764167826 acc: 0.9660194174757282
[166] VALIDATION  acc: 0.42729970326409494

[167] TRAIN  loss: 0.0988223705304454 acc: 0.9660194174757282
[167] VALIDATION  acc: 0.42136498516320475

[168] TRAIN  loss: 0.09465182989763847 acc: 0.9680998613037448
[168] VALIDATION  acc: 0.43026706231454004

[169] TRAIN  loss: 0.09908787424400078 acc: 0.9667128987517337
[169] VALIDATION  acc: 0.42433234421364985

[170] TRAIN  loss: 0.10011964626535803 acc: 0.9660194174757282
[170] VALIDATION  acc: 0.4391691394658754

[171] TRAIN  loss: 0.0924004281707448 acc: 0.9680998613037448
[171] VALIDATION  acc: 0.4065281899109792

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_18.pth
[172] TRAIN  loss: 0.08838391786170917 acc: 0.9687933425797504
[172] VALIDATION  acc: 0.42136498516320475

[173] TRAIN  loss: 0.17247384575812463 acc: 0.9479889042995839
[173] VALIDATION  acc: 0.41839762611275966

[174] TRAIN  loss: 0.226455183067627 acc: 0.9313453536754508
[174] VALIDATION  acc: 0.3887240356083086

[175] TRAIN  loss: 0.13979842550150695 acc: 0.9597780859916782
[175] VALIDATION  acc: 0.41839762611275966

[176] TRAIN  loss: 0.5851781058207383 acc: 0.8314840499306518
[176] VALIDATION  acc: 0.3768545994065282

[177] TRAIN  loss: 0.4600645383986114 acc: 0.8619972260748959
[177] VALIDATION  acc: 0.3827893175074184

[178] TRAIN  loss: 0.22965987818028522 acc: 0.9361997226074896
[178] VALIDATION  acc: 0.4094955489614243

[179] TRAIN  loss: 0.16158323868544314 acc: 0.9563106796116505
[179] VALIDATION  acc: 0.41839762611275966

[180] TRAIN  loss: 0.12633394652118457 acc: 0.9604715672676838
[180] VALIDATION  acc: 0.4094955489614243

[181] TRAIN  loss: 0.2059047480247557 acc: 0.9348127600554785
[181] VALIDATION  acc: 0.3857566765578635

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_19.pth
[182] TRAIN  loss: 0.5156973736306801 acc: 0.8536754507628294
[182] VALIDATION  acc: 0.33827893175074186

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_19.pth
[183] TRAIN  loss: 0.28712047728165824 acc: 0.9195561719833565
[183] VALIDATION  acc: 0.3887240356083086

[184] TRAIN  loss: 0.1330491345323785 acc: 0.9625520110957004
[184] VALIDATION  acc: 0.36795252225519287

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_19.pth
[185] TRAIN  loss: 0.1415298479638174 acc: 0.9549237170596394
[185] VALIDATION  acc: 0.40059347181008903

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_19.pth
[186] TRAIN  loss: 0.16193348426261936 acc: 0.9535367545076283
[186] VALIDATION  acc: 0.4065281899109792

[187] TRAIN  loss: 0.1244117350360588 acc: 0.9604715672676838
[187] VALIDATION  acc: 0.3887240356083086

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_19.pth
[188] TRAIN  loss: 0.13866015497411044 acc: 0.9535367545076283
[188] VALIDATION  acc: 0.4124629080118694

[189] TRAIN  loss: 0.24882063922640946 acc: 0.9327323162274619
[189] VALIDATION  acc: 0.3887240356083086

[190] TRAIN  loss: 0.1894539794074579 acc: 0.941747572815534
[190] VALIDATION  acc: 0.3798219584569733

[191] TRAIN  loss: 0.2038633207411901 acc: 0.9389736477115118
[191] VALIDATION  acc: 0.40059347181008903

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_20.pth
[192] TRAIN  loss: 0.14271160572495878 acc: 0.9542302357836339
[192] VALIDATION  acc: 0.37388724035608306

[193] TRAIN  loss: 0.14552419771377134 acc: 0.9576976421636616
[193] VALIDATION  acc: 0.3620178041543027

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_20.pth
[194] TRAIN  loss: 0.11045811137298545 acc: 0.9660194174757282
[194] VALIDATION  acc: 0.3887240356083086

[195] TRAIN  loss: 0.1467583470146567 acc: 0.9618585298196949
[195] VALIDATION  acc: 0.37091988130563797

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_20.pth
[196] TRAIN  loss: 0.152453664922007 acc: 0.9542302357836339
[196] VALIDATION  acc: 0.41543026706231456

[197] TRAIN  loss: 0.08778671030901508 acc: 0.9694868238557559
[197] VALIDATION  acc: 0.4094955489614243

[198] TRAIN  loss: 0.09262961643648301 acc: 0.9701803051317615
[198] VALIDATION  acc: 0.3916913946587537

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_20.pth
[199] TRAIN  loss: 0.08448874273941157 acc: 0.9701803051317615
[199] VALIDATION  acc: 0.42729970326409494

[200] TRAIN  loss: 0.08595722150163111 acc: 0.970873786407767
[200] VALIDATION  acc: 0.4065281899109792

[201] TRAIN  loss: 0.0827574278673877 acc: 0.9722607489597781
[201] VALIDATION  acc: 0.42136498516320475

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_21.pth
[202] TRAIN  loss: 0.07609360056164498 acc: 0.970873786407767
[202] VALIDATION  acc: 0.4065281899109792

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_21.pth
[203] TRAIN  loss: 0.07698706868621925 acc: 0.9750346740638003
[203] VALIDATION  acc: 0.41543026706231456

[204] TRAIN  loss: 0.08890266401590988 acc: 0.9715672676837726
[204] VALIDATION  acc: 0.41543026706231456

[205] TRAIN  loss: 0.07258177962357776 acc: 0.9778085991678225
[205] VALIDATION  acc: 0.40059347181008903

[206] TRAIN  loss: 0.07537427407230089 acc: 0.9715672676837726
[206] VALIDATION  acc: 0.40059347181008903

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_21.pth
[207] TRAIN  loss: 0.09391787869503125 acc: 0.9715672676837726
[207] VALIDATION  acc: 0.42729970326409494

[208] TRAIN  loss: 0.0823856005718299 acc: 0.9694868238557559
[208] VALIDATION  acc: 0.42433234421364985

[209] TRAIN  loss: 0.08217771580517988 acc: 0.9701803051317615
[209] VALIDATION  acc: 0.42136498516320475

[210] TRAIN  loss: 0.07632731204509473 acc: 0.9757281553398058
[210] VALIDATION  acc: 0.4094955489614243

[211] TRAIN  loss: 0.11266329757488977 acc: 0.9653259361997226
[211] VALIDATION  acc: 0.4065281899109792

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_22.pth
[212] TRAIN  loss: 0.08579537224618175 acc: 0.9715672676837726
[212] VALIDATION  acc: 0.41839762611275966

[213] TRAIN  loss: 0.08590388931836675 acc: 0.9750346740638003
[213] VALIDATION  acc: 0.39762611275964393

[214] TRAIN  loss: 0.07422043004948295 acc: 0.9743411927877947
[214] VALIDATION  acc: 0.4094955489614243

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_22.pth
[215] TRAIN  loss: 0.10506210841287987 acc: 0.9674063800277393
[215] VALIDATION  acc: 0.42136498516320475

[216] TRAIN  loss: 0.2834905257419077 acc: 0.9167822468793343
[216] VALIDATION  acc: 0.3857566765578635

[217] TRAIN  loss: 0.5986786975660182 acc: 0.8002773925104022
[217] VALIDATION  acc: 0.3264094955489614

[218] TRAIN  loss: 0.248258749477802 acc: 0.9244105409153953
[218] VALIDATION  acc: 0.42136498516320475

[219] TRAIN  loss: 0.08485841226788687 acc: 0.9750346740638003
[219] VALIDATION  acc: 0.40059347181008903

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_22.pth
[220] TRAIN  loss: 0.09252908950311116 acc: 0.9722607489597781
[220] VALIDATION  acc: 0.4362017804154303

[221] TRAIN  loss: 0.08046812462759366 acc: 0.9729542302357836
[221] VALIDATION  acc: 0.4065281899109792

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_23.pth
[222] TRAIN  loss: 0.07958925759833742 acc: 0.9722607489597781
[222] VALIDATION  acc: 0.39465875370919884

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_23.pth
[223] TRAIN  loss: 0.08516259157556398 acc: 0.9715672676837726
[223] VALIDATION  acc: 0.4124629080118694

[224] TRAIN  loss: 0.07586958080848764 acc: 0.9771151178918169
[224] VALIDATION  acc: 0.4035608308605341

[225] TRAIN  loss: 0.08338740368697285 acc: 0.9750346740638003
[225] VALIDATION  acc: 0.4035608308605341

[226] TRAIN  loss: 0.1041144549510613 acc: 0.9653259361997226
[226] VALIDATION  acc: 0.39465875370919884

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_23.pth
[227] TRAIN  loss: 0.0826422784302042 acc: 0.9750346740638003
[227] VALIDATION  acc: 0.4332344213649852

[228] TRAIN  loss: 0.08591293165653259 acc: 0.9687933425797504
[228] VALIDATION  acc: 0.3916913946587537

[229] TRAIN  loss: 0.11538820121231627 acc: 0.9674063800277393
[229] VALIDATION  acc: 0.39762611275964393

[230] TRAIN  loss: 0.18410081663031522 acc: 0.941747572815534
[230] VALIDATION  acc: 0.37091988130563797

[231] TRAIN  loss: 0.2673378480733753 acc: 0.9216366158113731
[231] VALIDATION  acc: 0.3857566765578635

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_24.pth
[232] TRAIN  loss: 0.15044109572641173 acc: 0.9542302357836339
[232] VALIDATION  acc: 0.3768545994065282

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_24.pth
[233] TRAIN  loss: 0.22239589724978662 acc: 0.9361997226074896
[233] VALIDATION  acc: 0.3827893175074184

[234] TRAIN  loss: 0.13238282806887633 acc: 0.9604715672676838
[234] VALIDATION  acc: 0.3798219584569733

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_24.pth
[235] TRAIN  loss: 0.14078270460542902 acc: 0.9542302357836339
[235] VALIDATION  acc: 0.39465875370919884

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_24.pth
[236] TRAIN  loss: 0.08412099089165342 acc: 0.9736477115117892
[236] VALIDATION  acc: 0.4094955489614243

[237] TRAIN  loss: 0.14808982412139007 acc: 0.9576976421636616
[237] VALIDATION  acc: 0.39465875370919884

[238] TRAIN  loss: 0.40224150627679106 acc: 0.8793342579750347
[238] VALIDATION  acc: 0.31750741839762614

[239] TRAIN  loss: 0.27676561607121625 acc: 0.9153952843273232
[239] VALIDATION  acc: 0.3620178041543027

[240] TRAIN  loss: 0.14793827980855453 acc: 0.9535367545076283
[240] VALIDATION  acc: 0.3857566765578635

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_24.pth
[241] TRAIN  loss: 0.07068530945040687 acc: 0.9764216366158114
[241] VALIDATION  acc: 0.4124629080118694

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_25.pth
[242] TRAIN  loss: 0.0752767175033395 acc: 0.9722607489597781
[242] VALIDATION  acc: 0.39762611275964393

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_25.pth
[243] TRAIN  loss: 0.08161073385502968 acc: 0.9764216366158114
[243] VALIDATION  acc: 0.41839762611275966

[244] TRAIN  loss: 0.0761590798125293 acc: 0.9750346740638003
[244] VALIDATION  acc: 0.41543026706231456

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_25.pth
[245] TRAIN  loss: 0.06328983108346335 acc: 0.9791955617198336
[245] VALIDATION  acc: 0.42729970326409494

[246] TRAIN  loss: 0.07288074067785118 acc: 0.9764216366158114
[246] VALIDATION  acc: 0.3916913946587537

[247] TRAIN  loss: 0.07849429675978035 acc: 0.9722607489597781
[247] VALIDATION  acc: 0.41839762611275966

[248] TRAIN  loss: 0.06056082843350448 acc: 0.9771151178918169
[248] VALIDATION  acc: 0.40059347181008903

[249] TRAIN  loss: 0.08975865178455553 acc: 0.9674063800277393
[249] VALIDATION  acc: 0.4124629080118694

[250] TRAIN  loss: 0.11007905304745155 acc: 0.9618585298196949
[250] VALIDATION  acc: 0.35311572700296734

[251] TRAIN  loss: 0.10201047257098617 acc: 0.9680998613037448
[251] VALIDATION  acc: 0.42136498516320475

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_26.pth
[252] TRAIN  loss: 0.06888646711824382 acc: 0.9750346740638003
[252] VALIDATION  acc: 0.40059347181008903

[253] TRAIN  loss: 0.2235106955587713 acc: 0.9389736477115118
[253] VALIDATION  acc: 0.37388724035608306

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_26.pth
[254] TRAIN  loss: 0.10635539560755758 acc: 0.9715672676837726
[254] VALIDATION  acc: 0.4065281899109792

[255] TRAIN  loss: 0.09335823373529897 acc: 0.9694868238557559
[255] VALIDATION  acc: 0.40059347181008903

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_26.pth
[256] TRAIN  loss: 0.15687572816285905 acc: 0.9597780859916782
[256] VALIDATION  acc: 0.41543026706231456

[257] TRAIN  loss: 0.10035544328483778 acc: 0.9701803051317615
[257] VALIDATION  acc: 0.4094955489614243

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_26.pth
[258] TRAIN  loss: 0.08133111170624518 acc: 0.9701803051317615
[258] VALIDATION  acc: 0.42136498516320475

[259] TRAIN  loss: 0.07606312749008849 acc: 0.9729542302357836
[259] VALIDATION  acc: 0.40059347181008903

[260] TRAIN  loss: 0.0676651454919143 acc: 0.9743411927877947
[260] VALIDATION  acc: 0.4065281899109792

[261] TRAIN  loss: 0.10031856366365953 acc: 0.9694868238557559
[261] VALIDATION  acc: 0.39465875370919884

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_27.pth
[262] TRAIN  loss: 0.07676610993264846 acc: 0.9743411927877947
[262] VALIDATION  acc: 0.40059347181008903

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_27.pth
[263] TRAIN  loss: 0.06792799374835212 acc: 0.9778085991678225
[263] VALIDATION  acc: 0.4332344213649852

[264] TRAIN  loss: 0.069612099221856 acc: 0.9743411927877947
[264] VALIDATION  acc: 0.4094955489614243

[265] TRAIN  loss: 0.06882666676230326 acc: 0.9757281553398058
[265] VALIDATION  acc: 0.4124629080118694

[266] TRAIN  loss: 0.07331660387675666 acc: 0.9750346740638003
[266] VALIDATION  acc: 0.3887240356083086

[267] TRAIN  loss: 0.060536909732142256 acc: 0.9805825242718447
[267] VALIDATION  acc: 0.41543026706231456

[268] TRAIN  loss: 0.06623737009393761 acc: 0.9750346740638003
[268] VALIDATION  acc: 0.41839762611275966

[269] TRAIN  loss: 0.06944010524821048 acc: 0.9722607489597781
[269] VALIDATION  acc: 0.4035608308605341

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_27.pth
[270] TRAIN  loss: 0.06518083935195884 acc: 0.9771151178918169
[270] VALIDATION  acc: 0.4362017804154303

[271] TRAIN  loss: 0.06159519843200749 acc: 0.9778085991678225
[271] VALIDATION  acc: 0.39762611275964393

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_28.pth
[272] TRAIN  loss: 0.05980544826447191 acc: 0.9771151178918169
[272] VALIDATION  acc: 0.43026706231454004

[273] TRAIN  loss: 0.07147947988079634 acc: 0.9743411927877947
[273] VALIDATION  acc: 0.42433234421364985

[274] TRAIN  loss: 0.06410226605023704 acc: 0.9757281553398058
[274] VALIDATION  acc: 0.41543026706231456

[275] TRAIN  loss: 0.05839662518615738 acc: 0.9771151178918169
[275] VALIDATION  acc: 0.41543026706231456

[276] TRAIN  loss: 0.051947325952653736 acc: 0.9812760055478502
[276] VALIDATION  acc: 0.42136498516320475

[277] TRAIN  loss: 0.05947570616356311 acc: 0.978502080443828
[277] VALIDATION  acc: 0.4094955489614243

[278] TRAIN  loss: 0.04987392513074196 acc: 0.9812760055478502
[278] VALIDATION  acc: 0.4065281899109792

[279] TRAIN  loss: 0.07026719352412561 acc: 0.9764216366158114
[279] VALIDATION  acc: 0.43026706231454004

[280] TRAIN  loss: 0.058794326883599625 acc: 0.9771151178918169
[280] VALIDATION  acc: 0.3827893175074184

[281] TRAIN  loss: 0.052145327969188866 acc: 0.978502080443828
[281] VALIDATION  acc: 0.40059347181008903

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_29.pth
[282] TRAIN  loss: 0.058003638680340634 acc: 0.9750346740638003
[282] VALIDATION  acc: 0.4065281899109792

[283] TRAIN  loss: 0.062167744789535004 acc: 0.9764216366158114
[283] VALIDATION  acc: 0.37388724035608306

[284] TRAIN  loss: 0.1105204447032568 acc: 0.9653259361997226
[284] VALIDATION  acc: 0.37388724035608306

[285] TRAIN  loss: 0.0840108473715994 acc: 0.9701803051317615
[285] VALIDATION  acc: 0.39762611275964393

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_29.pth
[286] TRAIN  loss: 0.06837312428252112 acc: 0.9764216366158114
[286] VALIDATION  acc: 0.41839762611275966

[287] TRAIN  loss: 0.05269985271560637 acc: 0.9778085991678225
[287] VALIDATION  acc: 0.3798219584569733

[288] TRAIN  loss: 0.05130101244680728 acc: 0.9812760055478502
[288] VALIDATION  acc: 0.4065281899109792

[289] TRAIN  loss: 0.0762005070234627 acc: 0.9722607489597781
[289] VALIDATION  acc: 0.37388724035608306

[290] TRAIN  loss: 0.0535265312447108 acc: 0.9778085991678225
[290] VALIDATION  acc: 0.4065281899109792

[291] TRAIN  loss: 0.07331119780150183 acc: 0.9750346740638003
[291] VALIDATION  acc: 0.35311572700296734

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_30.pth
[292] TRAIN  loss: 0.07518142063234137 acc: 0.9722607489597781
[292] VALIDATION  acc: 0.3857566765578635

[293] TRAIN  loss: 0.1264388929306804 acc: 0.9597780859916782
[293] VALIDATION  acc: 0.3798219584569733

[294] TRAIN  loss: 0.15804863582337583 acc: 0.9500693481276006
[294] VALIDATION  acc: 0.3827893175074184

[295] TRAIN  loss: 0.37143732322983447 acc: 0.8925104022191401
[295] VALIDATION  acc: 0.35311572700296734

[296] TRAIN  loss: 0.3206362108975757 acc: 0.9042995839112344
[296] VALIDATION  acc: 0.3649851632047478

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_30.pth
[297] TRAIN  loss: 0.07925641433106441 acc: 0.9736477115117892
[297] VALIDATION  acc: 0.3916913946587537

[298] TRAIN  loss: 0.06338508739245097 acc: 0.9743411927877947
[298] VALIDATION  acc: 0.3857566765578635

[299] TRAIN  loss: 0.07526656278309835 acc: 0.9743411927877947
[299] VALIDATION  acc: 0.3916913946587537

[300] TRAIN  loss: 0.3437160025316413 acc: 0.8938973647711512
[300] VALIDATION  acc: 0.3056379821958457

[301] TRAIN  loss: 0.4164446017973247 acc: 0.8744798890429958
[301] VALIDATION  acc: 0.3649851632047478

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_31.pth
[302] TRAIN  loss: 0.16273139489406296 acc: 0.9528432732316228
[302] VALIDATION  acc: 0.4094955489614243

[303] TRAIN  loss: 0.10373681943077645 acc: 0.9694868238557559
[303] VALIDATION  acc: 0.40059347181008903

[304] TRAIN  loss: 0.06540500460755444 acc: 0.9791955617198336
[304] VALIDATION  acc: 0.4094955489614243

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_31.pth
[305] TRAIN  loss: 0.06382235193611176 acc: 0.9791955617198336
[305] VALIDATION  acc: 0.4391691394658754

[306] TRAIN  loss: 0.06126367736351123 acc: 0.9791955617198336
[306] VALIDATION  acc: 0.42136498516320475

[307] TRAIN  loss: 0.09105478969010698 acc: 0.9736477115117892
[307] VALIDATION  acc: 0.39762611275964393

[308] TRAIN  loss: 0.060699212343788986 acc: 0.9771151178918169
[308] VALIDATION  acc: 0.4065281899109792

[309] TRAIN  loss: 0.07458301121540055 acc: 0.9791955617198336
[309] VALIDATION  acc: 0.43026706231454004

[310] TRAIN  loss: 0.06926026412793551 acc: 0.9743411927877947
[310] VALIDATION  acc: 0.4332344213649852

[311] TRAIN  loss: 0.06876619112336659 acc: 0.9750346740638003
[311] VALIDATION  acc: 0.4035608308605341

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_32.pth
[312] TRAIN  loss: 0.06141265420355493 acc: 0.978502080443828
[312] VALIDATION  acc: 0.4065281899109792

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_32.pth
[313] TRAIN  loss: 0.06929174746131236 acc: 0.9750346740638003
[313] VALIDATION  acc: 0.43026706231454004

[314] TRAIN  loss: 0.04343311608969043 acc: 0.9840499306518724
[314] VALIDATION  acc: 0.43026706231454004

[315] TRAIN  loss: 0.05340975867600141 acc: 0.9819694868238558
[315] VALIDATION  acc: 0.4065281899109792

[316] TRAIN  loss: 0.0480819721637867 acc: 0.9812760055478502
[316] VALIDATION  acc: 0.42433234421364985

[317] TRAIN  loss: 0.06264706392110525 acc: 0.9771151178918169
[317] VALIDATION  acc: 0.41543026706231456

[318] TRAIN  loss: 0.04720642669321309 acc: 0.9812760055478502
[318] VALIDATION  acc: 0.41543026706231456

[319] TRAIN  loss: 0.05804730844324512 acc: 0.9771151178918169
[319] VALIDATION  acc: 0.3916913946587537

[320] TRAIN  loss: 0.05733562123498406 acc: 0.9805825242718447
[320] VALIDATION  acc: 0.4094955489614243

[321] TRAIN  loss: 0.052470253304066655 acc: 0.9805825242718447
[321] VALIDATION  acc: 0.41543026706231456

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_33.pth
[322] TRAIN  loss: 0.051525207465021594 acc: 0.9778085991678225
[322] VALIDATION  acc: 0.4065281899109792

[323] TRAIN  loss: 0.07059271317387289 acc: 0.9743411927877947
[323] VALIDATION  acc: 0.4035608308605341

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_33.pth
[324] TRAIN  loss: 0.07661772307538196 acc: 0.9736477115117892
[324] VALIDATION  acc: 0.4124629080118694

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_33.pth
[325] TRAIN  loss: 0.08257244759722517 acc: 0.970873786407767
[325] VALIDATION  acc: 0.4391691394658754

[326] TRAIN  loss: 0.06824507354210081 acc: 0.9778085991678225
[326] VALIDATION  acc: 0.41839762611275966

[327] TRAIN  loss: 0.10801898398831616 acc: 0.9687933425797504
[327] VALIDATION  acc: 0.4124629080118694

[328] TRAIN  loss: 0.12410992806037127 acc: 0.9625520110957004
[328] VALIDATION  acc: 0.39465875370919884

[329] TRAIN  loss: 0.17266564776440238 acc: 0.9424410540915396
[329] VALIDATION  acc: 0.34124629080118696

[330] TRAIN  loss: 0.10630553431202541 acc: 0.9715672676837726
[330] VALIDATION  acc: 0.40059347181008903

[331] TRAIN  loss: 0.08960392021525398 acc: 0.9694868238557559
[331] VALIDATION  acc: 0.3916913946587537

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_34.pth
[332] TRAIN  loss: 0.17540061810051433 acc: 0.9459084604715673
[332] VALIDATION  acc: 0.3857566765578635

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_34.pth
[333] TRAIN  loss: 0.16296113069388732 acc: 0.9445214979195562
[333] VALIDATION  acc: 0.40059347181008903

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_34.pth
[334] TRAIN  loss: 0.06319204960250072 acc: 0.9791955617198336
[334] VALIDATION  acc: 0.4065281899109792

[335] TRAIN  loss: 0.060085450220481645 acc: 0.9771151178918169
[335] VALIDATION  acc: 0.39465875370919884

[336] TRAIN  loss: 0.044467419304628206 acc: 0.9826629680998613
[336] VALIDATION  acc: 0.4035608308605341

[337] TRAIN  loss: 0.04965632336754599 acc: 0.9812760055478502
[337] VALIDATION  acc: 0.39762611275964393

[338] TRAIN  loss: 0.05216196825272346 acc: 0.978502080443828
[338] VALIDATION  acc: 0.4065281899109792

[339] TRAIN  loss: 0.04274046076594603 acc: 0.9833564493758669
[339] VALIDATION  acc: 0.3916913946587537

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_34.pth
[340] TRAIN  loss: 0.044943523545039936 acc: 0.9868238557558946
[340] VALIDATION  acc: 0.4124629080118694

[341] TRAIN  loss: 0.05182593244106495 acc: 0.9812760055478502
[341] VALIDATION  acc: 0.4094955489614243

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_35.pth
[342] TRAIN  loss: 0.05607206072093803 acc: 0.9791955617198336
[342] VALIDATION  acc: 0.4124629080118694

[343] TRAIN  loss: 0.07265305386993529 acc: 0.9757281553398058
[343] VALIDATION  acc: 0.4094955489614243

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_v_35.pth
[344] TRAIN  loss: 0.05896157061017445 acc: 0.9764216366158114
[344] VALIDATION  acc: 0.42729970326409494

[345] TRAIN  loss: 0.05234480097513195 acc: 0.9812760055478502
[345] VALIDATION  acc: 0.41839762611275966

[346] TRAIN  loss: 0.14071580890953841 acc: 0.9528432732316228
[346] VALIDATION  acc: 0.3798219584569733

[347] TRAIN  loss: 0.16356815891984186 acc: 0.955617198335645
[347] VALIDATION  acc: 0.3798219584569733

[348] TRAIN  loss: 0.0425870652541741 acc: 0.986130374479889
[348] VALIDATION  acc: 0.40059347181008903

[349] TRAIN  loss: 0.05220702375193288 acc: 0.9791955617198336
[349] VALIDATION  acc: 0.4035608308605341

[350] TRAIN  loss: 0.04650443386872994 acc: 0.9833564493758669
[350] VALIDATION  acc: 0.40059347181008903


Testing checkpointed models starting...

Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0, 10: 0.0, 11: 0.0, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.0, 19: 0.0, 20: 0.0, 21: 0.0, 22: 0.0, 23: 0.0, 24: 0.0, 25: 0.0, 26: 0.0, 27: 0.0, 28: 0.0, 29: 0.0, 30: 0.0, 31: 0.0, 32: 0.0, 33: 0.0, 34: 0.0, 35: 0.0, 36: 0.0, 37: 0.0, 38: 0.0, 39: 0.0, 40: 0.0, 41: 0.0, 42: 0.0, 43: 0.0, 44: 0.0, 45: 0.0, 46: 0.0, 47: 0.0, 48: 0.0, 49: 0.0, 50: 0.0, 51: 0.0, 52: 0.0, 53: 0.0, 54: 0.0, 55: 0.0, 56: 0.0, 57: 0.0, 58: 0.0, 59: 0.0, 60: 0.0, 61: 0.0, 62: 0.0, 63: 0.0, 64: 0.0, 65: 0.0, 66: 0.0, 67: 0.0, 68: 0.0, 69: 0.0, 70: 0.0, 71: 0.0, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.0, 77: 0.0, 78: 0.0, 79: 0.0, 80: 0.0, 81: 0.0, 82: 0.0, 83: 0.0, 84: 0.0, 85: 0.0, 86: 0.0, 87: 0.0, 88: 0.0, 89: 0.0, 90: 0.0, 91: 0.0, 92: 0.0, 93: 0.0, 94: 0.0, 95: 0.0, 96: 0.0, 97: 0.0, 98: 0.0, 99: 0.0}

checkpoint_t_0  ->  0.023255813953488372
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0, 10: 0.0, 11: 0.0, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.0, 19: 0.0, 20: 0.0, 21: 0.0, 22: 0.0, 23: 0.0, 24: 0.0, 25: 0.0, 26: 0.0, 27: 0.0, 28: 0.0, 29: 0.0, 30: 0.0, 31: 0.0, 32: 0.0, 33: 0.0, 34: 0.0, 35: 0.0, 36: 0.0, 37: 0.0, 38: 0.0, 39: 0.0, 40: 0.0, 41: 0.0, 42: 0.0, 43: 0.0, 44: 0.0, 45: 0.0, 46: 0.0, 47: 0.0, 48: 0.0, 49: 0.0, 50: 0.0, 51: 0.0, 52: 0.0, 53: 0.0, 54: 0.0, 55: 0.0, 56: 0.0, 57: 0.0, 58: 0.0, 59: 0.0, 60: 0.0, 61: 0.0, 62: 0.0, 63: 0.0, 64: 0.0, 65: 0.0, 66: 0.0, 67: 0.0, 68: 0.0, 69: 0.0, 70: 0.0, 71: 0.0, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.0, 77: 0.0, 78: 0.0, 79: 0.0, 80: 0.0, 81: 0.0, 82: 0.0, 83: 0.0, 84: 0.0, 85: 0.0, 86: 0.0, 87: 0.0, 88: 0.0, 89: 0.0, 90: 0.0, 91: 0.0, 92: 0.0, 93: 0.0, 94: 0.0, 95: 0.0, 96: 0.0, 97: 0.0, 98: 0.0, 99: 0.0}

checkpoint_v_0  ->  0.023255813953488372
Label accuracies statistics:
{0: 0.5, 1: 0.25, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0, 10: 0.0, 11: 0.0, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.0, 19: 0.0, 20: 0.0, 21: 0.0, 22: 0.0, 23: 0.0, 24: 0.3333333333333333, 25: 0.0, 26: 0.3333333333333333, 27: 0.0, 28: 0.0, 29: 0.0, 30: 0.0, 31: 0.0, 32: 0.0, 33: 0.0, 34: 0.0, 35: 0.0, 36: 0.0, 37: 0.0, 38: 0.0, 39: 0.0, 40: 0.0, 41: 0.0, 42: 0.0, 43: 0.6666666666666666, 44: 0.0, 45: 0.0, 46: 0.0, 47: 0.0, 48: 0.0, 49: 1.0, 50: 0.0, 51: 0.0, 52: 0.0, 53: 0.0, 54: 0.0, 55: 0.0, 56: 0.0, 57: 0.0, 58: 0.0, 59: 0.0, 60: 0.0, 61: 0.0, 62: 0.0, 63: 1.0, 64: 0.0, 65: 0.0, 66: 0.0, 67: 0.0, 68: 0.3333333333333333, 69: 0.0, 70: 0.0, 71: 0.0, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.0, 77: 1.0, 78: 0.0, 79: 0.0, 80: 0.0, 81: 0.0, 82: 0.0, 83: 0.0, 84: 0.0, 85: 0.0, 86: 1.0, 87: 0.0, 88: 0.0, 89: 0.0, 90: 0.5, 91: 0.0, 92: 0.0, 93: 0.0, 94: 0.0, 95: 0.0, 96: 0.0, 97: 0.0, 98: 0.0, 99: 0.0}

checkpoint_t_1  ->  0.06976744186046512
Label accuracies statistics:
{0: 0.5, 1: 0.25, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0, 10: 0.0, 11: 0.0, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.0, 19: 0.0, 20: 0.0, 21: 0.0, 22: 0.0, 23: 0.0, 24: 0.3333333333333333, 25: 0.0, 26: 0.3333333333333333, 27: 0.0, 28: 0.0, 29: 0.0, 30: 0.0, 31: 0.0, 32: 0.0, 33: 0.0, 34: 0.0, 35: 0.0, 36: 0.0, 37: 0.0, 38: 0.0, 39: 0.0, 40: 0.0, 41: 0.0, 42: 0.0, 43: 0.6666666666666666, 44: 0.0, 45: 0.0, 46: 0.0, 47: 0.0, 48: 0.0, 49: 1.0, 50: 0.0, 51: 0.0, 52: 0.0, 53: 0.0, 54: 0.0, 55: 0.0, 56: 0.0, 57: 0.0, 58: 0.0, 59: 0.0, 60: 0.0, 61: 0.0, 62: 0.0, 63: 1.0, 64: 0.0, 65: 0.0, 66: 0.0, 67: 0.0, 68: 0.3333333333333333, 69: 0.0, 70: 0.0, 71: 0.0, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.0, 77: 1.0, 78: 0.0, 79: 0.0, 80: 0.0, 81: 0.0, 82: 0.0, 83: 0.0, 84: 0.0, 85: 0.0, 86: 1.0, 87: 0.0, 88: 0.0, 89: 0.0, 90: 0.5, 91: 0.0, 92: 0.0, 93: 0.0, 94: 0.0, 95: 0.0, 96: 0.0, 97: 0.0, 98: 0.0, 99: 0.0}

checkpoint_v_1  ->  0.06976744186046512
Label accuracies statistics:
{0: 1.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.3333333333333333, 5: 0.3333333333333333, 6: 0.3333333333333333, 7: 0.3333333333333333, 8: 0.3333333333333333, 9: 0.0, 10: 0.6666666666666666, 11: 0.0, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.0, 19: 0.0, 20: 0.0, 21: 0.3333333333333333, 22: 0.0, 23: 0.0, 24: 0.0, 25: 0.0, 26: 1.0, 27: 0.0, 28: 0.6666666666666666, 29: 0.0, 30: 0.0, 31: 0.3333333333333333, 32: 0.0, 33: 1.0, 34: 0.0, 35: 0.5, 36: 0.3333333333333333, 37: 0.0, 38: 0.0, 39: 0.0, 40: 1.0, 41: 0.0, 42: 0.0, 43: 0.3333333333333333, 44: 0.0, 45: 0.0, 46: 0.0, 47: 0.0, 48: 0.3333333333333333, 49: 0.5, 50: 0.5, 51: 0.0, 52: 0.0, 53: 0.0, 54: 0.0, 55: 0.5, 56: 0.0, 57: 0.0, 58: 0.0, 59: 0.0, 60: 0.0, 61: 0.0, 62: 0.5, 63: 0.5, 64: 0.0, 65: 0.0, 66: 0.0, 67: 0.3333333333333333, 68: 0.0, 69: 0.0, 70: 0.0, 71: 0.6666666666666666, 72: 0.0, 73: 0.0, 74: 0.5, 75: 0.0, 76: 0.0, 77: 0.0, 78: 0.0, 79: 0.5, 80: 0.3333333333333333, 81: 0.5, 82: 0.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 0.0, 87: 0.5, 88: 0.3333333333333333, 89: 0.5, 90: 0.0, 91: 0.0, 92: 0.5, 93: 0.0, 94: 0.0, 95: 0.0, 96: 0.0, 97: 1.0, 98: 0.0, 99: 0.0}

checkpoint_t_2  ->  0.1744186046511628
Label accuracies statistics:
{0: 1.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.3333333333333333, 5: 0.3333333333333333, 6: 0.3333333333333333, 7: 0.3333333333333333, 8: 0.3333333333333333, 9: 0.0, 10: 0.6666666666666666, 11: 0.0, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.0, 19: 0.0, 20: 0.0, 21: 0.3333333333333333, 22: 0.0, 23: 0.0, 24: 0.0, 25: 0.0, 26: 1.0, 27: 0.0, 28: 0.6666666666666666, 29: 0.0, 30: 0.0, 31: 0.3333333333333333, 32: 0.0, 33: 1.0, 34: 0.0, 35: 0.5, 36: 0.3333333333333333, 37: 0.0, 38: 0.0, 39: 0.0, 40: 1.0, 41: 0.0, 42: 0.0, 43: 0.3333333333333333, 44: 0.0, 45: 0.0, 46: 0.0, 47: 0.0, 48: 0.3333333333333333, 49: 0.5, 50: 0.5, 51: 0.0, 52: 0.0, 53: 0.0, 54: 0.0, 55: 0.5, 56: 0.0, 57: 0.0, 58: 0.0, 59: 0.0, 60: 0.0, 61: 0.0, 62: 0.5, 63: 0.5, 64: 0.0, 65: 0.0, 66: 0.0, 67: 0.3333333333333333, 68: 0.0, 69: 0.0, 70: 0.0, 71: 0.6666666666666666, 72: 0.0, 73: 0.0, 74: 0.5, 75: 0.0, 76: 0.0, 77: 0.0, 78: 0.0, 79: 0.5, 80: 0.3333333333333333, 81: 0.5, 82: 0.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 0.0, 87: 0.5, 88: 0.3333333333333333, 89: 0.5, 90: 0.0, 91: 0.0, 92: 0.5, 93: 0.0, 94: 0.0, 95: 0.0, 96: 0.0, 97: 1.0, 98: 0.0, 99: 0.0}

checkpoint_v_2  ->  0.1744186046511628
Label accuracies statistics:
{0: 0.75, 1: 0.0, 2: 0.4, 3: 0.25, 4: 0.0, 5: 0.3333333333333333, 6: 0.6666666666666666, 7: 0.0, 8: 0.3333333333333333, 9: 0.0, 10: 0.3333333333333333, 11: 0.0, 12: 0.6666666666666666, 13: 0.6666666666666666, 14: 0.3333333333333333, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.0, 19: 0.0, 20: 0.0, 21: 0.3333333333333333, 22: 0.3333333333333333, 23: 0.0, 24: 0.6666666666666666, 25: 0.0, 26: 0.0, 27: 0.0, 28: 0.3333333333333333, 29: 0.0, 30: 0.3333333333333333, 31: 0.3333333333333333, 32: 0.5, 33: 1.0, 34: 0.5, 35: 0.5, 36: 0.0, 37: 0.5, 38: 0.0, 39: 0.0, 40: 0.5, 41: 0.5, 42: 0.0, 43: 0.3333333333333333, 44: 0.0, 45: 0.0, 46: 0.6666666666666666, 47: 0.0, 48: 0.6666666666666666, 49: 0.5, 50: 0.5, 51: 0.3333333333333333, 52: 0.0, 53: 0.0, 54: 0.5, 55: 0.5, 56: 0.0, 57: 0.3333333333333333, 58: 0.5, 59: 0.3333333333333333, 60: 0.3333333333333333, 61: 0.0, 62: 0.5, 63: 0.0, 64: 0.0, 65: 0.3333333333333333, 66: 0.0, 67: 0.0, 68: 0.0, 69: 0.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.0, 77: 0.5, 78: 0.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 0.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 0.0, 87: 0.5, 88: 0.3333333333333333, 89: 1.0, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.5, 94: 0.5, 95: 0.0, 96: 0.3333333333333333, 97: 1.0, 98: 0.0, 99: 0.0}

checkpoint_t_3  ->  0.26744186046511625
Label accuracies statistics:
{0: 1.0, 1: 0.0, 2: 0.4, 3: 0.0, 4: 1.0, 5: 0.0, 6: 0.6666666666666666, 7: 0.6666666666666666, 8: 0.0, 9: 0.0, 10: 0.6666666666666666, 11: 0.0, 12: 0.3333333333333333, 13: 0.3333333333333333, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.0, 19: 0.3333333333333333, 20: 0.0, 21: 0.3333333333333333, 22: 0.0, 23: 0.0, 24: 0.6666666666666666, 25: 0.0, 26: 0.3333333333333333, 27: 0.6666666666666666, 28: 0.3333333333333333, 29: 0.0, 30: 0.0, 31: 0.0, 32: 0.5, 33: 1.0, 34: 1.0, 35: 0.5, 36: 0.6666666666666666, 37: 0.0, 38: 0.0, 39: 0.0, 40: 0.0, 41: 0.0, 42: 0.0, 43: 0.3333333333333333, 44: 0.0, 45: 0.0, 46: 0.6666666666666666, 47: 0.5, 48: 0.3333333333333333, 49: 0.5, 50: 0.5, 51: 0.3333333333333333, 52: 1.0, 53: 0.0, 54: 1.0, 55: 0.5, 56: 0.0, 57: 0.3333333333333333, 58: 0.0, 59: 0.0, 60: 0.6666666666666666, 61: 0.0, 62: 0.5, 63: 0.5, 64: 0.0, 65: 0.3333333333333333, 66: 1.0, 67: 0.0, 68: 0.0, 69: 0.5, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.0, 77: 1.0, 78: 0.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 0.6666666666666666, 87: 0.0, 88: 0.6666666666666666, 89: 0.0, 90: 0.0, 91: 0.5, 92: 0.0, 93: 0.0, 94: 0.0, 95: 0.0, 96: 0.0, 97: 0.5, 98: 0.0, 99: 0.0}

checkpoint_v_3  ->  0.29069767441860467
Label accuracies statistics:
{0: 0.25, 1: 0.0, 2: 0.6, 3: 0.25, 4: 0.3333333333333333, 5: 0.0, 6: 1.0, 7: 0.3333333333333333, 8: 0.0, 9: 0.3333333333333333, 10: 0.3333333333333333, 11: 0.0, 12: 0.6666666666666666, 13: 0.0, 14: 0.3333333333333333, 15: 0.6666666666666666, 16: 1.0, 17: 0.6666666666666666, 18: 0.3333333333333333, 19: 0.3333333333333333, 20: 0.0, 21: 0.3333333333333333, 22: 0.3333333333333333, 23: 0.0, 24: 0.3333333333333333, 25: 0.6666666666666666, 26: 0.3333333333333333, 27: 0.0, 28: 0.3333333333333333, 29: 0.0, 30: 0.0, 31: 0.6666666666666666, 32: 0.0, 33: 1.0, 34: 0.0, 35: 0.5, 36: 0.0, 37: 0.0, 38: 0.3333333333333333, 39: 0.0, 40: 1.0, 41: 1.0, 42: 0.0, 43: 0.0, 44: 0.5, 45: 0.0, 46: 0.3333333333333333, 47: 1.0, 48: 0.3333333333333333, 49: 0.5, 50: 0.0, 51: 0.0, 52: 0.0, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.0, 57: 0.6666666666666666, 58: 0.5, 59: 0.3333333333333333, 60: 0.6666666666666666, 61: 0.0, 62: 0.5, 63: 0.5, 64: 0.0, 65: 0.3333333333333333, 66: 1.0, 67: 0.0, 68: 0.0, 69: 0.5, 70: 0.0, 71: 0.3333333333333333, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.0, 77: 0.5, 78: 0.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.6666666666666666, 87: 1.0, 88: 0.3333333333333333, 89: 1.0, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.0, 94: 1.0, 95: 0.0, 96: 0.3333333333333333, 97: 0.5, 98: 0.0, 99: 0.0}

checkpoint_t_4  ->  0.313953488372093
Label accuracies statistics:
{0: 0.75, 1: 0.0, 2: 0.4, 3: 0.25, 4: 0.3333333333333333, 5: 0.0, 6: 0.6666666666666666, 7: 0.3333333333333333, 8: 0.6666666666666666, 9: 0.6666666666666666, 10: 0.3333333333333333, 11: 0.3333333333333333, 12: 0.0, 13: 0.3333333333333333, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.6666666666666666, 18: 0.3333333333333333, 19: 0.3333333333333333, 20: 0.0, 21: 0.3333333333333333, 22: 0.3333333333333333, 23: 0.0, 24: 0.3333333333333333, 25: 0.0, 26: 0.0, 27: 0.6666666666666666, 28: 0.3333333333333333, 29: 0.3333333333333333, 30: 0.6666666666666666, 31: 0.0, 32: 0.0, 33: 1.0, 34: 0.5, 35: 0.5, 36: 0.3333333333333333, 37: 0.0, 38: 0.3333333333333333, 39: 0.0, 40: 0.5, 41: 0.0, 42: 0.0, 43: 0.3333333333333333, 44: 0.5, 45: 0.0, 46: 0.6666666666666666, 47: 1.0, 48: 0.6666666666666666, 49: 0.0, 50: 0.5, 51: 0.3333333333333333, 52: 0.5, 53: 1.0, 54: 0.5, 55: 0.5, 56: 0.0, 57: 0.3333333333333333, 58: 0.5, 59: 0.3333333333333333, 60: 1.0, 61: 0.5, 62: 0.5, 63: 1.0, 64: 0.0, 65: 0.3333333333333333, 66: 1.0, 67: 0.0, 68: 0.0, 69: 0.0, 70: 0.0, 71: 0.6666666666666666, 72: 0.0, 73: 0.0, 74: 0.5, 75: 0.0, 76: 0.0, 77: 0.5, 78: 0.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 0.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 0.3333333333333333, 87: 1.0, 88: 0.3333333333333333, 89: 0.5, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.0, 94: 0.0, 95: 0.0, 96: 0.3333333333333333, 97: 0.5, 98: 0.0, 99: 0.0}

checkpoint_v_4  ->  0.32945736434108525
Label accuracies statistics:
{0: 1.0, 1: 0.25, 2: 0.4, 3: 0.25, 4: 0.3333333333333333, 5: 0.3333333333333333, 6: 0.6666666666666666, 7: 0.3333333333333333, 8: 0.6666666666666666, 9: 0.0, 10: 0.3333333333333333, 11: 0.0, 12: 0.6666666666666666, 13: 0.0, 14: 0.3333333333333333, 15: 1.0, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.3333333333333333, 20: 0.3333333333333333, 21: 0.3333333333333333, 22: 0.6666666666666666, 23: 0.0, 24: 0.3333333333333333, 25: 0.3333333333333333, 26: 0.0, 27: 0.6666666666666666, 28: 0.0, 29: 0.3333333333333333, 30: 0.0, 31: 0.3333333333333333, 32: 0.5, 33: 1.0, 34: 0.0, 35: 0.5, 36: 0.0, 37: 0.0, 38: 0.3333333333333333, 39: 0.0, 40: 1.0, 41: 0.5, 42: 0.0, 43: 0.3333333333333333, 44: 0.5, 45: 0.0, 46: 0.6666666666666666, 47: 1.0, 48: 0.6666666666666666, 49: 0.0, 50: 0.5, 51: 0.3333333333333333, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.0, 56: 0.0, 57: 1.0, 58: 0.5, 59: 0.0, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.3333333333333333, 66: 0.5, 67: 0.0, 68: 0.3333333333333333, 69: 0.0, 70: 0.0, 71: 0.0, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.3333333333333333, 77: 1.0, 78: 0.0, 79: 0.5, 80: 0.3333333333333333, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 0.6666666666666666, 87: 1.0, 88: 0.3333333333333333, 89: 0.5, 90: 0.0, 91: 1.0, 92: 0.5, 93: 0.0, 94: 0.5, 95: 0.5, 96: 0.3333333333333333, 97: 0.0, 98: 0.5, 99: 0.0}

checkpoint_t_5  ->  0.3682170542635659
Label accuracies statistics:
{0: 1.0, 1: 0.25, 2: 0.4, 3: 0.25, 4: 0.6666666666666666, 5: 0.3333333333333333, 6: 1.0, 7: 0.6666666666666666, 8: 0.6666666666666666, 9: 0.0, 10: 0.3333333333333333, 11: 0.3333333333333333, 12: 0.6666666666666666, 13: 0.0, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.6666666666666666, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.0, 21: 0.3333333333333333, 22: 0.3333333333333333, 23: 0.0, 24: 0.6666666666666666, 25: 0.3333333333333333, 26: 0.3333333333333333, 27: 0.3333333333333333, 28: 0.3333333333333333, 29: 0.0, 30: 0.6666666666666666, 31: 0.3333333333333333, 32: 0.5, 33: 0.5, 34: 0.0, 35: 0.5, 36: 0.0, 37: 0.0, 38: 0.0, 39: 0.5, 40: 0.5, 41: 0.0, 42: 0.0, 43: 0.3333333333333333, 44: 0.5, 45: 0.5, 46: 1.0, 47: 1.0, 48: 0.3333333333333333, 49: 0.0, 50: 0.5, 51: 0.0, 52: 1.0, 53: 0.0, 54: 1.0, 55: 0.5, 56: 0.6666666666666666, 57: 0.3333333333333333, 58: 0.5, 59: 0.3333333333333333, 60: 0.6666666666666666, 61: 0.0, 62: 0.5, 63: 0.5, 64: 0.0, 65: 0.3333333333333333, 66: 1.0, 67: 0.0, 68: 0.0, 69: 0.5, 70: 0.0, 71: 0.0, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.3333333333333333, 77: 1.0, 78: 0.3333333333333333, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 0.6666666666666666, 87: 1.0, 88: 0.6666666666666666, 89: 1.0, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_5  ->  0.38372093023255816
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 0.3333333333333333, 5: 0.3333333333333333, 6: 1.0, 7: 0.6666666666666666, 8: 0.6666666666666666, 9: 0.0, 10: 1.0, 11: 0.0, 12: 1.0, 13: 0.0, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 1.0, 17: 0.0, 18: 0.3333333333333333, 19: 0.0, 20: 0.0, 21: 0.3333333333333333, 22: 0.3333333333333333, 23: 0.0, 24: 0.3333333333333333, 25: 0.6666666666666666, 26: 0.0, 27: 0.6666666666666666, 28: 0.3333333333333333, 29: 0.0, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 0.5, 33: 1.0, 34: 0.5, 35: 0.5, 36: 0.3333333333333333, 37: 0.0, 38: 0.6666666666666666, 39: 0.0, 40: 1.0, 41: 0.5, 42: 0.0, 43: 0.6666666666666666, 44: 0.5, 45: 0.5, 46: 0.0, 47: 0.5, 48: 0.6666666666666666, 49: 0.0, 50: 0.5, 51: 0.3333333333333333, 52: 1.0, 53: 0.0, 54: 0.5, 55: 1.0, 56: 0.0, 57: 0.0, 58: 1.0, 59: 0.0, 60: 1.0, 61: 0.0, 62: 0.5, 63: 0.5, 64: 0.0, 65: 0.3333333333333333, 66: 0.5, 67: 0.0, 68: 0.3333333333333333, 69: 0.5, 70: 0.0, 71: 0.0, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.3333333333333333, 77: 0.5, 78: 0.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.6666666666666666, 87: 0.5, 88: 0.3333333333333333, 89: 0.5, 90: 0.0, 91: 0.5, 92: 1.0, 93: 0.5, 94: 0.5, 95: 0.5, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_6  ->  0.39147286821705424
Label accuracies statistics:
{0: 1.0, 1: 0.25, 2: 0.4, 3: 0.25, 4: 0.0, 5: 0.3333333333333333, 6: 1.0, 7: 0.3333333333333333, 8: 0.0, 9: 0.0, 10: 0.3333333333333333, 11: 0.3333333333333333, 12: 0.6666666666666666, 13: 0.0, 14: 0.3333333333333333, 15: 0.0, 16: 0.6666666666666666, 17: 0.6666666666666666, 18: 0.0, 19: 0.3333333333333333, 20: 0.3333333333333333, 21: 0.3333333333333333, 22: 0.3333333333333333, 23: 0.0, 24: 0.3333333333333333, 25: 0.6666666666666666, 26: 0.0, 27: 0.6666666666666666, 28: 0.6666666666666666, 29: 0.0, 30: 0.6666666666666666, 31: 0.3333333333333333, 32: 0.5, 33: 1.0, 34: 0.5, 35: 0.5, 36: 0.0, 37: 0.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 0.0, 42: 0.0, 43: 0.3333333333333333, 44: 0.5, 45: 0.5, 46: 0.6666666666666666, 47: 1.0, 48: 0.6666666666666666, 49: 0.5, 50: 0.5, 51: 0.3333333333333333, 52: 0.5, 53: 1.0, 54: 1.0, 55: 0.5, 56: 0.0, 57: 0.6666666666666666, 58: 0.5, 59: 0.0, 60: 1.0, 61: 0.0, 62: 0.5, 63: 1.0, 64: 0.0, 65: 0.3333333333333333, 66: 0.5, 67: 0.0, 68: 0.3333333333333333, 69: 0.0, 70: 1.0, 71: 0.0, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.5, 76: 0.3333333333333333, 77: 1.0, 78: 0.3333333333333333, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 0.6666666666666666, 87: 0.0, 88: 0.3333333333333333, 89: 0.5, 90: 0.0, 91: 1.0, 92: 0.5, 93: 0.5, 94: 0.0, 95: 0.0, 96: 0.3333333333333333, 97: 1.0, 98: 0.5, 99: 0.0}

checkpoint_v_6  ->  0.38372093023255816
Label accuracies statistics:
{0: 1.0, 1: 0.25, 2: 0.6, 3: 0.5, 4: 1.0, 5: 0.3333333333333333, 6: 1.0, 7: 0.3333333333333333, 8: 0.6666666666666666, 9: 0.3333333333333333, 10: 0.6666666666666666, 11: 0.3333333333333333, 12: 1.0, 13: 0.6666666666666666, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 1.0, 17: 0.3333333333333333, 18: 0.0, 19: 0.6666666666666666, 20: 0.3333333333333333, 21: 0.3333333333333333, 22: 0.3333333333333333, 23: 0.0, 24: 0.3333333333333333, 25: 0.0, 26: 0.0, 27: 0.6666666666666666, 28: 0.6666666666666666, 29: 0.0, 30: 0.6666666666666666, 31: 0.3333333333333333, 32: 0.0, 33: 1.0, 34: 0.0, 35: 0.5, 36: 0.3333333333333333, 37: 0.0, 38: 0.3333333333333333, 39: 0.5, 40: 0.5, 41: 0.0, 42: 0.0, 43: 1.0, 44: 0.5, 45: 0.5, 46: 0.6666666666666666, 47: 1.0, 48: 0.3333333333333333, 49: 0.0, 50: 0.5, 51: 0.3333333333333333, 52: 1.0, 53: 0.0, 54: 0.0, 55: 0.0, 56: 0.0, 57: 0.3333333333333333, 58: 1.0, 59: 0.0, 60: 0.6666666666666666, 61: 0.0, 62: 0.5, 63: 0.5, 64: 0.0, 65: 0.3333333333333333, 66: 0.5, 67: 0.0, 68: 0.0, 69: 0.5, 70: 1.0, 71: 0.3333333333333333, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.0, 77: 1.0, 78: 0.3333333333333333, 79: 1.0, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 1.0, 87: 0.5, 88: 0.3333333333333333, 89: 0.5, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.5, 94: 1.0, 95: 0.0, 96: 0.0, 97: 0.5, 98: 0.0, 99: 0.5}

checkpoint_t_7  ->  0.40310077519379844
Label accuracies statistics:
{0: 1.0, 1: 0.25, 2: 0.4, 3: 0.25, 4: 0.3333333333333333, 5: 0.3333333333333333, 6: 1.0, 7: 0.6666666666666666, 8: 0.3333333333333333, 9: 0.0, 10: 0.3333333333333333, 11: 0.3333333333333333, 12: 1.0, 13: 0.0, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 1.0, 17: 0.0, 18: 0.3333333333333333, 19: 0.3333333333333333, 20: 0.3333333333333333, 21: 0.3333333333333333, 22: 0.6666666666666666, 23: 0.0, 24: 0.3333333333333333, 25: 0.6666666666666666, 26: 0.3333333333333333, 27: 0.0, 28: 0.3333333333333333, 29: 0.3333333333333333, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 0.0, 33: 1.0, 34: 0.5, 35: 0.5, 36: 0.6666666666666666, 37: 0.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 0.5, 42: 0.0, 43: 0.6666666666666666, 44: 0.5, 45: 0.0, 46: 0.3333333333333333, 47: 1.0, 48: 0.6666666666666666, 49: 0.5, 50: 0.5, 51: 0.3333333333333333, 52: 1.0, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 0.5, 59: 0.3333333333333333, 60: 1.0, 61: 0.0, 62: 0.5, 63: 1.0, 64: 0.0, 65: 0.3333333333333333, 66: 0.5, 67: 0.0, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.6666666666666666, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.5, 76: 0.0, 77: 1.0, 78: 0.3333333333333333, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 0.6666666666666666, 87: 0.0, 88: 0.6666666666666666, 89: 0.5, 90: 0.0, 91: 0.0, 92: 0.5, 93: 0.0, 94: 0.5, 95: 0.5, 96: 0.3333333333333333, 97: 0.0, 98: 0.5, 99: 0.5}

checkpoint_v_7  ->  0.4069767441860465
Label accuracies statistics:
{0: 1.0, 1: 0.25, 2: 0.4, 3: 0.5, 4: 0.0, 5: 0.3333333333333333, 6: 1.0, 7: 0.3333333333333333, 8: 0.0, 9: 0.0, 10: 0.6666666666666666, 11: 0.0, 12: 1.0, 13: 0.0, 14: 0.3333333333333333, 15: 0.6666666666666666, 16: 1.0, 17: 1.0, 18: 0.0, 19: 0.3333333333333333, 20: 0.0, 21: 0.3333333333333333, 22: 0.3333333333333333, 23: 0.0, 24: 0.3333333333333333, 25: 0.6666666666666666, 26: 0.3333333333333333, 27: 0.3333333333333333, 28: 0.6666666666666666, 29: 0.3333333333333333, 30: 0.6666666666666666, 31: 0.0, 32: 0.5, 33: 0.5, 34: 0.0, 35: 0.5, 36: 0.0, 37: 0.0, 38: 0.6666666666666666, 39: 0.5, 40: 1.0, 41: 0.5, 42: 0.0, 43: 0.3333333333333333, 44: 0.5, 45: 0.5, 46: 0.0, 47: 1.0, 48: 0.6666666666666666, 49: 0.5, 50: 0.5, 51: 0.3333333333333333, 52: 1.0, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 1.0, 59: 0.6666666666666666, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.3333333333333333, 66: 0.5, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 0.0, 70: 0.0, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.3333333333333333, 77: 1.0, 78: 0.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 1.0, 87: 0.5, 88: 0.3333333333333333, 89: 1.0, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.5, 94: 0.5, 95: 0.0, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.5}

checkpoint_t_8  ->  0.4108527131782946
Label accuracies statistics:
{0: 0.75, 1: 0.0, 2: 0.2, 3: 0.25, 4: 0.3333333333333333, 5: 0.3333333333333333, 6: 1.0, 7: 0.3333333333333333, 8: 0.3333333333333333, 9: 0.0, 10: 0.3333333333333333, 11: 0.0, 12: 1.0, 13: 0.0, 14: 0.3333333333333333, 15: 1.0, 16: 1.0, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.0, 20: 0.0, 21: 0.3333333333333333, 22: 0.6666666666666666, 23: 0.0, 24: 0.3333333333333333, 25: 0.0, 26: 0.3333333333333333, 27: 0.6666666666666666, 28: 0.6666666666666666, 29: 0.6666666666666666, 30: 0.6666666666666666, 31: 0.0, 32: 0.5, 33: 0.5, 34: 0.5, 35: 0.5, 36: 0.3333333333333333, 37: 0.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 0.5, 42: 0.0, 43: 0.3333333333333333, 44: 0.5, 45: 0.5, 46: 0.6666666666666666, 47: 1.0, 48: 0.0, 49: 0.5, 50: 0.5, 51: 0.6666666666666666, 52: 1.0, 53: 0.0, 54: 0.0, 55: 0.5, 56: 0.0, 57: 1.0, 58: 0.5, 59: 0.0, 60: 0.3333333333333333, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.3333333333333333, 66: 0.5, 67: 0.0, 68: 0.3333333333333333, 69: 1.0, 70: 0.0, 71: 0.3333333333333333, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.5, 76: 0.0, 77: 1.0, 78: 0.3333333333333333, 79: 0.0, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.6666666666666666, 87: 0.5, 88: 0.3333333333333333, 89: 1.0, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.0, 94: 1.0, 95: 0.5, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_8  ->  0.3875968992248062
Label accuracies statistics:
{0: 1.0, 1: 0.25, 2: 0.4, 3: 0.25, 4: 0.3333333333333333, 5: 0.3333333333333333, 6: 1.0, 7: 0.0, 8: 0.0, 9: 0.6666666666666666, 10: 0.3333333333333333, 11: 0.3333333333333333, 12: 0.6666666666666666, 13: 0.0, 14: 0.3333333333333333, 15: 0.6666666666666666, 16: 1.0, 17: 0.0, 18: 0.3333333333333333, 19: 0.0, 20: 0.3333333333333333, 21: 0.3333333333333333, 22: 0.3333333333333333, 23: 0.0, 24: 0.3333333333333333, 25: 0.6666666666666666, 26: 0.3333333333333333, 27: 0.3333333333333333, 28: 0.3333333333333333, 29: 0.3333333333333333, 30: 0.3333333333333333, 31: 0.3333333333333333, 32: 0.5, 33: 1.0, 34: 0.0, 35: 0.5, 36: 0.3333333333333333, 37: 0.0, 38: 0.6666666666666666, 39: 0.5, 40: 0.5, 41: 0.5, 42: 0.0, 43: 1.0, 44: 0.5, 45: 0.5, 46: 0.6666666666666666, 47: 0.5, 48: 0.6666666666666666, 49: 0.5, 50: 0.5, 51: 0.3333333333333333, 52: 1.0, 53: 0.0, 54: 0.5, 55: 0.5, 56: 0.0, 57: 0.3333333333333333, 58: 1.0, 59: 0.6666666666666666, 60: 1.0, 61: 0.0, 62: 0.5, 63: 1.0, 64: 0.0, 65: 0.3333333333333333, 66: 0.5, 67: 0.0, 68: 0.3333333333333333, 69: 0.0, 70: 0.0, 71: 0.3333333333333333, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.0, 77: 1.0, 78: 0.0, 79: 1.0, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 0.6666666666666666, 87: 1.0, 88: 0.3333333333333333, 89: 0.5, 90: 0.0, 91: 1.0, 92: 0.5, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_9  ->  0.3953488372093023
Label accuracies statistics:
{0: 1.0, 1: 0.25, 2: 0.4, 3: 0.25, 4: 0.6666666666666666, 5: 0.3333333333333333, 6: 1.0, 7: 0.0, 8: 0.6666666666666666, 9: 0.0, 10: 0.3333333333333333, 11: 0.3333333333333333, 12: 1.0, 13: 0.3333333333333333, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 1.0, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.3333333333333333, 21: 0.3333333333333333, 22: 0.6666666666666666, 23: 0.0, 24: 0.3333333333333333, 25: 0.6666666666666666, 26: 0.3333333333333333, 27: 0.3333333333333333, 28: 0.6666666666666666, 29: 0.3333333333333333, 30: 0.6666666666666666, 31: 0.0, 32: 0.5, 33: 0.5, 34: 0.0, 35: 0.5, 36: 0.3333333333333333, 37: 0.0, 38: 0.3333333333333333, 39: 0.5, 40: 0.5, 41: 0.5, 42: 0.0, 43: 0.6666666666666666, 44: 0.5, 45: 0.5, 46: 0.3333333333333333, 47: 0.5, 48: 0.3333333333333333, 49: 0.5, 50: 0.5, 51: 0.3333333333333333, 52: 1.0, 53: 0.5, 54: 1.0, 55: 0.0, 56: 0.0, 57: 0.3333333333333333, 58: 1.0, 59: 0.6666666666666666, 60: 0.6666666666666666, 61: 0.5, 62: 0.5, 63: 1.0, 64: 0.0, 65: 0.0, 66: 0.5, 67: 0.0, 68: 0.3333333333333333, 69: 0.5, 70: 0.0, 71: 0.3333333333333333, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 1.0, 78: 0.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 0.6666666666666666, 87: 1.0, 88: 0.6666666666666666, 89: 0.0, 90: 0.0, 91: 1.0, 92: 0.5, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.5}

checkpoint_v_9  ->  0.4186046511627907
Label accuracies statistics:
{0: 1.0, 1: 0.25, 2: 0.6, 3: 0.25, 4: 0.3333333333333333, 5: 0.6666666666666666, 6: 1.0, 7: 0.3333333333333333, 8: 0.3333333333333333, 9: 0.3333333333333333, 10: 0.3333333333333333, 11: 0.0, 12: 0.6666666666666666, 13: 0.0, 14: 0.0, 15: 0.3333333333333333, 16: 1.0, 17: 1.0, 18: 0.3333333333333333, 19: 0.3333333333333333, 20: 0.3333333333333333, 21: 0.3333333333333333, 22: 0.6666666666666666, 23: 0.0, 24: 0.3333333333333333, 25: 0.6666666666666666, 26: 0.3333333333333333, 27: 0.6666666666666666, 28: 0.6666666666666666, 29: 0.3333333333333333, 30: 0.6666666666666666, 31: 0.0, 32: 0.0, 33: 0.5, 34: 0.0, 35: 0.5, 36: 0.6666666666666666, 37: 0.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 0.0, 42: 0.0, 43: 0.3333333333333333, 44: 0.5, 45: 0.5, 46: 0.6666666666666666, 47: 1.0, 48: 0.3333333333333333, 49: 0.5, 50: 0.5, 51: 0.3333333333333333, 52: 1.0, 53: 0.0, 54: 1.0, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 0.5, 59: 0.3333333333333333, 60: 1.0, 61: 0.0, 62: 0.5, 63: 1.0, 64: 0.0, 65: 0.3333333333333333, 66: 0.5, 67: 0.0, 68: 0.3333333333333333, 69: 1.0, 70: 0.0, 71: 0.3333333333333333, 72: 0.0, 73: 0.0, 74: 0.5, 75: 0.0, 76: 0.3333333333333333, 77: 1.0, 78: 0.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 1.0, 87: 1.0, 88: 0.3333333333333333, 89: 0.5, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.5, 94: 0.5, 95: 0.5, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.5}

checkpoint_t_10  ->  0.4263565891472868
Label accuracies statistics:
{0: 1.0, 1: 0.25, 2: 0.4, 3: 0.5, 4: 0.6666666666666666, 5: 0.3333333333333333, 6: 1.0, 7: 0.3333333333333333, 8: 0.0, 9: 0.3333333333333333, 10: 0.3333333333333333, 11: 0.0, 12: 0.6666666666666666, 13: 0.0, 14: 0.3333333333333333, 15: 0.6666666666666666, 16: 1.0, 17: 0.3333333333333333, 18: 0.0, 19: 0.3333333333333333, 20: 0.0, 21: 0.3333333333333333, 22: 0.6666666666666666, 23: 0.0, 24: 0.3333333333333333, 25: 0.0, 26: 0.3333333333333333, 27: 0.6666666666666666, 28: 0.6666666666666666, 29: 0.6666666666666666, 30: 0.6666666666666666, 31: 0.0, 32: 0.0, 33: 0.5, 34: 0.5, 35: 0.5, 36: 0.3333333333333333, 37: 0.0, 38: 0.6666666666666666, 39: 0.5, 40: 1.0, 41: 0.5, 42: 0.0, 43: 0.3333333333333333, 44: 0.5, 45: 0.0, 46: 0.3333333333333333, 47: 1.0, 48: 0.3333333333333333, 49: 0.5, 50: 0.5, 51: 0.6666666666666666, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.0, 56: 0.6666666666666666, 57: 0.6666666666666666, 58: 0.5, 59: 0.6666666666666666, 60: 0.6666666666666666, 61: 0.0, 62: 0.5, 63: 1.0, 64: 0.0, 65: 0.3333333333333333, 66: 0.5, 67: 0.0, 68: 0.3333333333333333, 69: 0.5, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.6666666666666666, 77: 1.0, 78: 0.0, 79: 0.0, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 1.0, 87: 0.5, 88: 0.3333333333333333, 89: 0.5, 90: 0.0, 91: 1.0, 92: 0.5, 93: 0.5, 94: 0.5, 95: 0.0, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.5}

checkpoint_v_10  ->  0.4108527131782946
Label accuracies statistics:
{0: 1.0, 1: 0.25, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.3333333333333333, 6: 1.0, 7: 0.3333333333333333, 8: 0.3333333333333333, 9: 0.6666666666666666, 10: 0.3333333333333333, 11: 0.3333333333333333, 12: 0.6666666666666666, 13: 0.3333333333333333, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 1.0, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.3333333333333333, 20: 0.0, 21: 0.3333333333333333, 22: 0.6666666666666666, 23: 0.0, 24: 0.3333333333333333, 25: 0.0, 26: 0.3333333333333333, 27: 0.6666666666666666, 28: 0.6666666666666666, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 0.0, 32: 0.5, 33: 0.5, 34: 0.0, 35: 0.5, 36: 0.6666666666666666, 37: 0.5, 38: 0.6666666666666666, 39: 0.5, 40: 1.0, 41: 0.0, 42: 0.0, 43: 0.3333333333333333, 44: 0.5, 45: 0.5, 46: 0.6666666666666666, 47: 1.0, 48: 0.6666666666666666, 49: 0.5, 50: 0.5, 51: 0.3333333333333333, 52: 1.0, 53: 0.0, 54: 1.0, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 0.5, 59: 0.6666666666666666, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.3333333333333333, 66: 0.5, 67: 0.0, 68: 0.3333333333333333, 69: 1.0, 70: 0.0, 71: 0.3333333333333333, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.3333333333333333, 77: 1.0, 78: 0.0, 79: 1.0, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 1.0, 87: 0.5, 88: 0.3333333333333333, 89: 0.5, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.5, 94: 0.5, 95: 0.5, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.5}

checkpoint_t_11  ->  0.44573643410852715
Label accuracies statistics:
{0: 1.0, 1: 0.25, 2: 0.4, 3: 0.25, 4: 0.6666666666666666, 5: 0.6666666666666666, 6: 1.0, 7: 0.6666666666666666, 8: 0.3333333333333333, 9: 0.3333333333333333, 10: 0.3333333333333333, 11: 0.0, 12: 1.0, 13: 0.3333333333333333, 14: 0.3333333333333333, 15: 0.6666666666666666, 16: 1.0, 17: 0.3333333333333333, 18: 0.0, 19: 0.3333333333333333, 20: 0.0, 21: 0.3333333333333333, 22: 0.3333333333333333, 23: 0.0, 24: 0.3333333333333333, 25: 0.6666666666666666, 26: 0.3333333333333333, 27: 0.6666666666666666, 28: 0.6666666666666666, 29: 0.3333333333333333, 30: 0.6666666666666666, 31: 0.3333333333333333, 32: 0.5, 33: 1.0, 34: 0.0, 35: 0.5, 36: 0.6666666666666666, 37: 0.0, 38: 0.6666666666666666, 39: 0.5, 40: 1.0, 41: 0.5, 42: 0.0, 43: 0.3333333333333333, 44: 0.5, 45: 0.5, 46: 0.3333333333333333, 47: 1.0, 48: 0.6666666666666666, 49: 0.0, 50: 0.5, 51: 0.3333333333333333, 52: 0.5, 53: 0.5, 54: 0.5, 55: 0.0, 56: 0.0, 57: 1.0, 58: 1.0, 59: 0.6666666666666666, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.3333333333333333, 66: 0.5, 67: 0.3333333333333333, 68: 0.0, 69: 1.0, 70: 0.0, 71: 0.6666666666666666, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.3333333333333333, 77: 1.0, 78: 0.0, 79: 1.0, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 0.6666666666666666, 87: 1.0, 88: 0.6666666666666666, 89: 0.5, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.5, 94: 0.5, 95: 0.5, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.5}

checkpoint_v_11  ->  0.45348837209302323
Label accuracies statistics:
{0: 0.25, 1: 0.25, 2: 0.4, 3: 0.0, 4: 0.6666666666666666, 5: 0.3333333333333333, 6: 1.0, 7: 0.0, 8: 0.0, 9: 0.0, 10: 0.3333333333333333, 11: 0.0, 12: 0.3333333333333333, 13: 0.0, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.3333333333333333, 21: 0.3333333333333333, 22: 0.6666666666666666, 23: 0.0, 24: 0.0, 25: 0.3333333333333333, 26: 0.3333333333333333, 27: 0.6666666666666666, 28: 0.3333333333333333, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 0.0, 32: 0.0, 33: 0.5, 34: 0.0, 35: 0.0, 36: 0.0, 37: 0.5, 38: 0.0, 39: 0.5, 40: 1.0, 41: 0.0, 42: 0.0, 43: 0.3333333333333333, 44: 0.0, 45: 0.5, 46: 0.3333333333333333, 47: 1.0, 48: 0.6666666666666666, 49: 0.0, 50: 0.5, 51: 0.3333333333333333, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.5, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 0.5, 59: 0.3333333333333333, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 0.5, 67: 0.0, 68: 0.3333333333333333, 69: 0.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.3333333333333333, 77: 1.0, 78: 0.0, 79: 1.0, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 0.3333333333333333, 87: 0.0, 88: 0.6666666666666666, 89: 0.0, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.0, 94: 0.0, 95: 0.0, 96: 0.0, 97: 0.0, 98: 0.0, 99: 0.5}

checkpoint_t_12  ->  0.32558139534883723
Label accuracies statistics:
{0: 1.0, 1: 0.25, 2: 0.4, 3: 0.0, 4: 0.6666666666666666, 5: 0.3333333333333333, 6: 1.0, 7: 0.3333333333333333, 8: 0.3333333333333333, 9: 0.6666666666666666, 10: 0.3333333333333333, 11: 0.3333333333333333, 12: 0.6666666666666666, 13: 0.3333333333333333, 14: 0.3333333333333333, 15: 0.6666666666666666, 16: 1.0, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.3333333333333333, 20: 0.3333333333333333, 21: 0.3333333333333333, 22: 0.6666666666666666, 23: 0.0, 24: 0.3333333333333333, 25: 0.3333333333333333, 26: 0.3333333333333333, 27: 0.6666666666666666, 28: 0.6666666666666666, 29: 0.3333333333333333, 30: 0.3333333333333333, 31: 0.3333333333333333, 32: 0.5, 33: 1.0, 34: 0.0, 35: 0.5, 36: 0.6666666666666666, 37: 0.0, 38: 0.3333333333333333, 39: 0.5, 40: 0.5, 41: 0.0, 42: 0.0, 43: 0.3333333333333333, 44: 0.5, 45: 0.5, 46: 1.0, 47: 1.0, 48: 0.6666666666666666, 49: 0.5, 50: 0.5, 51: 0.6666666666666666, 52: 1.0, 53: 0.0, 54: 1.0, 55: 0.5, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 1.0, 59: 0.6666666666666666, 60: 1.0, 61: 0.0, 62: 0.5, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 0.5, 67: 0.0, 68: 0.6666666666666666, 69: 1.0, 70: 0.0, 71: 0.3333333333333333, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.3333333333333333, 77: 1.0, 78: 0.0, 79: 1.0, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 0.6666666666666666, 87: 1.0, 88: 0.3333333333333333, 89: 1.0, 90: 0.0, 91: 1.0, 92: 0.5, 93: 0.5, 94: 0.0, 95: 0.0, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.5}

checkpoint_v_12  ->  0.4573643410852713
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.5, 4: 0.6666666666666666, 5: 0.3333333333333333, 6: 1.0, 7: 0.3333333333333333, 8: 0.3333333333333333, 9: 0.0, 10: 0.6666666666666666, 11: 0.0, 12: 1.0, 13: 0.3333333333333333, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 1.0, 17: 0.3333333333333333, 18: 0.0, 19: 0.0, 20: 0.3333333333333333, 21: 0.3333333333333333, 22: 0.6666666666666666, 23: 0.0, 24: 0.3333333333333333, 25: 0.3333333333333333, 26: 0.3333333333333333, 27: 0.6666666666666666, 28: 0.6666666666666666, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 0.0, 32: 0.5, 33: 0.5, 34: 0.0, 35: 0.5, 36: 0.3333333333333333, 37: 0.0, 38: 0.6666666666666666, 39: 0.5, 40: 0.5, 41: 0.5, 42: 0.0, 43: 1.0, 44: 0.5, 45: 0.0, 46: 0.3333333333333333, 47: 0.5, 48: 0.6666666666666666, 49: 0.5, 50: 0.5, 51: 0.3333333333333333, 52: 1.0, 53: 0.5, 54: 1.0, 55: 0.5, 56: 0.3333333333333333, 57: 1.0, 58: 1.0, 59: 0.6666666666666666, 60: 1.0, 61: 0.0, 62: 0.5, 63: 1.0, 64: 0.0, 65: 0.3333333333333333, 66: 0.5, 67: 0.0, 68: 0.6666666666666666, 69: 0.0, 70: 0.0, 71: 0.6666666666666666, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.5, 76: 0.3333333333333333, 77: 1.0, 78: 0.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 0.6666666666666666, 87: 0.5, 88: 0.3333333333333333, 89: 0.5, 90: 0.0, 91: 1.0, 92: 0.5, 93: 0.5, 94: 0.5, 95: 0.5, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.5}

checkpoint_t_13  ->  0.4418604651162791
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.5, 4: 0.6666666666666666, 5: 0.3333333333333333, 6: 1.0, 7: 0.3333333333333333, 8: 0.3333333333333333, 9: 0.0, 10: 0.6666666666666666, 11: 0.0, 12: 1.0, 13: 0.3333333333333333, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 1.0, 17: 0.3333333333333333, 18: 0.0, 19: 0.0, 20: 0.3333333333333333, 21: 0.3333333333333333, 22: 0.6666666666666666, 23: 0.0, 24: 0.3333333333333333, 25: 0.3333333333333333, 26: 0.3333333333333333, 27: 0.6666666666666666, 28: 0.6666666666666666, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 0.0, 32: 0.5, 33: 0.5, 34: 0.0, 35: 0.5, 36: 0.3333333333333333, 37: 0.0, 38: 0.6666666666666666, 39: 0.5, 40: 0.5, 41: 0.5, 42: 0.0, 43: 1.0, 44: 0.5, 45: 0.0, 46: 0.3333333333333333, 47: 0.5, 48: 0.6666666666666666, 49: 0.5, 50: 0.5, 51: 0.3333333333333333, 52: 1.0, 53: 0.5, 54: 1.0, 55: 0.5, 56: 0.3333333333333333, 57: 1.0, 58: 1.0, 59: 0.6666666666666666, 60: 1.0, 61: 0.0, 62: 0.5, 63: 1.0, 64: 0.0, 65: 0.3333333333333333, 66: 0.5, 67: 0.0, 68: 0.6666666666666666, 69: 0.0, 70: 0.0, 71: 0.6666666666666666, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.5, 76: 0.3333333333333333, 77: 1.0, 78: 0.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 0.6666666666666666, 87: 0.5, 88: 0.3333333333333333, 89: 0.5, 90: 0.0, 91: 1.0, 92: 0.5, 93: 0.5, 94: 0.5, 95: 0.5, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.5}

checkpoint_v_13  ->  0.4418604651162791
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 0.3333333333333333, 5: 0.3333333333333333, 6: 1.0, 7: 0.3333333333333333, 8: 0.3333333333333333, 9: 0.0, 10: 0.3333333333333333, 11: 0.0, 12: 1.0, 13: 0.0, 14: 0.3333333333333333, 15: 0.6666666666666666, 16: 1.0, 17: 0.3333333333333333, 18: 0.0, 19: 0.3333333333333333, 20: 0.0, 21: 0.3333333333333333, 22: 0.6666666666666666, 23: 0.0, 24: 0.3333333333333333, 25: 0.6666666666666666, 26: 0.3333333333333333, 27: 0.6666666666666666, 28: 0.6666666666666666, 29: 0.3333333333333333, 30: 0.6666666666666666, 31: 0.0, 32: 0.5, 33: 1.0, 34: 0.0, 35: 0.5, 36: 0.6666666666666666, 37: 0.5, 38: 0.6666666666666666, 39: 0.5, 40: 0.5, 41: 0.5, 42: 0.0, 43: 1.0, 44: 0.0, 45: 0.5, 46: 0.6666666666666666, 47: 1.0, 48: 0.6666666666666666, 49: 0.0, 50: 0.5, 51: 0.3333333333333333, 52: 1.0, 53: 0.5, 54: 1.0, 55: 0.0, 56: 0.3333333333333333, 57: 0.3333333333333333, 58: 1.0, 59: 0.6666666666666666, 60: 1.0, 61: 0.0, 62: 0.5, 63: 1.0, 64: 0.0, 65: 0.3333333333333333, 66: 0.5, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.0, 71: 0.3333333333333333, 72: 0.0, 73: 0.0, 74: 0.5, 75: 0.0, 76: 0.6666666666666666, 77: 1.0, 78: 0.0, 79: 1.0, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 0.6666666666666666, 87: 1.0, 88: 0.3333333333333333, 89: 1.0, 90: 0.0, 91: 1.0, 92: 0.5, 93: 0.5, 94: 0.0, 95: 0.0, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_14  ->  0.44573643410852715
Label accuracies statistics:
{0: 1.0, 1: 0.25, 2: 0.6, 3: 0.25, 4: 0.6666666666666666, 5: 0.6666666666666666, 6: 1.0, 7: 0.6666666666666666, 8: 0.0, 9: 0.3333333333333333, 10: 0.3333333333333333, 11: 0.3333333333333333, 12: 0.6666666666666666, 13: 0.0, 14: 0.3333333333333333, 15: 0.6666666666666666, 16: 1.0, 17: 0.3333333333333333, 18: 0.0, 19: 0.6666666666666666, 20: 0.0, 21: 0.3333333333333333, 22: 0.3333333333333333, 23: 0.0, 24: 0.3333333333333333, 25: 0.6666666666666666, 26: 0.3333333333333333, 27: 0.6666666666666666, 28: 0.6666666666666666, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 0.0, 32: 0.5, 33: 1.0, 34: 0.0, 35: 0.0, 36: 0.0, 37: 0.0, 38: 0.6666666666666666, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.0, 43: 1.0, 44: 0.5, 45: 0.0, 46: 0.3333333333333333, 47: 1.0, 48: 0.6666666666666666, 49: 0.5, 50: 0.5, 51: 0.3333333333333333, 52: 1.0, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 1.0, 59: 0.6666666666666666, 60: 1.0, 61: 0.0, 62: 0.5, 63: 1.0, 64: 0.0, 65: 0.0, 66: 0.5, 67: 0.0, 68: 0.3333333333333333, 69: 1.0, 70: 0.0, 71: 0.6666666666666666, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.5, 76: 0.3333333333333333, 77: 1.0, 78: 0.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 1.0, 87: 1.0, 88: 0.3333333333333333, 89: 0.0, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.5, 94: 0.5, 95: 0.5, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_14  ->  0.43410852713178294
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 0.6666666666666666, 5: 0.3333333333333333, 6: 1.0, 7: 0.6666666666666666, 8: 0.3333333333333333, 9: 0.0, 10: 0.3333333333333333, 11: 0.3333333333333333, 12: 1.0, 13: 0.6666666666666666, 14: 0.3333333333333333, 15: 0.6666666666666666, 16: 1.0, 17: 0.6666666666666666, 18: 0.3333333333333333, 19: 0.3333333333333333, 20: 0.0, 21: 0.3333333333333333, 22: 0.3333333333333333, 23: 0.0, 24: 0.6666666666666666, 25: 0.6666666666666666, 26: 0.3333333333333333, 27: 0.6666666666666666, 28: 0.6666666666666666, 29: 0.3333333333333333, 30: 0.6666666666666666, 31: 0.6666666666666666, 32: 0.5, 33: 0.5, 34: 0.0, 35: 0.5, 36: 0.6666666666666666, 37: 0.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 0.5, 42: 0.0, 43: 0.3333333333333333, 44: 0.5, 45: 0.5, 46: 0.6666666666666666, 47: 1.0, 48: 0.6666666666666666, 49: 0.0, 50: 0.5, 51: 0.3333333333333333, 52: 1.0, 53: 0.0, 54: 1.0, 55: 0.5, 56: 0.0, 57: 0.3333333333333333, 58: 1.0, 59: 0.6666666666666666, 60: 1.0, 61: 0.0, 62: 0.5, 63: 1.0, 64: 0.0, 65: 0.3333333333333333, 66: 0.5, 67: 0.0, 68: 0.3333333333333333, 69: 1.0, 70: 0.0, 71: 0.3333333333333333, 72: 0.0, 73: 0.0, 74: 0.5, 75: 0.0, 76: 0.6666666666666666, 77: 1.0, 78: 0.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 1.0, 87: 1.0, 88: 0.6666666666666666, 89: 1.0, 90: 0.0, 91: 0.5, 92: 1.0, 93: 0.0, 94: 0.0, 95: 0.5, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.5}

checkpoint_t_15  ->  0.4689922480620155
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 0.6666666666666666, 5: 0.3333333333333333, 6: 1.0, 7: 0.6666666666666666, 8: 0.3333333333333333, 9: 0.0, 10: 0.3333333333333333, 11: 0.3333333333333333, 12: 1.0, 13: 0.6666666666666666, 14: 0.3333333333333333, 15: 0.6666666666666666, 16: 1.0, 17: 0.6666666666666666, 18: 0.3333333333333333, 19: 0.3333333333333333, 20: 0.0, 21: 0.3333333333333333, 22: 0.3333333333333333, 23: 0.0, 24: 0.6666666666666666, 25: 0.6666666666666666, 26: 0.3333333333333333, 27: 0.6666666666666666, 28: 0.6666666666666666, 29: 0.3333333333333333, 30: 0.6666666666666666, 31: 0.6666666666666666, 32: 0.5, 33: 0.5, 34: 0.0, 35: 0.5, 36: 0.6666666666666666, 37: 0.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 0.5, 42: 0.0, 43: 0.3333333333333333, 44: 0.5, 45: 0.5, 46: 0.6666666666666666, 47: 1.0, 48: 0.6666666666666666, 49: 0.0, 50: 0.5, 51: 0.3333333333333333, 52: 1.0, 53: 0.0, 54: 1.0, 55: 0.5, 56: 0.0, 57: 0.3333333333333333, 58: 1.0, 59: 0.6666666666666666, 60: 1.0, 61: 0.0, 62: 0.5, 63: 1.0, 64: 0.0, 65: 0.3333333333333333, 66: 0.5, 67: 0.0, 68: 0.3333333333333333, 69: 1.0, 70: 0.0, 71: 0.3333333333333333, 72: 0.0, 73: 0.0, 74: 0.5, 75: 0.0, 76: 0.6666666666666666, 77: 1.0, 78: 0.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 1.0, 87: 1.0, 88: 0.6666666666666666, 89: 1.0, 90: 0.0, 91: 0.5, 92: 1.0, 93: 0.0, 94: 0.0, 95: 0.5, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.5}

checkpoint_v_15  ->  0.4689922480620155
Label accuracies statistics:
{0: 1.0, 1: 0.25, 2: 0.4, 3: 0.25, 4: 0.3333333333333333, 5: 0.3333333333333333, 6: 1.0, 7: 0.6666666666666666, 8: 0.0, 9: 0.3333333333333333, 10: 0.3333333333333333, 11: 0.0, 12: 1.0, 13: 0.3333333333333333, 14: 0.3333333333333333, 15: 0.6666666666666666, 16: 1.0, 17: 0.3333333333333333, 18: 0.0, 19: 0.6666666666666666, 20: 0.0, 21: 0.3333333333333333, 22: 0.3333333333333333, 23: 0.0, 24: 0.3333333333333333, 25: 0.6666666666666666, 26: 0.3333333333333333, 27: 0.6666666666666666, 28: 0.6666666666666666, 29: 0.3333333333333333, 30: 0.6666666666666666, 31: 0.3333333333333333, 32: 0.5, 33: 0.5, 34: 0.0, 35: 0.0, 36: 0.6666666666666666, 37: 0.5, 38: 0.6666666666666666, 39: 0.5, 40: 1.0, 41: 0.0, 42: 0.0, 43: 0.3333333333333333, 44: 0.5, 45: 0.5, 46: 0.6666666666666666, 47: 1.0, 48: 0.6666666666666666, 49: 0.5, 50: 0.5, 51: 0.3333333333333333, 52: 1.0, 53: 0.0, 54: 0.5, 55: 0.5, 56: 0.3333333333333333, 57: 0.3333333333333333, 58: 1.0, 59: 0.6666666666666666, 60: 1.0, 61: 0.0, 62: 0.5, 63: 1.0, 64: 0.0, 65: 0.3333333333333333, 66: 1.0, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.0, 71: 0.6666666666666666, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.3333333333333333, 77: 1.0, 78: 0.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 0.6666666666666666, 87: 1.0, 88: 0.3333333333333333, 89: 0.5, 90: 0.0, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.5, 95: 0.0, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.5}

checkpoint_t_16  ->  0.44573643410852715
Label accuracies statistics:
{0: 1.0, 1: 0.25, 2: 0.4, 3: 0.25, 4: 0.3333333333333333, 5: 0.3333333333333333, 6: 1.0, 7: 0.6666666666666666, 8: 0.0, 9: 0.3333333333333333, 10: 0.3333333333333333, 11: 0.0, 12: 1.0, 13: 0.3333333333333333, 14: 0.3333333333333333, 15: 0.6666666666666666, 16: 1.0, 17: 0.3333333333333333, 18: 0.0, 19: 0.6666666666666666, 20: 0.0, 21: 0.3333333333333333, 22: 0.3333333333333333, 23: 0.0, 24: 0.3333333333333333, 25: 0.6666666666666666, 26: 0.3333333333333333, 27: 0.6666666666666666, 28: 0.6666666666666666, 29: 0.3333333333333333, 30: 0.6666666666666666, 31: 0.3333333333333333, 32: 0.5, 33: 0.5, 34: 0.0, 35: 0.0, 36: 0.6666666666666666, 37: 0.5, 38: 0.6666666666666666, 39: 0.5, 40: 1.0, 41: 0.0, 42: 0.0, 43: 0.3333333333333333, 44: 0.5, 45: 0.5, 46: 0.6666666666666666, 47: 1.0, 48: 0.6666666666666666, 49: 0.5, 50: 0.5, 51: 0.3333333333333333, 52: 1.0, 53: 0.0, 54: 0.5, 55: 0.5, 56: 0.3333333333333333, 57: 0.3333333333333333, 58: 1.0, 59: 0.6666666666666666, 60: 1.0, 61: 0.0, 62: 0.5, 63: 1.0, 64: 0.0, 65: 0.3333333333333333, 66: 1.0, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.0, 71: 0.6666666666666666, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.3333333333333333, 77: 1.0, 78: 0.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 0.6666666666666666, 87: 1.0, 88: 0.3333333333333333, 89: 0.5, 90: 0.0, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.5, 95: 0.0, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.5}

checkpoint_v_16  ->  0.44573643410852715
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 0.6666666666666666, 5: 0.3333333333333333, 6: 1.0, 7: 0.6666666666666666, 8: 0.3333333333333333, 9: 0.0, 10: 0.6666666666666666, 11: 0.0, 12: 1.0, 13: 0.0, 14: 0.3333333333333333, 15: 0.6666666666666666, 16: 1.0, 17: 0.3333333333333333, 18: 0.0, 19: 0.3333333333333333, 20: 0.0, 21: 0.3333333333333333, 22: 0.3333333333333333, 23: 0.0, 24: 0.3333333333333333, 25: 0.6666666666666666, 26: 0.3333333333333333, 27: 0.6666666666666666, 28: 0.6666666666666666, 29: 0.3333333333333333, 30: 0.3333333333333333, 31: 0.3333333333333333, 32: 0.5, 33: 0.5, 34: 0.0, 35: 0.5, 36: 0.6666666666666666, 37: 0.5, 38: 0.6666666666666666, 39: 0.5, 40: 1.0, 41: 0.5, 42: 0.0, 43: 0.3333333333333333, 44: 0.5, 45: 0.5, 46: 0.3333333333333333, 47: 1.0, 48: 0.6666666666666666, 49: 0.0, 50: 0.5, 51: 0.3333333333333333, 52: 1.0, 53: 0.5, 54: 1.0, 55: 0.5, 56: 0.3333333333333333, 57: 0.3333333333333333, 58: 1.0, 59: 0.6666666666666666, 60: 1.0, 61: 0.0, 62: 0.5, 63: 1.0, 64: 0.0, 65: 0.3333333333333333, 66: 0.5, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.0, 71: 0.6666666666666666, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.6666666666666666, 77: 1.0, 78: 0.0, 79: 1.0, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 0.6666666666666666, 87: 1.0, 88: 0.6666666666666666, 89: 1.0, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.5}

checkpoint_t_17  ->  0.4573643410852713
Label accuracies statistics:
{0: 1.0, 1: 0.25, 2: 0.6, 3: 0.25, 4: 0.3333333333333333, 5: 0.3333333333333333, 6: 1.0, 7: 0.3333333333333333, 8: 0.3333333333333333, 9: 0.3333333333333333, 10: 0.3333333333333333, 11: 0.0, 12: 0.6666666666666666, 13: 0.6666666666666666, 14: 0.3333333333333333, 15: 0.6666666666666666, 16: 1.0, 17: 0.3333333333333333, 18: 0.0, 19: 0.6666666666666666, 20: 0.0, 21: 0.3333333333333333, 22: 0.3333333333333333, 23: 0.0, 24: 0.3333333333333333, 25: 0.6666666666666666, 26: 0.3333333333333333, 27: 0.6666666666666666, 28: 0.6666666666666666, 29: 0.3333333333333333, 30: 0.6666666666666666, 31: 0.3333333333333333, 32: 0.5, 33: 1.0, 34: 0.0, 35: 0.5, 36: 0.6666666666666666, 37: 0.5, 38: 0.6666666666666666, 39: 0.5, 40: 1.0, 41: 0.5, 42: 0.0, 43: 0.3333333333333333, 44: 0.5, 45: 0.5, 46: 0.6666666666666666, 47: 1.0, 48: 0.6666666666666666, 49: 0.0, 50: 0.5, 51: 0.3333333333333333, 52: 1.0, 53: 0.5, 54: 0.0, 55: 0.5, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 1.0, 59: 0.3333333333333333, 60: 1.0, 61: 0.0, 62: 0.5, 63: 1.0, 64: 0.0, 65: 0.3333333333333333, 66: 0.5, 67: 0.0, 68: 0.3333333333333333, 69: 1.0, 70: 0.0, 71: 0.3333333333333333, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.3333333333333333, 77: 1.0, 78: 0.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 0.6666666666666666, 87: 1.0, 88: 0.6666666666666666, 89: 0.5, 90: 0.5, 91: 0.5, 92: 0.5, 93: 0.5, 94: 1.0, 95: 0.0, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.5}

checkpoint_v_17  ->  0.4496124031007752
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.3333333333333333, 6: 1.0, 7: 0.6666666666666666, 8: 0.6666666666666666, 9: 0.3333333333333333, 10: 0.6666666666666666, 11: 0.0, 12: 1.0, 13: 1.0, 14: 0.3333333333333333, 15: 0.6666666666666666, 16: 1.0, 17: 0.3333333333333333, 18: 0.0, 19: 0.3333333333333333, 20: 0.0, 21: 0.3333333333333333, 22: 0.3333333333333333, 23: 0.0, 24: 0.3333333333333333, 25: 0.6666666666666666, 26: 0.3333333333333333, 27: 0.6666666666666666, 28: 0.6666666666666666, 29: 0.3333333333333333, 30: 0.3333333333333333, 31: 0.3333333333333333, 32: 0.5, 33: 1.0, 34: 0.0, 35: 0.5, 36: 0.6666666666666666, 37: 0.0, 38: 0.6666666666666666, 39: 0.5, 40: 1.0, 41: 0.0, 42: 0.0, 43: 0.6666666666666666, 44: 0.5, 45: 0.5, 46: 0.6666666666666666, 47: 1.0, 48: 0.6666666666666666, 49: 0.0, 50: 0.5, 51: 0.3333333333333333, 52: 1.0, 53: 0.5, 54: 0.0, 55: 0.0, 56: 0.3333333333333333, 57: 0.3333333333333333, 58: 1.0, 59: 0.3333333333333333, 60: 1.0, 61: 0.0, 62: 0.5, 63: 1.0, 64: 0.0, 65: 0.0, 66: 0.5, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.0, 71: 0.3333333333333333, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 1.0, 77: 1.0, 78: 0.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 1.0, 87: 1.0, 88: 0.3333333333333333, 89: 0.5, 90: 0.0, 91: 1.0, 92: 0.5, 93: 0.0, 94: 0.5, 95: 0.0, 96: 0.3333333333333333, 97: 0.5, 98: 0.0, 99: 0.5}

checkpoint_t_18  ->  0.45348837209302323
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.3333333333333333, 6: 1.0, 7: 0.6666666666666666, 8: 0.6666666666666666, 9: 0.3333333333333333, 10: 0.6666666666666666, 11: 0.0, 12: 1.0, 13: 1.0, 14: 0.3333333333333333, 15: 0.6666666666666666, 16: 1.0, 17: 0.3333333333333333, 18: 0.0, 19: 0.3333333333333333, 20: 0.0, 21: 0.3333333333333333, 22: 0.3333333333333333, 23: 0.0, 24: 0.3333333333333333, 25: 0.6666666666666666, 26: 0.3333333333333333, 27: 0.6666666666666666, 28: 0.6666666666666666, 29: 0.3333333333333333, 30: 0.3333333333333333, 31: 0.3333333333333333, 32: 0.5, 33: 1.0, 34: 0.0, 35: 0.5, 36: 0.6666666666666666, 37: 0.0, 38: 0.6666666666666666, 39: 0.5, 40: 1.0, 41: 0.0, 42: 0.0, 43: 0.6666666666666666, 44: 0.5, 45: 0.5, 46: 0.6666666666666666, 47: 1.0, 48: 0.6666666666666666, 49: 0.0, 50: 0.5, 51: 0.3333333333333333, 52: 1.0, 53: 0.5, 54: 0.0, 55: 0.0, 56: 0.3333333333333333, 57: 0.3333333333333333, 58: 1.0, 59: 0.3333333333333333, 60: 1.0, 61: 0.0, 62: 0.5, 63: 1.0, 64: 0.0, 65: 0.0, 66: 0.5, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.0, 71: 0.3333333333333333, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 1.0, 77: 1.0, 78: 0.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 1.0, 87: 1.0, 88: 0.3333333333333333, 89: 0.5, 90: 0.0, 91: 1.0, 92: 0.5, 93: 0.0, 94: 0.5, 95: 0.0, 96: 0.3333333333333333, 97: 0.5, 98: 0.0, 99: 0.5}

checkpoint_v_18  ->  0.45348837209302323
Label accuracies statistics:
{0: 0.5, 1: 0.25, 2: 0.4, 3: 0.25, 4: 0.0, 5: 0.3333333333333333, 6: 0.6666666666666666, 7: 0.3333333333333333, 8: 0.3333333333333333, 9: 0.3333333333333333, 10: 0.3333333333333333, 11: 0.0, 12: 0.6666666666666666, 13: 0.0, 14: 0.3333333333333333, 15: 0.6666666666666666, 16: 1.0, 17: 0.3333333333333333, 18: 0.0, 19: 0.6666666666666666, 20: 0.0, 21: 0.3333333333333333, 22: 0.3333333333333333, 23: 0.0, 24: 0.0, 25: 0.6666666666666666, 26: 0.6666666666666666, 27: 0.6666666666666666, 28: 0.6666666666666666, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 0.0, 32: 0.0, 33: 1.0, 34: 0.0, 35: 0.5, 36: 0.6666666666666666, 37: 0.0, 38: 0.3333333333333333, 39: 0.5, 40: 0.5, 41: 0.5, 42: 0.0, 43: 0.3333333333333333, 44: 0.5, 45: 0.0, 46: 0.3333333333333333, 47: 0.0, 48: 0.6666666666666666, 49: 0.5, 50: 0.5, 51: 0.3333333333333333, 52: 1.0, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.0, 57: 0.6666666666666666, 58: 1.0, 59: 0.6666666666666666, 60: 0.6666666666666666, 61: 0.0, 62: 0.5, 63: 1.0, 64: 0.0, 65: 0.3333333333333333, 66: 1.0, 67: 0.3333333333333333, 68: 0.6666666666666666, 69: 0.0, 70: 0.0, 71: 0.3333333333333333, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.3333333333333333, 77: 1.0, 78: 0.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 1.0, 87: 1.0, 88: 0.3333333333333333, 89: 0.0, 90: 0.0, 91: 1.0, 92: 0.5, 93: 0.0, 94: 0.5, 95: 0.5, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.5}

checkpoint_t_19  ->  0.3798449612403101
Label accuracies statistics:
{0: 1.0, 1: 0.25, 2: 0.4, 3: 0.5, 4: 1.0, 5: 0.3333333333333333, 6: 1.0, 7: 0.3333333333333333, 8: 0.0, 9: 0.0, 10: 0.3333333333333333, 11: 0.0, 12: 1.0, 13: 0.3333333333333333, 14: 0.3333333333333333, 15: 0.6666666666666666, 16: 1.0, 17: 0.0, 18: 0.3333333333333333, 19: 0.0, 20: 0.0, 21: 0.3333333333333333, 22: 0.6666666666666666, 23: 0.0, 24: 0.6666666666666666, 25: 0.3333333333333333, 26: 0.3333333333333333, 27: 0.6666666666666666, 28: 0.6666666666666666, 29: 0.3333333333333333, 30: 0.0, 31: 0.0, 32: 0.5, 33: 1.0, 34: 0.0, 35: 0.5, 36: 0.6666666666666666, 37: 0.0, 38: 0.6666666666666666, 39: 0.5, 40: 1.0, 41: 0.5, 42: 0.0, 43: 0.3333333333333333, 44: 0.5, 45: 0.0, 46: 0.6666666666666666, 47: 1.0, 48: 0.6666666666666666, 49: 1.0, 50: 0.5, 51: 0.3333333333333333, 52: 1.0, 53: 0.0, 54: 0.5, 55: 0.5, 56: 0.0, 57: 0.6666666666666666, 58: 1.0, 59: 0.3333333333333333, 60: 1.0, 61: 0.0, 62: 0.5, 63: 1.0, 64: 0.0, 65: 0.3333333333333333, 66: 1.0, 67: 0.3333333333333333, 68: 0.0, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.0, 77: 1.0, 78: 0.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 0.6666666666666666, 87: 1.0, 88: 0.3333333333333333, 89: 0.5, 90: 0.0, 91: 1.0, 92: 0.5, 93: 0.0, 94: 0.0, 95: 0.0, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.5}

checkpoint_v_19  ->  0.4186046511627907
Label accuracies statistics:
{0: 1.0, 1: 0.25, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.3333333333333333, 6: 1.0, 7: 0.3333333333333333, 8: 0.3333333333333333, 9: 0.0, 10: 0.3333333333333333, 11: 0.0, 12: 1.0, 13: 0.3333333333333333, 14: 0.3333333333333333, 15: 0.6666666666666666, 16: 1.0, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.3333333333333333, 20: 0.0, 21: 0.3333333333333333, 22: 0.3333333333333333, 23: 0.0, 24: 0.6666666666666666, 25: 0.6666666666666666, 26: 0.3333333333333333, 27: 0.6666666666666666, 28: 0.6666666666666666, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 0.0, 32: 0.5, 33: 1.0, 34: 0.0, 35: 0.5, 36: 0.6666666666666666, 37: 0.5, 38: 0.6666666666666666, 39: 0.5, 40: 1.0, 41: 0.0, 42: 0.0, 43: 0.6666666666666666, 44: 0.5, 45: 0.5, 46: 0.6666666666666666, 47: 1.0, 48: 0.6666666666666666, 49: 0.0, 50: 0.5, 51: 0.3333333333333333, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.5, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 1.0, 59: 0.6666666666666666, 60: 0.6666666666666666, 61: 0.0, 62: 0.5, 63: 1.0, 64: 0.0, 65: 0.0, 66: 0.5, 67: 0.0, 68: 0.3333333333333333, 69: 0.5, 70: 0.0, 71: 0.3333333333333333, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.3333333333333333, 77: 1.0, 78: 0.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 0.6666666666666666, 87: 1.0, 88: 0.3333333333333333, 89: 1.0, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.3333333333333333, 97: 0.5, 98: 1.0, 99: 0.5}

checkpoint_t_20  ->  0.4418604651162791
Label accuracies statistics:
{0: 1.0, 1: 0.25, 2: 0.4, 3: 0.0, 4: 1.0, 5: 0.3333333333333333, 6: 1.0, 7: 0.6666666666666666, 8: 0.3333333333333333, 9: 0.3333333333333333, 10: 0.3333333333333333, 11: 0.0, 12: 0.6666666666666666, 13: 0.3333333333333333, 14: 0.3333333333333333, 15: 0.6666666666666666, 16: 1.0, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.0, 21: 0.3333333333333333, 22: 0.3333333333333333, 23: 0.0, 24: 0.6666666666666666, 25: 0.3333333333333333, 26: 0.3333333333333333, 27: 0.6666666666666666, 28: 0.6666666666666666, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 0.3333333333333333, 32: 0.5, 33: 0.5, 34: 0.0, 35: 0.5, 36: 0.3333333333333333, 37: 0.0, 38: 0.6666666666666666, 39: 0.5, 40: 0.5, 41: 1.0, 42: 0.0, 43: 0.6666666666666666, 44: 0.5, 45: 0.5, 46: 0.3333333333333333, 47: 1.0, 48: 0.6666666666666666, 49: 0.5, 50: 0.5, 51: 0.3333333333333333, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 1.0, 59: 0.6666666666666666, 60: 0.6666666666666666, 61: 0.0, 62: 0.5, 63: 1.0, 64: 0.0, 65: 0.3333333333333333, 66: 1.0, 67: 0.0, 68: 0.3333333333333333, 69: 1.0, 70: 0.0, 71: 0.3333333333333333, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.3333333333333333, 77: 1.0, 78: 0.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 1.0, 87: 1.0, 88: 0.3333333333333333, 89: 1.0, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.5, 94: 0.5, 95: 0.5, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.5}

checkpoint_v_20  ->  0.4496124031007752
Label accuracies statistics:
{0: 1.0, 1: 0.25, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.3333333333333333, 6: 1.0, 7: 0.3333333333333333, 8: 0.6666666666666666, 9: 0.0, 10: 0.3333333333333333, 11: 0.0, 12: 1.0, 13: 0.6666666666666666, 14: 0.3333333333333333, 15: 0.6666666666666666, 16: 1.0, 17: 0.3333333333333333, 18: 0.0, 19: 0.6666666666666666, 20: 0.0, 21: 0.3333333333333333, 22: 0.3333333333333333, 23: 0.0, 24: 0.6666666666666666, 25: 0.6666666666666666, 26: 0.3333333333333333, 27: 0.6666666666666666, 28: 0.6666666666666666, 29: 0.6666666666666666, 30: 0.6666666666666666, 31: 0.0, 32: 0.5, 33: 1.0, 34: 0.0, 35: 0.5, 36: 0.6666666666666666, 37: 0.0, 38: 0.6666666666666666, 39: 0.5, 40: 1.0, 41: 0.5, 42: 0.0, 43: 0.6666666666666666, 44: 0.5, 45: 0.5, 46: 0.3333333333333333, 47: 1.0, 48: 0.6666666666666666, 49: 0.0, 50: 0.5, 51: 0.3333333333333333, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.5, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 1.0, 59: 0.6666666666666666, 60: 0.6666666666666666, 61: 0.0, 62: 0.5, 63: 1.0, 64: 0.0, 65: 0.0, 66: 0.5, 67: 0.0, 68: 0.3333333333333333, 69: 0.5, 70: 0.0, 71: 0.3333333333333333, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.6666666666666666, 77: 1.0, 78: 0.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 1.0, 87: 1.0, 88: 0.3333333333333333, 89: 1.0, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.5}

checkpoint_t_21  ->  0.4496124031007752
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.3333333333333333, 6: 1.0, 7: 0.3333333333333333, 8: 0.3333333333333333, 9: 0.0, 10: 0.3333333333333333, 11: 0.0, 12: 0.6666666666666666, 13: 0.6666666666666666, 14: 0.3333333333333333, 15: 0.6666666666666666, 16: 1.0, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.3333333333333333, 20: 0.0, 21: 0.3333333333333333, 22: 0.3333333333333333, 23: 0.0, 24: 0.6666666666666666, 25: 0.6666666666666666, 26: 0.3333333333333333, 27: 0.6666666666666666, 28: 0.6666666666666666, 29: 0.3333333333333333, 30: 0.6666666666666666, 31: 0.3333333333333333, 32: 0.5, 33: 0.5, 34: 0.0, 35: 0.5, 36: 0.6666666666666666, 37: 0.0, 38: 0.6666666666666666, 39: 0.5, 40: 1.0, 41: 0.5, 42: 0.0, 43: 0.3333333333333333, 44: 0.5, 45: 0.5, 46: 0.6666666666666666, 47: 1.0, 48: 0.6666666666666666, 49: 0.0, 50: 0.5, 51: 0.3333333333333333, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.5, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 1.0, 59: 0.6666666666666666, 60: 0.6666666666666666, 61: 0.0, 62: 0.5, 63: 1.0, 64: 0.0, 65: 0.0, 66: 0.5, 67: 0.0, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.3333333333333333, 77: 1.0, 78: 0.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 1.0, 87: 1.0, 88: 0.3333333333333333, 89: 1.0, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.5, 94: 0.0, 95: 0.0, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.5}

checkpoint_v_21  ->  0.44573643410852715
Label accuracies statistics:
{0: 1.0, 1: 0.25, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.6666666666666666, 8: 0.3333333333333333, 9: 0.0, 10: 0.3333333333333333, 11: 0.0, 12: 0.6666666666666666, 13: 0.3333333333333333, 14: 0.3333333333333333, 15: 1.0, 16: 1.0, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.0, 20: 0.0, 21: 0.3333333333333333, 22: 0.3333333333333333, 23: 0.0, 24: 0.6666666666666666, 25: 0.6666666666666666, 26: 0.3333333333333333, 27: 0.6666666666666666, 28: 0.6666666666666666, 29: 0.6666666666666666, 30: 0.6666666666666666, 31: 0.0, 32: 0.5, 33: 0.5, 34: 0.0, 35: 0.5, 36: 0.3333333333333333, 37: 0.5, 38: 0.6666666666666666, 39: 0.5, 40: 1.0, 41: 0.0, 42: 0.0, 43: 0.3333333333333333, 44: 0.5, 45: 0.5, 46: 0.3333333333333333, 47: 1.0, 48: 0.6666666666666666, 49: 0.0, 50: 0.5, 51: 0.3333333333333333, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 1.0, 59: 0.3333333333333333, 60: 0.3333333333333333, 61: 0.0, 62: 0.5, 63: 1.0, 64: 0.0, 65: 0.0, 66: 1.0, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.0, 71: 0.3333333333333333, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.3333333333333333, 77: 1.0, 78: 0.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 1.0, 87: 1.0, 88: 0.6666666666666666, 89: 1.0, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.5, 94: 0.0, 95: 0.0, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.5}

checkpoint_t_22  ->  0.43410852713178294
Label accuracies statistics:
{0: 1.0, 1: 0.25, 2: 0.4, 3: 0.25, 4: 0.6666666666666666, 5: 0.3333333333333333, 6: 1.0, 7: 0.6666666666666666, 8: 0.6666666666666666, 9: 0.3333333333333333, 10: 0.3333333333333333, 11: 0.0, 12: 1.0, 13: 0.0, 14: 0.3333333333333333, 15: 0.6666666666666666, 16: 1.0, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.3333333333333333, 20: 0.0, 21: 0.3333333333333333, 22: 0.3333333333333333, 23: 0.0, 24: 0.3333333333333333, 25: 0.6666666666666666, 26: 0.3333333333333333, 27: 0.6666666666666666, 28: 0.6666666666666666, 29: 0.3333333333333333, 30: 0.6666666666666666, 31: 0.0, 32: 0.5, 33: 1.0, 34: 0.0, 35: 0.5, 36: 0.6666666666666666, 37: 0.0, 38: 0.6666666666666666, 39: 0.5, 40: 0.5, 41: 0.5, 42: 0.0, 43: 0.3333333333333333, 44: 0.5, 45: 0.5, 46: 0.3333333333333333, 47: 1.0, 48: 0.6666666666666666, 49: 0.0, 50: 0.5, 51: 0.3333333333333333, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.0, 56: 0.0, 57: 0.6666666666666666, 58: 1.0, 59: 0.3333333333333333, 60: 1.0, 61: 0.0, 62: 0.5, 63: 1.0, 64: 0.0, 65: 0.3333333333333333, 66: 0.5, 67: 0.3333333333333333, 68: 0.6666666666666666, 69: 1.0, 70: 0.0, 71: 0.3333333333333333, 72: 0.5, 73: 0.0, 74: 0.5, 75: 0.0, 76: 0.3333333333333333, 77: 1.0, 78: 0.0, 79: 1.0, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 1.0, 87: 1.0, 88: 0.6666666666666666, 89: 0.5, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.5, 94: 0.5, 95: 0.5, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.5}

checkpoint_v_22  ->  0.45348837209302323
Label accuracies statistics:
{0: 1.0, 1: 0.25, 2: 0.6, 3: 0.25, 4: 1.0, 5: 0.3333333333333333, 6: 1.0, 7: 0.3333333333333333, 8: 0.3333333333333333, 9: 0.0, 10: 0.3333333333333333, 11: 0.0, 12: 0.6666666666666666, 13: 0.0, 14: 0.3333333333333333, 15: 0.6666666666666666, 16: 1.0, 17: 0.0, 18: 0.3333333333333333, 19: 0.3333333333333333, 20: 0.0, 21: 0.3333333333333333, 22: 0.3333333333333333, 23: 0.0, 24: 0.3333333333333333, 25: 0.6666666666666666, 26: 0.3333333333333333, 27: 0.6666666666666666, 28: 0.6666666666666666, 29: 0.6666666666666666, 30: 0.6666666666666666, 31: 0.3333333333333333, 32: 0.5, 33: 0.5, 34: 0.0, 35: 0.5, 36: 0.6666666666666666, 37: 0.0, 38: 0.3333333333333333, 39: 0.5, 40: 0.5, 41: 0.0, 42: 0.0, 43: 0.3333333333333333, 44: 0.5, 45: 0.5, 46: 0.6666666666666666, 47: 1.0, 48: 0.6666666666666666, 49: 0.0, 50: 0.5, 51: 0.3333333333333333, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.5, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 1.0, 59: 0.3333333333333333, 60: 0.6666666666666666, 61: 0.0, 62: 0.5, 63: 1.0, 64: 0.0, 65: 0.3333333333333333, 66: 0.5, 67: 0.0, 68: 0.6666666666666666, 69: 0.5, 70: 0.5, 71: 0.6666666666666666, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.0, 76: 0.6666666666666666, 77: 1.0, 78: 0.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 0.6666666666666666, 87: 1.0, 88: 0.6666666666666666, 89: 1.0, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.5}

checkpoint_t_23  ->  0.437984496124031
Label accuracies statistics:
{0: 1.0, 1: 0.25, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.3333333333333333, 6: 1.0, 7: 0.6666666666666666, 8: 0.3333333333333333, 9: 0.6666666666666666, 10: 0.3333333333333333, 11: 0.0, 12: 0.6666666666666666, 13: 0.3333333333333333, 14: 0.3333333333333333, 15: 0.6666666666666666, 16: 1.0, 17: 0.3333333333333333, 18: 0.0, 19: 0.6666666666666666, 20: 0.0, 21: 0.3333333333333333, 22: 0.3333333333333333, 23: 0.0, 24: 0.3333333333333333, 25: 1.0, 26: 0.3333333333333333, 27: 0.6666666666666666, 28: 0.6666666666666666, 29: 0.3333333333333333, 30: 0.6666666666666666, 31: 0.0, 32: 0.5, 33: 0.5, 34: 0.0, 35: 0.5, 36: 0.3333333333333333, 37: 0.0, 38: 0.6666666666666666, 39: 0.5, 40: 0.5, 41: 0.5, 42: 0.0, 43: 0.3333333333333333, 44: 0.5, 45: 0.5, 46: 0.3333333333333333, 47: 1.0, 48: 0.6666666666666666, 49: 0.0, 50: 0.5, 51: 0.3333333333333333, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.0, 56: 0.0, 57: 0.6666666666666666, 58: 1.0, 59: 0.3333333333333333, 60: 0.6666666666666666, 61: 0.0, 62: 0.5, 63: 1.0, 64: 0.0, 65: 0.3333333333333333, 66: 0.5, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.6666666666666666, 77: 1.0, 78: 0.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 1.0, 87: 0.5, 88: 0.3333333333333333, 89: 0.5, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.5}

checkpoint_v_23  ->  0.43023255813953487
Label accuracies statistics:
{0: 1.0, 1: 0.25, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.3333333333333333, 6: 1.0, 7: 0.6666666666666666, 8: 0.3333333333333333, 9: 0.3333333333333333, 10: 0.3333333333333333, 11: 0.0, 12: 0.6666666666666666, 13: 0.3333333333333333, 14: 0.3333333333333333, 15: 0.6666666666666666, 16: 1.0, 17: 0.3333333333333333, 18: 0.0, 19: 0.6666666666666666, 20: 0.0, 21: 0.3333333333333333, 22: 0.6666666666666666, 23: 0.0, 24: 0.3333333333333333, 25: 0.6666666666666666, 26: 0.0, 27: 0.6666666666666666, 28: 0.6666666666666666, 29: 0.3333333333333333, 30: 0.3333333333333333, 31: 0.3333333333333333, 32: 0.5, 33: 0.5, 34: 0.0, 35: 0.5, 36: 0.6666666666666666, 37: 0.0, 38: 0.6666666666666666, 39: 0.5, 40: 0.5, 41: 0.5, 42: 0.0, 43: 0.6666666666666666, 44: 0.5, 45: 0.0, 46: 0.6666666666666666, 47: 1.0, 48: 0.6666666666666666, 49: 0.0, 50: 0.5, 51: 0.3333333333333333, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 1.0, 59: 0.6666666666666666, 60: 0.6666666666666666, 61: 0.0, 62: 0.5, 63: 1.0, 64: 0.0, 65: 0.3333333333333333, 66: 0.5, 67: 0.3333333333333333, 68: 0.6666666666666666, 69: 1.0, 70: 0.0, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.0, 76: 0.6666666666666666, 77: 1.0, 78: 0.0, 79: 0.0, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 0.6666666666666666, 87: 1.0, 88: 0.3333333333333333, 89: 0.5, 90: 0.0, 91: 0.0, 92: 0.5, 93: 0.5, 94: 0.5, 95: 0.5, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.5}

checkpoint_t_24  ->  0.437984496124031
Label accuracies statistics:
{0: 1.0, 1: 0.25, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.3333333333333333, 6: 1.0, 7: 0.6666666666666666, 8: 0.3333333333333333, 9: 0.3333333333333333, 10: 0.3333333333333333, 11: 0.0, 12: 0.6666666666666666, 13: 0.3333333333333333, 14: 0.3333333333333333, 15: 0.6666666666666666, 16: 1.0, 17: 0.3333333333333333, 18: 0.0, 19: 0.6666666666666666, 20: 0.0, 21: 0.3333333333333333, 22: 0.6666666666666666, 23: 0.0, 24: 0.3333333333333333, 25: 0.6666666666666666, 26: 0.0, 27: 0.6666666666666666, 28: 0.6666666666666666, 29: 0.3333333333333333, 30: 0.3333333333333333, 31: 0.3333333333333333, 32: 0.5, 33: 0.5, 34: 0.0, 35: 0.5, 36: 0.6666666666666666, 37: 0.0, 38: 0.6666666666666666, 39: 0.5, 40: 0.5, 41: 0.5, 42: 0.0, 43: 0.6666666666666666, 44: 0.5, 45: 0.0, 46: 0.6666666666666666, 47: 1.0, 48: 0.6666666666666666, 49: 0.0, 50: 0.5, 51: 0.3333333333333333, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 1.0, 59: 0.6666666666666666, 60: 0.6666666666666666, 61: 0.0, 62: 0.5, 63: 1.0, 64: 0.0, 65: 0.3333333333333333, 66: 0.5, 67: 0.3333333333333333, 68: 0.6666666666666666, 69: 1.0, 70: 0.0, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.0, 76: 0.6666666666666666, 77: 1.0, 78: 0.0, 79: 0.0, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 0.6666666666666666, 87: 1.0, 88: 0.3333333333333333, 89: 0.5, 90: 0.0, 91: 0.0, 92: 0.5, 93: 0.5, 94: 0.5, 95: 0.5, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.5}

checkpoint_v_24  ->  0.437984496124031
Label accuracies statistics:
{0: 1.0, 1: 0.25, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.3333333333333333, 6: 1.0, 7: 0.3333333333333333, 8: 0.6666666666666666, 9: 0.0, 10: 0.3333333333333333, 11: 0.0, 12: 0.6666666666666666, 13: 0.3333333333333333, 14: 0.3333333333333333, 15: 0.6666666666666666, 16: 1.0, 17: 0.3333333333333333, 18: 0.0, 19: 0.3333333333333333, 20: 0.0, 21: 0.3333333333333333, 22: 0.3333333333333333, 23: 0.0, 24: 0.3333333333333333, 25: 0.6666666666666666, 26: 0.3333333333333333, 27: 0.6666666666666666, 28: 0.6666666666666666, 29: 0.3333333333333333, 30: 0.6666666666666666, 31: 0.0, 32: 0.5, 33: 0.5, 34: 0.0, 35: 0.5, 36: 0.6666666666666666, 37: 0.5, 38: 0.6666666666666666, 39: 0.5, 40: 0.5, 41: 0.5, 42: 0.0, 43: 0.3333333333333333, 44: 0.5, 45: 0.5, 46: 0.3333333333333333, 47: 1.0, 48: 0.6666666666666666, 49: 0.0, 50: 0.5, 51: 0.3333333333333333, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.5, 56: 0.0, 57: 0.6666666666666666, 58: 1.0, 59: 0.6666666666666666, 60: 0.6666666666666666, 61: 0.0, 62: 0.5, 63: 1.0, 64: 0.0, 65: 0.0, 66: 0.5, 67: 0.0, 68: 0.6666666666666666, 69: 1.0, 70: 0.0, 71: 0.6666666666666666, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.0, 76: 1.0, 77: 1.0, 78: 0.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 0.6666666666666666, 87: 1.0, 88: 0.3333333333333333, 89: 1.0, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.5, 94: 0.0, 95: 0.0, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.5}

checkpoint_t_25  ->  0.43410852713178294
Label accuracies statistics:
{0: 1.0, 1: 0.25, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.3333333333333333, 6: 1.0, 7: 0.3333333333333333, 8: 0.6666666666666666, 9: 0.0, 10: 0.3333333333333333, 11: 0.0, 12: 0.6666666666666666, 13: 0.3333333333333333, 14: 0.3333333333333333, 15: 0.6666666666666666, 16: 1.0, 17: 0.3333333333333333, 18: 0.0, 19: 0.3333333333333333, 20: 0.0, 21: 0.3333333333333333, 22: 0.3333333333333333, 23: 0.0, 24: 0.3333333333333333, 25: 0.6666666666666666, 26: 0.3333333333333333, 27: 0.6666666666666666, 28: 0.6666666666666666, 29: 0.3333333333333333, 30: 0.6666666666666666, 31: 0.0, 32: 0.5, 33: 0.5, 34: 0.0, 35: 0.5, 36: 0.6666666666666666, 37: 0.5, 38: 0.6666666666666666, 39: 0.5, 40: 0.5, 41: 0.5, 42: 0.0, 43: 0.3333333333333333, 44: 0.5, 45: 0.5, 46: 0.3333333333333333, 47: 1.0, 48: 0.6666666666666666, 49: 0.0, 50: 0.5, 51: 0.3333333333333333, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.5, 56: 0.0, 57: 0.6666666666666666, 58: 1.0, 59: 0.6666666666666666, 60: 0.6666666666666666, 61: 0.0, 62: 0.5, 63: 1.0, 64: 0.0, 65: 0.0, 66: 0.5, 67: 0.0, 68: 0.6666666666666666, 69: 1.0, 70: 0.0, 71: 0.6666666666666666, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.0, 76: 1.0, 77: 1.0, 78: 0.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 0.6666666666666666, 87: 1.0, 88: 0.3333333333333333, 89: 1.0, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.5, 94: 0.0, 95: 0.0, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.5}

checkpoint_v_25  ->  0.43410852713178294
Label accuracies statistics:
{0: 1.0, 1: 0.25, 2: 0.4, 3: 0.25, 4: 0.6666666666666666, 5: 0.3333333333333333, 6: 1.0, 7: 0.3333333333333333, 8: 0.3333333333333333, 9: 0.0, 10: 0.6666666666666666, 11: 0.0, 12: 0.6666666666666666, 13: 0.0, 14: 0.6666666666666666, 15: 0.6666666666666666, 16: 1.0, 17: 0.0, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.0, 21: 0.3333333333333333, 22: 0.3333333333333333, 23: 0.0, 24: 0.3333333333333333, 25: 0.6666666666666666, 26: 0.3333333333333333, 27: 0.6666666666666666, 28: 0.6666666666666666, 29: 0.3333333333333333, 30: 0.3333333333333333, 31: 0.0, 32: 0.5, 33: 0.5, 34: 0.0, 35: 0.5, 36: 0.3333333333333333, 37: 1.0, 38: 0.6666666666666666, 39: 0.5, 40: 0.5, 41: 0.0, 42: 0.0, 43: 0.6666666666666666, 44: 0.5, 45: 0.0, 46: 0.3333333333333333, 47: 0.5, 48: 0.6666666666666666, 49: 0.5, 50: 0.5, 51: 0.3333333333333333, 52: 1.0, 53: 0.5, 54: 1.0, 55: 0.5, 56: 0.0, 57: 0.3333333333333333, 58: 1.0, 59: 0.3333333333333333, 60: 0.6666666666666666, 61: 0.0, 62: 0.5, 63: 0.5, 64: 0.0, 65: 0.3333333333333333, 66: 0.5, 67: 0.0, 68: 0.6666666666666666, 69: 0.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.3333333333333333, 77: 0.5, 78: 0.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 0.6666666666666666, 87: 1.0, 88: 0.3333333333333333, 89: 1.0, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.3333333333333333, 97: 0.5, 98: 1.0, 99: 0.5}

checkpoint_t_26  ->  0.4069767441860465
Label accuracies statistics:
{0: 0.75, 1: 0.25, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.3333333333333333, 6: 1.0, 7: 0.3333333333333333, 8: 0.3333333333333333, 9: 0.0, 10: 0.3333333333333333, 11: 0.0, 12: 1.0, 13: 1.0, 14: 0.3333333333333333, 15: 0.6666666666666666, 16: 1.0, 17: 0.3333333333333333, 18: 0.0, 19: 0.6666666666666666, 20: 0.0, 21: 0.3333333333333333, 22: 0.3333333333333333, 23: 0.0, 24: 0.3333333333333333, 25: 0.6666666666666666, 26: 0.3333333333333333, 27: 0.6666666666666666, 28: 0.6666666666666666, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 0.0, 32: 0.5, 33: 0.5, 34: 0.0, 35: 0.5, 36: 0.6666666666666666, 37: 0.5, 38: 0.6666666666666666, 39: 0.5, 40: 0.5, 41: 0.0, 42: 0.0, 43: 0.6666666666666666, 44: 0.5, 45: 0.5, 46: 0.3333333333333333, 47: 1.0, 48: 0.6666666666666666, 49: 0.0, 50: 0.5, 51: 0.3333333333333333, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 1.0, 59: 0.6666666666666666, 60: 1.0, 61: 0.0, 62: 0.5, 63: 1.0, 64: 0.0, 65: 0.3333333333333333, 66: 0.5, 67: 0.0, 68: 0.3333333333333333, 69: 1.0, 70: 0.0, 71: 0.3333333333333333, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.3333333333333333, 77: 1.0, 78: 0.0, 79: 1.0, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 0.6666666666666666, 87: 1.0, 88: 0.3333333333333333, 89: 1.0, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.5}

checkpoint_v_26  ->  0.437984496124031
Label accuracies statistics:
{0: 1.0, 1: 0.25, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.3333333333333333, 6: 1.0, 7: 0.3333333333333333, 8: 0.3333333333333333, 9: 0.0, 10: 0.3333333333333333, 11: 0.0, 12: 1.0, 13: 0.3333333333333333, 14: 0.3333333333333333, 15: 0.6666666666666666, 16: 1.0, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.3333333333333333, 20: 0.0, 21: 0.3333333333333333, 22: 0.3333333333333333, 23: 0.0, 24: 0.6666666666666666, 25: 0.6666666666666666, 26: 0.3333333333333333, 27: 0.6666666666666666, 28: 0.6666666666666666, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 0.0, 32: 0.5, 33: 0.5, 34: 0.0, 35: 0.5, 36: 0.3333333333333333, 37: 0.5, 38: 0.6666666666666666, 39: 0.5, 40: 0.5, 41: 0.5, 42: 0.0, 43: 0.6666666666666666, 44: 0.5, 45: 0.5, 46: 0.6666666666666666, 47: 1.0, 48: 0.6666666666666666, 49: 0.0, 50: 0.5, 51: 0.3333333333333333, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.5, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 1.0, 59: 0.6666666666666666, 60: 1.0, 61: 0.5, 62: 0.5, 63: 1.0, 64: 0.0, 65: 0.0, 66: 0.5, 67: 0.0, 68: 0.6666666666666666, 69: 0.5, 70: 0.0, 71: 0.6666666666666666, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.6666666666666666, 77: 1.0, 78: 0.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 0.6666666666666666, 87: 1.0, 88: 0.3333333333333333, 89: 1.0, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.5, 94: 0.5, 95: 0.0, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.5}

checkpoint_t_27  ->  0.4496124031007752
Label accuracies statistics:
{0: 1.0, 1: 0.25, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.3333333333333333, 6: 1.0, 7: 0.3333333333333333, 8: 0.3333333333333333, 9: 0.0, 10: 0.6666666666666666, 11: 0.0, 12: 1.0, 13: 0.6666666666666666, 14: 0.3333333333333333, 15: 0.6666666666666666, 16: 1.0, 17: 0.3333333333333333, 18: 0.0, 19: 0.3333333333333333, 20: 0.0, 21: 0.3333333333333333, 22: 0.3333333333333333, 23: 0.0, 24: 0.3333333333333333, 25: 0.6666666666666666, 26: 0.3333333333333333, 27: 0.6666666666666666, 28: 0.6666666666666666, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 0.0, 32: 0.5, 33: 0.5, 34: 0.0, 35: 0.5, 36: 0.3333333333333333, 37: 1.0, 38: 0.6666666666666666, 39: 0.5, 40: 0.5, 41: 0.5, 42: 0.0, 43: 0.6666666666666666, 44: 0.5, 45: 0.5, 46: 0.3333333333333333, 47: 1.0, 48: 0.6666666666666666, 49: 0.5, 50: 0.5, 51: 0.3333333333333333, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.0, 56: 0.3333333333333333, 57: 0.3333333333333333, 58: 1.0, 59: 0.6666666666666666, 60: 1.0, 61: 0.0, 62: 0.5, 63: 1.0, 64: 0.0, 65: 0.3333333333333333, 66: 0.5, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.0, 71: 0.3333333333333333, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.6666666666666666, 77: 1.0, 78: 0.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 0.6666666666666666, 87: 1.0, 88: 0.3333333333333333, 89: 1.0, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.5, 94: 0.5, 95: 0.5, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.5}

checkpoint_v_27  ->  0.4496124031007752
Label accuracies statistics:
{0: 1.0, 1: 0.25, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.3333333333333333, 6: 1.0, 7: 0.3333333333333333, 8: 0.0, 9: 0.0, 10: 0.3333333333333333, 11: 0.0, 12: 1.0, 13: 1.0, 14: 0.3333333333333333, 15: 0.6666666666666666, 16: 1.0, 17: 0.6666666666666666, 18: 0.3333333333333333, 19: 0.3333333333333333, 20: 0.0, 21: 0.3333333333333333, 22: 0.3333333333333333, 23: 0.0, 24: 0.6666666666666666, 25: 0.6666666666666666, 26: 0.3333333333333333, 27: 0.6666666666666666, 28: 0.6666666666666666, 29: 0.3333333333333333, 30: 0.3333333333333333, 31: 0.0, 32: 0.5, 33: 0.5, 34: 0.0, 35: 0.5, 36: 0.3333333333333333, 37: 0.0, 38: 0.6666666666666666, 39: 0.5, 40: 0.5, 41: 0.5, 42: 0.0, 43: 0.6666666666666666, 44: 0.5, 45: 0.5, 46: 0.6666666666666666, 47: 1.0, 48: 0.6666666666666666, 49: 0.0, 50: 0.5, 51: 0.3333333333333333, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.0, 56: 0.3333333333333333, 57: 0.3333333333333333, 58: 1.0, 59: 0.6666666666666666, 60: 0.6666666666666666, 61: 0.0, 62: 0.5, 63: 1.0, 64: 0.0, 65: 0.3333333333333333, 66: 0.5, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.0, 76: 0.6666666666666666, 77: 1.0, 78: 0.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 0.6666666666666666, 87: 1.0, 88: 0.6666666666666666, 89: 1.0, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.5, 94: 0.5, 95: 0.0, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.5}

checkpoint_t_28  ->  0.4496124031007752
Label accuracies statistics:
{0: 1.0, 1: 0.25, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.3333333333333333, 6: 1.0, 7: 0.3333333333333333, 8: 0.0, 9: 0.0, 10: 0.3333333333333333, 11: 0.3333333333333333, 12: 1.0, 13: 0.0, 14: 0.3333333333333333, 15: 0.6666666666666666, 16: 1.0, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.3333333333333333, 20: 0.0, 21: 0.3333333333333333, 22: 0.3333333333333333, 23: 0.0, 24: 0.3333333333333333, 25: 0.6666666666666666, 26: 0.3333333333333333, 27: 0.6666666666666666, 28: 0.6666666666666666, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 0.0, 32: 0.5, 33: 0.5, 34: 0.0, 35: 0.5, 36: 0.3333333333333333, 37: 0.5, 38: 0.6666666666666666, 39: 0.5, 40: 0.5, 41: 1.0, 42: 0.0, 43: 0.6666666666666666, 44: 0.5, 45: 0.5, 46: 0.3333333333333333, 47: 1.0, 48: 0.6666666666666666, 49: 0.0, 50: 0.5, 51: 0.3333333333333333, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.0, 56: 0.3333333333333333, 57: 0.3333333333333333, 58: 1.0, 59: 0.6666666666666666, 60: 1.0, 61: 0.0, 62: 0.5, 63: 1.0, 64: 0.0, 65: 0.3333333333333333, 66: 0.5, 67: 0.0, 68: 0.6666666666666666, 69: 1.0, 70: 0.5, 71: 0.6666666666666666, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.3333333333333333, 77: 1.0, 78: 0.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 1.0, 87: 1.0, 88: 0.6666666666666666, 89: 1.0, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.5}

checkpoint_v_28  ->  0.44573643410852715
Label accuracies statistics:
{0: 1.0, 1: 0.25, 2: 0.4, 3: 0.25, 4: 0.6666666666666666, 5: 0.3333333333333333, 6: 1.0, 7: 0.3333333333333333, 8: 0.3333333333333333, 9: 0.3333333333333333, 10: 0.3333333333333333, 11: 0.0, 12: 1.0, 13: 0.3333333333333333, 14: 0.3333333333333333, 15: 0.6666666666666666, 16: 1.0, 17: 0.0, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.0, 21: 0.3333333333333333, 22: 0.3333333333333333, 23: 0.0, 24: 0.6666666666666666, 25: 0.6666666666666666, 26: 0.3333333333333333, 27: 0.6666666666666666, 28: 0.6666666666666666, 29: 0.3333333333333333, 30: 0.3333333333333333, 31: 0.0, 32: 0.5, 33: 0.5, 34: 0.0, 35: 0.5, 36: 0.6666666666666666, 37: 0.5, 38: 0.6666666666666666, 39: 0.5, 40: 0.5, 41: 0.5, 42: 0.0, 43: 0.6666666666666666, 44: 0.5, 45: 0.5, 46: 0.6666666666666666, 47: 0.5, 48: 0.6666666666666666, 49: 0.5, 50: 0.5, 51: 0.3333333333333333, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.0, 56: 0.0, 57: 0.6666666666666666, 58: 1.0, 59: 0.6666666666666666, 60: 1.0, 61: 0.0, 62: 0.5, 63: 1.0, 64: 0.0, 65: 0.0, 66: 0.5, 67: 0.0, 68: 0.3333333333333333, 69: 1.0, 70: 0.0, 71: 0.3333333333333333, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.3333333333333333, 77: 1.0, 78: 0.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 0.6666666666666666, 87: 1.0, 88: 0.3333333333333333, 89: 1.0, 90: 0.0, 91: 0.5, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.0, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.5}

checkpoint_t_29  ->  0.43023255813953487
Label accuracies statistics:
{0: 1.0, 1: 0.25, 2: 0.4, 3: 0.25, 4: 0.6666666666666666, 5: 0.3333333333333333, 6: 1.0, 7: 0.6666666666666666, 8: 0.0, 9: 0.3333333333333333, 10: 0.3333333333333333, 11: 0.0, 12: 1.0, 13: 0.6666666666666666, 14: 0.3333333333333333, 15: 0.6666666666666666, 16: 1.0, 17: 0.3333333333333333, 18: 0.0, 19: 0.6666666666666666, 20: 0.0, 21: 0.3333333333333333, 22: 0.3333333333333333, 23: 0.0, 24: 0.6666666666666666, 25: 0.6666666666666666, 26: 0.3333333333333333, 27: 0.6666666666666666, 28: 0.6666666666666666, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 0.0, 32: 0.5, 33: 0.5, 34: 0.0, 35: 0.5, 36: 0.6666666666666666, 37: 0.0, 38: 0.6666666666666666, 39: 0.5, 40: 0.5, 41: 0.5, 42: 0.0, 43: 0.6666666666666666, 44: 0.5, 45: 0.5, 46: 0.3333333333333333, 47: 0.5, 48: 0.6666666666666666, 49: 0.5, 50: 0.5, 51: 0.3333333333333333, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.5, 56: 0.3333333333333333, 57: 0.3333333333333333, 58: 1.0, 59: 0.3333333333333333, 60: 1.0, 61: 0.0, 62: 0.5, 63: 1.0, 64: 0.0, 65: 0.3333333333333333, 66: 0.5, 67: 0.0, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.6666666666666666, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.3333333333333333, 77: 1.0, 78: 0.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 1.0, 87: 1.0, 88: 0.6666666666666666, 89: 0.5, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.5, 94: 0.0, 95: 0.0, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.5}

checkpoint_v_29  ->  0.4418604651162791
Label accuracies statistics:
{0: 1.0, 1: 0.25, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.3333333333333333, 6: 1.0, 7: 0.3333333333333333, 8: 0.0, 9: 0.3333333333333333, 10: 0.3333333333333333, 11: 0.3333333333333333, 12: 0.6666666666666666, 13: 0.0, 14: 0.3333333333333333, 15: 1.0, 16: 1.0, 17: 0.3333333333333333, 18: 0.0, 19: 0.6666666666666666, 20: 0.0, 21: 0.3333333333333333, 22: 0.3333333333333333, 23: 0.0, 24: 0.6666666666666666, 25: 0.6666666666666666, 26: 0.3333333333333333, 27: 0.6666666666666666, 28: 0.6666666666666666, 29: 0.6666666666666666, 30: 0.6666666666666666, 31: 0.0, 32: 0.5, 33: 0.5, 34: 0.0, 35: 0.5, 36: 0.3333333333333333, 37: 0.0, 38: 0.3333333333333333, 39: 0.5, 40: 0.5, 41: 0.5, 42: 0.0, 43: 0.3333333333333333, 44: 0.5, 45: 0.0, 46: 0.3333333333333333, 47: 1.0, 48: 0.6666666666666666, 49: 0.0, 50: 0.5, 51: 0.6666666666666666, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.5, 56: 0.0, 57: 0.6666666666666666, 58: 1.0, 59: 0.3333333333333333, 60: 1.0, 61: 0.0, 62: 1.0, 63: 0.5, 64: 0.0, 65: 0.3333333333333333, 66: 0.5, 67: 0.0, 68: 0.6666666666666666, 69: 0.5, 70: 0.5, 71: 0.6666666666666666, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.3333333333333333, 77: 1.0, 78: 0.0, 79: 0.0, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 1.0, 87: 1.0, 88: 0.6666666666666666, 89: 0.5, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.0, 94: 0.0, 95: 0.0, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.5}

checkpoint_t_30  ->  0.42248062015503873
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.3333333333333333, 6: 1.0, 7: 0.3333333333333333, 8: 0.0, 9: 0.0, 10: 0.3333333333333333, 11: 0.3333333333333333, 12: 0.6666666666666666, 13: 0.0, 14: 0.3333333333333333, 15: 1.0, 16: 1.0, 17: 0.0, 18: 0.0, 19: 0.6666666666666666, 20: 0.0, 21: 0.3333333333333333, 22: 0.3333333333333333, 23: 0.0, 24: 0.3333333333333333, 25: 0.6666666666666666, 26: 0.3333333333333333, 27: 0.6666666666666666, 28: 0.6666666666666666, 29: 0.6666666666666666, 30: 0.6666666666666666, 31: 0.0, 32: 0.5, 33: 1.0, 34: 0.0, 35: 0.5, 36: 0.3333333333333333, 37: 0.0, 38: 0.3333333333333333, 39: 0.5, 40: 0.5, 41: 0.5, 42: 0.0, 43: 0.6666666666666666, 44: 0.5, 45: 0.0, 46: 0.3333333333333333, 47: 1.0, 48: 0.6666666666666666, 49: 0.0, 50: 0.5, 51: 0.3333333333333333, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.5, 56: 0.0, 57: 0.0, 58: 1.0, 59: 0.3333333333333333, 60: 1.0, 61: 0.0, 62: 1.0, 63: 0.5, 64: 0.0, 65: 0.3333333333333333, 66: 0.5, 67: 0.0, 68: 0.6666666666666666, 69: 1.0, 70: 0.0, 71: 0.3333333333333333, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.3333333333333333, 77: 1.0, 78: 0.0, 79: 0.0, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 1.0, 87: 1.0, 88: 0.6666666666666666, 89: 0.5, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.0, 94: 0.0, 95: 0.0, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.5}

checkpoint_v_30  ->  0.4069767441860465
Label accuracies statistics:
{0: 1.0, 1: 0.25, 2: 0.4, 3: 0.25, 4: 0.3333333333333333, 5: 0.3333333333333333, 6: 1.0, 7: 0.3333333333333333, 8: 0.0, 9: 0.3333333333333333, 10: 0.3333333333333333, 11: 0.3333333333333333, 12: 0.3333333333333333, 13: 0.0, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 1.0, 17: 0.3333333333333333, 18: 0.0, 19: 0.3333333333333333, 20: 0.3333333333333333, 21: 0.3333333333333333, 22: 0.3333333333333333, 23: 0.0, 24: 0.6666666666666666, 25: 0.6666666666666666, 26: 0.3333333333333333, 27: 0.0, 28: 0.6666666666666666, 29: 0.3333333333333333, 30: 0.6666666666666666, 31: 0.3333333333333333, 32: 0.5, 33: 0.5, 34: 0.0, 35: 0.5, 36: 0.6666666666666666, 37: 0.5, 38: 0.3333333333333333, 39: 0.5, 40: 0.5, 41: 0.0, 42: 0.0, 43: 0.3333333333333333, 44: 0.0, 45: 0.0, 46: 0.6666666666666666, 47: 1.0, 48: 0.6666666666666666, 49: 0.0, 50: 0.5, 51: 0.3333333333333333, 52: 1.0, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.0, 57: 0.3333333333333333, 58: 1.0, 59: 0.3333333333333333, 60: 0.6666666666666666, 61: 0.0, 62: 0.5, 63: 1.0, 64: 0.0, 65: 0.0, 66: 0.5, 67: 0.0, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.3333333333333333, 77: 0.5, 78: 0.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 0.6666666666666666, 87: 1.0, 88: 0.6666666666666666, 89: 1.0, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.5, 94: 0.0, 95: 0.0, 96: 0.3333333333333333, 97: 1.0, 98: 0.5, 99: 0.5}

checkpoint_t_31  ->  0.3798449612403101
Label accuracies statistics:
{0: 1.0, 1: 0.25, 2: 0.4, 3: 0.25, 4: 0.3333333333333333, 5: 0.3333333333333333, 6: 1.0, 7: 0.3333333333333333, 8: 0.3333333333333333, 9: 0.3333333333333333, 10: 0.3333333333333333, 11: 0.0, 12: 0.3333333333333333, 13: 0.3333333333333333, 14: 0.3333333333333333, 15: 0.6666666666666666, 16: 1.0, 17: 0.0, 18: 0.0, 19: 0.6666666666666666, 20: 0.0, 21: 0.3333333333333333, 22: 0.3333333333333333, 23: 0.0, 24: 0.3333333333333333, 25: 0.3333333333333333, 26: 0.3333333333333333, 27: 0.6666666666666666, 28: 0.6666666666666666, 29: 0.3333333333333333, 30: 0.6666666666666666, 31: 0.3333333333333333, 32: 0.5, 33: 0.5, 34: 0.0, 35: 0.5, 36: 0.3333333333333333, 37: 0.5, 38: 0.6666666666666666, 39: 0.5, 40: 0.5, 41: 0.5, 42: 0.0, 43: 0.6666666666666666, 44: 0.0, 45: 0.5, 46: 0.3333333333333333, 47: 1.0, 48: 0.6666666666666666, 49: 0.0, 50: 0.5, 51: 0.3333333333333333, 52: 1.0, 53: 0.5, 54: 1.0, 55: 0.0, 56: 0.3333333333333333, 57: 1.0, 58: 1.0, 59: 0.3333333333333333, 60: 1.0, 61: 0.0, 62: 0.5, 63: 1.0, 64: 0.0, 65: 0.0, 66: 0.5, 67: 0.0, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.6666666666666666, 77: 0.5, 78: 0.0, 79: 0.5, 80: 0.3333333333333333, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 0.6666666666666666, 87: 1.0, 88: 0.3333333333333333, 89: 1.0, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.5, 94: 0.0, 95: 0.0, 96: 0.3333333333333333, 97: 1.0, 98: 1.0, 99: 0.5}

checkpoint_v_31  ->  0.42248062015503873
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 0.6666666666666666, 5: 0.3333333333333333, 6: 1.0, 7: 0.0, 8: 0.0, 9: 0.0, 10: 0.3333333333333333, 11: 0.3333333333333333, 12: 0.6666666666666666, 13: 0.6666666666666666, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 1.0, 17: 0.3333333333333333, 18: 0.0, 19: 0.6666666666666666, 20: 0.0, 21: 0.3333333333333333, 22: 0.6666666666666666, 23: 0.0, 24: 0.6666666666666666, 25: 0.6666666666666666, 26: 0.3333333333333333, 27: 0.6666666666666666, 28: 0.6666666666666666, 29: 0.6666666666666666, 30: 0.6666666666666666, 31: 0.0, 32: 0.5, 33: 0.5, 34: 0.0, 35: 0.5, 36: 0.3333333333333333, 37: 0.5, 38: 0.6666666666666666, 39: 0.5, 40: 1.0, 41: 0.5, 42: 0.0, 43: 0.3333333333333333, 44: 0.5, 45: 0.5, 46: 0.6666666666666666, 47: 1.0, 48: 0.6666666666666666, 49: 0.0, 50: 0.5, 51: 0.3333333333333333, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 1.0, 59: 0.3333333333333333, 60: 1.0, 61: 0.0, 62: 0.5, 63: 1.0, 64: 0.0, 65: 0.3333333333333333, 66: 0.5, 67: 0.0, 68: 0.6666666666666666, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.0, 76: 0.6666666666666666, 77: 1.0, 78: 0.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 0.6666666666666666, 87: 1.0, 88: 0.6666666666666666, 89: 1.0, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.5, 94: 0.0, 95: 0.0, 96: 0.3333333333333333, 97: 1.0, 98: 0.0, 99: 0.5}

checkpoint_t_32  ->  0.4496124031007752
Label accuracies statistics:
{0: 1.0, 1: 0.25, 2: 0.4, 3: 0.25, 4: 0.3333333333333333, 5: 0.3333333333333333, 6: 1.0, 7: 0.6666666666666666, 8: 0.0, 9: 0.3333333333333333, 10: 0.3333333333333333, 11: 0.3333333333333333, 12: 0.3333333333333333, 13: 0.0, 14: 0.3333333333333333, 15: 0.6666666666666666, 16: 1.0, 17: 0.3333333333333333, 18: 0.0, 19: 0.3333333333333333, 20: 0.0, 21: 0.3333333333333333, 22: 0.3333333333333333, 23: 0.0, 24: 0.6666666666666666, 25: 0.6666666666666666, 26: 0.3333333333333333, 27: 0.6666666666666666, 28: 0.6666666666666666, 29: 0.6666666666666666, 30: 0.6666666666666666, 31: 0.0, 32: 0.5, 33: 0.5, 34: 0.0, 35: 0.5, 36: 0.6666666666666666, 37: 1.0, 38: 0.6666666666666666, 39: 0.5, 40: 0.5, 41: 0.5, 42: 0.0, 43: 0.3333333333333333, 44: 0.5, 45: 0.5, 46: 0.6666666666666666, 47: 1.0, 48: 0.6666666666666666, 49: 0.0, 50: 0.5, 51: 0.3333333333333333, 52: 1.0, 53: 0.0, 54: 1.0, 55: 0.0, 56: 0.3333333333333333, 57: 1.0, 58: 1.0, 59: 0.3333333333333333, 60: 1.0, 61: 0.0, 62: 0.5, 63: 1.0, 64: 0.0, 65: 0.3333333333333333, 66: 0.5, 67: 0.0, 68: 0.3333333333333333, 69: 1.0, 70: 0.0, 71: 0.6666666666666666, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.3333333333333333, 77: 1.0, 78: 0.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 0.6666666666666666, 87: 1.0, 88: 0.6666666666666666, 89: 1.0, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.5, 94: 0.0, 95: 0.0, 96: 0.3333333333333333, 97: 1.0, 98: 0.5, 99: 0.5}

checkpoint_v_32  ->  0.437984496124031
Label accuracies statistics:
{0: 1.0, 1: 0.25, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.3333333333333333, 6: 1.0, 7: 0.3333333333333333, 8: 0.0, 9: 0.3333333333333333, 10: 0.3333333333333333, 11: 0.0, 12: 0.3333333333333333, 13: 0.6666666666666666, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 1.0, 17: 0.3333333333333333, 18: 0.0, 19: 0.3333333333333333, 20: 0.3333333333333333, 21: 0.3333333333333333, 22: 0.3333333333333333, 23: 0.3333333333333333, 24: 0.6666666666666666, 25: 0.6666666666666666, 26: 0.3333333333333333, 27: 0.3333333333333333, 28: 0.6666666666666666, 29: 0.6666666666666666, 30: 0.6666666666666666, 31: 0.0, 32: 0.5, 33: 0.5, 34: 0.0, 35: 0.5, 36: 0.6666666666666666, 37: 0.5, 38: 0.6666666666666666, 39: 0.5, 40: 0.5, 41: 0.5, 42: 0.0, 43: 0.6666666666666666, 44: 0.5, 45: 0.5, 46: 0.6666666666666666, 47: 1.0, 48: 0.6666666666666666, 49: 0.0, 50: 0.5, 51: 0.3333333333333333, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.0, 56: 0.0, 57: 0.6666666666666666, 58: 1.0, 59: 0.3333333333333333, 60: 1.0, 61: 0.0, 62: 0.5, 63: 1.0, 64: 0.0, 65: 0.3333333333333333, 66: 0.5, 67: 0.0, 68: 0.3333333333333333, 69: 1.0, 70: 0.0, 71: 0.6666666666666666, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.3333333333333333, 77: 0.5, 78: 0.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 0.6666666666666666, 87: 1.0, 88: 0.3333333333333333, 89: 0.5, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.5, 94: 0.0, 95: 0.0, 96: 0.3333333333333333, 97: 1.0, 98: 0.5, 99: 0.5}

checkpoint_t_33  ->  0.4263565891472868
Label accuracies statistics:
{0: 1.0, 1: 0.25, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.3333333333333333, 6: 1.0, 7: 0.3333333333333333, 8: 0.0, 9: 0.0, 10: 0.3333333333333333, 11: 0.0, 12: 1.0, 13: 0.6666666666666666, 14: 0.3333333333333333, 15: 0.6666666666666666, 16: 1.0, 17: 0.3333333333333333, 18: 0.0, 19: 0.3333333333333333, 20: 0.0, 21: 0.3333333333333333, 22: 0.3333333333333333, 23: 0.0, 24: 0.6666666666666666, 25: 0.0, 26: 0.3333333333333333, 27: 0.6666666666666666, 28: 0.6666666666666666, 29: 0.3333333333333333, 30: 0.6666666666666666, 31: 0.0, 32: 0.5, 33: 0.5, 34: 0.0, 35: 0.5, 36: 0.3333333333333333, 37: 0.0, 38: 0.6666666666666666, 39: 0.5, 40: 0.5, 41: 0.5, 42: 0.0, 43: 0.3333333333333333, 44: 0.5, 45: 0.5, 46: 0.6666666666666666, 47: 1.0, 48: 0.6666666666666666, 49: 0.0, 50: 0.5, 51: 0.3333333333333333, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.5, 56: 0.0, 57: 0.0, 58: 1.0, 59: 0.3333333333333333, 60: 0.6666666666666666, 61: 0.0, 62: 0.5, 63: 1.0, 64: 0.0, 65: 0.3333333333333333, 66: 0.5, 67: 0.0, 68: 0.6666666666666666, 69: 1.0, 70: 0.5, 71: 0.6666666666666666, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.6666666666666666, 77: 0.5, 78: 0.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 1.0, 87: 1.0, 88: 0.3333333333333333, 89: 1.0, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.5, 94: 0.0, 95: 0.0, 96: 0.3333333333333333, 97: 1.0, 98: 1.0, 99: 0.5}

checkpoint_v_33  ->  0.42248062015503873
Label accuracies statistics:
{0: 1.0, 1: 0.25, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.3333333333333333, 6: 1.0, 7: 0.3333333333333333, 8: 0.3333333333333333, 9: 0.3333333333333333, 10: 0.3333333333333333, 11: 0.0, 12: 0.6666666666666666, 13: 0.6666666666666666, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 1.0, 17: 0.3333333333333333, 18: 0.0, 19: 0.6666666666666666, 20: 0.0, 21: 0.3333333333333333, 22: 0.3333333333333333, 23: 0.0, 24: 0.6666666666666666, 25: 0.6666666666666666, 26: 0.3333333333333333, 27: 0.6666666666666666, 28: 0.6666666666666666, 29: 0.3333333333333333, 30: 0.6666666666666666, 31: 0.3333333333333333, 32: 0.5, 33: 0.5, 34: 0.5, 35: 0.5, 36: 0.6666666666666666, 37: 0.0, 38: 0.6666666666666666, 39: 0.5, 40: 0.5, 41: 0.5, 42: 0.0, 43: 0.3333333333333333, 44: 0.5, 45: 0.5, 46: 0.6666666666666666, 47: 1.0, 48: 0.6666666666666666, 49: 0.0, 50: 0.5, 51: 0.3333333333333333, 52: 1.0, 53: 0.5, 54: 1.0, 55: 1.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 1.0, 59: 0.3333333333333333, 60: 0.6666666666666666, 61: 0.0, 62: 0.5, 63: 1.0, 64: 0.0, 65: 0.3333333333333333, 66: 0.5, 67: 0.0, 68: 0.3333333333333333, 69: 1.0, 70: 0.0, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.0, 76: 0.6666666666666666, 77: 1.0, 78: 0.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 0.6666666666666666, 87: 1.0, 88: 0.3333333333333333, 89: 1.0, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.5, 94: 0.5, 95: 0.0, 96: 0.3333333333333333, 97: 0.5, 98: 1.0, 99: 0.5}

checkpoint_t_34  ->  0.4573643410852713
Label accuracies statistics:
{0: 1.0, 1: 0.25, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.3333333333333333, 6: 1.0, 7: 0.3333333333333333, 8: 0.3333333333333333, 9: 0.3333333333333333, 10: 0.3333333333333333, 11: 0.0, 12: 0.6666666666666666, 13: 0.6666666666666666, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 1.0, 17: 0.3333333333333333, 18: 0.0, 19: 0.6666666666666666, 20: 0.0, 21: 0.3333333333333333, 22: 0.3333333333333333, 23: 0.0, 24: 0.6666666666666666, 25: 0.6666666666666666, 26: 0.3333333333333333, 27: 0.6666666666666666, 28: 0.6666666666666666, 29: 0.3333333333333333, 30: 0.6666666666666666, 31: 0.3333333333333333, 32: 0.5, 33: 0.5, 34: 0.5, 35: 0.5, 36: 0.6666666666666666, 37: 0.0, 38: 0.6666666666666666, 39: 0.5, 40: 0.5, 41: 0.5, 42: 0.0, 43: 0.3333333333333333, 44: 0.5, 45: 0.5, 46: 0.6666666666666666, 47: 1.0, 48: 0.6666666666666666, 49: 0.0, 50: 0.5, 51: 0.3333333333333333, 52: 1.0, 53: 0.5, 54: 1.0, 55: 1.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 1.0, 59: 0.3333333333333333, 60: 0.6666666666666666, 61: 0.0, 62: 0.5, 63: 1.0, 64: 0.0, 65: 0.3333333333333333, 66: 0.5, 67: 0.0, 68: 0.3333333333333333, 69: 1.0, 70: 0.0, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.0, 76: 0.6666666666666666, 77: 1.0, 78: 0.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 0.6666666666666666, 87: 1.0, 88: 0.3333333333333333, 89: 1.0, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.5, 94: 0.5, 95: 0.0, 96: 0.3333333333333333, 97: 0.5, 98: 1.0, 99: 0.5}

checkpoint_v_34  ->  0.4573643410852713
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 0.3333333333333333, 5: 0.3333333333333333, 6: 1.0, 7: 0.3333333333333333, 8: 0.3333333333333333, 9: 0.0, 10: 0.3333333333333333, 11: 0.3333333333333333, 12: 0.6666666666666666, 13: 0.0, 14: 0.3333333333333333, 15: 0.6666666666666666, 16: 1.0, 17: 0.0, 18: 0.0, 19: 0.6666666666666666, 20: 0.3333333333333333, 21: 0.3333333333333333, 22: 0.3333333333333333, 23: 0.0, 24: 0.6666666666666666, 25: 0.6666666666666666, 26: 0.3333333333333333, 27: 0.3333333333333333, 28: 0.6666666666666666, 29: 0.6666666666666666, 30: 0.6666666666666666, 31: 0.0, 32: 0.5, 33: 0.5, 34: 0.0, 35: 0.5, 36: 0.6666666666666666, 37: 0.5, 38: 0.6666666666666666, 39: 0.5, 40: 0.5, 41: 0.0, 42: 0.0, 43: 0.3333333333333333, 44: 0.5, 45: 0.5, 46: 0.3333333333333333, 47: 1.0, 48: 0.6666666666666666, 49: 0.0, 50: 0.5, 51: 0.3333333333333333, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.5, 56: 0.3333333333333333, 57: 0.0, 58: 1.0, 59: 0.6666666666666666, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.0, 66: 0.5, 67: 0.0, 68: 0.6666666666666666, 69: 0.5, 70: 0.0, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.0, 76: 0.0, 77: 0.5, 78: 0.0, 79: 1.0, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 1.0, 87: 1.0, 88: 0.3333333333333333, 89: 1.0, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.5, 94: 0.0, 95: 0.0, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.5}

checkpoint_t_35  ->  0.41472868217054265
Label accuracies statistics:
{0: 1.0, 1: 0.25, 2: 0.4, 3: 0.25, 4: 0.6666666666666666, 5: 0.3333333333333333, 6: 1.0, 7: 0.3333333333333333, 8: 0.3333333333333333, 9: 0.0, 10: 0.3333333333333333, 11: 0.0, 12: 1.0, 13: 0.6666666666666666, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 1.0, 17: 0.3333333333333333, 18: 0.0, 19: 0.6666666666666666, 20: 0.0, 21: 0.3333333333333333, 22: 0.3333333333333333, 23: 0.0, 24: 0.6666666666666666, 25: 0.6666666666666666, 26: 0.3333333333333333, 27: 0.6666666666666666, 28: 0.3333333333333333, 29: 0.3333333333333333, 30: 0.6666666666666666, 31: 0.3333333333333333, 32: 0.5, 33: 0.5, 34: 0.0, 35: 0.5, 36: 0.6666666666666666, 37: 0.5, 38: 0.6666666666666666, 39: 0.5, 40: 0.5, 41: 0.5, 42: 0.0, 43: 0.3333333333333333, 44: 0.5, 45: 0.0, 46: 0.6666666666666666, 47: 1.0, 48: 0.6666666666666666, 49: 0.0, 50: 0.5, 51: 0.3333333333333333, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 1.0, 59: 0.3333333333333333, 60: 0.6666666666666666, 61: 0.0, 62: 0.5, 63: 1.0, 64: 0.0, 65: 0.3333333333333333, 66: 0.5, 67: 0.0, 68: 0.6666666666666666, 69: 1.0, 70: 1.0, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.0, 76: 0.6666666666666666, 77: 1.0, 78: 0.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 1.0, 87: 1.0, 88: 0.6666666666666666, 89: 1.0, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.5, 94: 0.5, 95: 0.0, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.5}

checkpoint_v_35  ->  0.4496124031007752

The top result was recorded at 0.4689922480620155 testing accuracy. The best checkpoint is test_WLASL100_Spoter_noNorm_noAugm_SPOTERlandmarks/checkpoint_t_15.

Any desired statistics have been plotted.
The experiment is finished.

