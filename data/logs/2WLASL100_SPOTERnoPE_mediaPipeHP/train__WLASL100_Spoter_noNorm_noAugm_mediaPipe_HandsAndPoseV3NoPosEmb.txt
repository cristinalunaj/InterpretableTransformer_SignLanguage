(spoter) (base) cristinalunaj@ALV:/home/cristinalunaj/PycharmProjects/spoter$ py
thon3 train.py --experiment_name test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_Ha
ndsAndPoseV3NoPosEmb --epochs 350 --lr 0.001 --training_set_path /home/cristinal
unaj/PycharmProjects/spoter/data/WLASL100/own_data/x-y/WLASL100_train.csv --vali
dation_set_path /home/cristinalunaj/PycharmProjects/spoter/data/WLASL100/own_dat
a/x-y/WLASL100_val.csv --testing_set_path /home/cristinalunaj/PycharmProjects/sp
oter/data/WLASL100/own_data/x-y/WLASL100_test.csv --hidden_dim 150 --n_heads 10
Using model originalSpoter
Starting test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb...


... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_0.pth
[1] TRAIN  loss: 4.647416114972468 acc: 0.022191400832177532
[1] VALIDATION  acc: 0.020710059171597635

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_1.pth
[2] TRAIN  loss: 4.329036626174282 acc: 0.024965325936199722
[2] VALIDATION  acc: 0.047337278106508875

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_1.pth
[3] TRAIN  loss: 4.14225788486814 acc: 0.0478502080443828
[3] VALIDATION  acc: 0.06804733727810651

[4] TRAIN  loss: 3.9221808803726335 acc: 0.07142857142857142
[4] VALIDATION  acc: 0.0650887573964497

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_1.pth
[5] TRAIN  loss: 3.729774716905681 acc: 0.09778085991678225
[5] VALIDATION  acc: 0.08579881656804733

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_1.pth
[6] TRAIN  loss: 3.5804958532818807 acc: 0.09916782246879334
[6] VALIDATION  acc: 0.1301775147928994

[7] TRAIN  loss: 3.4595207408297903 acc: 0.10679611650485436
[7] VALIDATION  acc: 0.11834319526627218

[8] TRAIN  loss: 3.336687061558484 acc: 0.14563106796116504
[8] VALIDATION  acc: 0.11242603550295859

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_1.pth
[9] TRAIN  loss: 3.23315642470295 acc: 0.16435506241331485
[9] VALIDATION  acc: 0.13313609467455623

[10] TRAIN  loss: 3.1226230156653134 acc: 0.1754507628294036
[10] VALIDATION  acc: 0.1242603550295858

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_1.pth
[11] TRAIN  loss: 3.0162551727936435 acc: 0.18446601941747573
[11] VALIDATION  acc: 0.16568047337278108

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_2.pth
[12] TRAIN  loss: 2.9216267218950223 acc: 0.2087378640776699
[12] VALIDATION  acc: 0.16568047337278108

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_2.pth
[13] TRAIN  loss: 2.8039122930264178 acc: 0.23300970873786409
[13] VALIDATION  acc: 0.20414201183431951

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_2.pth
[14] TRAIN  loss: 2.7009157970775015 acc: 0.2669902912621359
[14] VALIDATION  acc: 0.23076923076923078

[15] TRAIN  loss: 2.590867950292963 acc: 0.3092926490984743
[15] VALIDATION  acc: 0.20118343195266272

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_2.pth
[16] TRAIN  loss: 2.5162892155607595 acc: 0.30721220527045767
[16] VALIDATION  acc: 0.2455621301775148

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_2.pth
[17] TRAIN  loss: 2.3972975054959895 acc: 0.3474341192787795
[17] VALIDATION  acc: 0.2869822485207101

[18] TRAIN  loss: 2.300384710972997 acc: 0.35852981969486825
[18] VALIDATION  acc: 0.26627218934911245

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_2.pth
[19] TRAIN  loss: 2.187195123089335 acc: 0.3710124826629681
[19] VALIDATION  acc: 0.3076923076923077

[20] TRAIN  loss: 2.1116631224896145 acc: 0.406380027739251
[20] VALIDATION  acc: 0.28994082840236685

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_2.pth
[21] TRAIN  loss: 2.008192730481102 acc: 0.4292649098474341
[21] VALIDATION  acc: 0.31952662721893493

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_3.pth
[22] TRAIN  loss: 1.9135302740010987 acc: 0.45145631067961167
[22] VALIDATION  acc: 0.30177514792899407

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_3.pth
[23] TRAIN  loss: 1.8601417178843538 acc: 0.4694868238557559
[23] VALIDATION  acc: 0.3698224852071006

[24] TRAIN  loss: 1.7620560781727965 acc: 0.4958391123439667
[24] VALIDATION  acc: 0.363905325443787

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_3.pth
[25] TRAIN  loss: 1.679929368352923 acc: 0.5110957004160888
[25] VALIDATION  acc: 0.3875739644970414

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_3.pth
[26] TRAIN  loss: 1.6288596794794568 acc: 0.5319001386962552
[26] VALIDATION  acc: 0.41124260355029585

[27] TRAIN  loss: 1.53849388224986 acc: 0.5533980582524272
[27] VALIDATION  acc: 0.3875739644970414

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_3.pth
[28] TRAIN  loss: 1.488790809591501 acc: 0.5700416088765603
[28] VALIDATION  acc: 0.4230769230769231

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_3.pth
[29] TRAIN  loss: 1.4100500281445485 acc: 0.5866851595006934
[29] VALIDATION  acc: 0.44970414201183434

[30] TRAIN  loss: 1.3750740449162568 acc: 0.5943134535367545
[30] VALIDATION  acc: 0.4260355029585799

[31] TRAIN  loss: 1.3008703484604247 acc: 0.6213592233009708
[31] VALIDATION  acc: 0.39349112426035504

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_4.pth
[32] TRAIN  loss: 1.2336062249571251 acc: 0.6262135922330098
[32] VALIDATION  acc: 0.4881656804733728

[33] TRAIN  loss: 1.1802160769220489 acc: 0.6532593619972261
[33] VALIDATION  acc: 0.33727810650887574

[34] TRAIN  loss: 1.1407848359653971 acc: 0.6490984743411928
[34] VALIDATION  acc: 0.47633136094674555

[35] TRAIN  loss: 1.090006248652806 acc: 0.6650485436893204
[35] VALIDATION  acc: 0.4230769230769231

[36] TRAIN  loss: 1.047148766892545 acc: 0.6837725381414702
[36] VALIDATION  acc: 0.4526627218934911

[37] TRAIN  loss: 0.9519190225309735 acc: 0.7149791955617198
[37] VALIDATION  acc: 0.3609467455621302

[38] TRAIN  loss: 0.9538102710306975 acc: 0.7080443828016644
[38] VALIDATION  acc: 0.39644970414201186

[39] TRAIN  loss: 0.9029868855987173 acc: 0.7135922330097088
[39] VALIDATION  acc: 0.4822485207100592

[40] TRAIN  loss: 0.8512494763644896 acc: 0.7482662968099861
[40] VALIDATION  acc: 0.4526627218934911

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_4.pth
[41] TRAIN  loss: 0.8251415778354493 acc: 0.7517337031900139
[41] VALIDATION  acc: 0.5

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_5.pth
[42] TRAIN  loss: 0.7967319750130479 acc: 0.7579750346740638
[42] VALIDATION  acc: 0.4822485207100592

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_5.pth
[43] TRAIN  loss: 0.7147157612441097 acc: 0.7884882108183079
[43] VALIDATION  acc: 0.5118343195266272

[44] TRAIN  loss: 0.7126902777216579 acc: 0.7766990291262136
[44] VALIDATION  acc: 0.5118343195266272

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_5.pth
[45] TRAIN  loss: 0.6501162906165071 acc: 0.8058252427184466
[45] VALIDATION  acc: 0.5177514792899408

[46] TRAIN  loss: 0.6340672905164824 acc: 0.8099861303744799
[46] VALIDATION  acc: 0.5118343195266272

[47] TRAIN  loss: 0.6282182361054023 acc: 0.8058252427184466
[47] VALIDATION  acc: 0.47337278106508873

[48] TRAIN  loss: 0.5598861991296085 acc: 0.8300970873786407
[48] VALIDATION  acc: 0.46449704142011833

[49] TRAIN  loss: 0.581971770014156 acc: 0.8238557558945908
[49] VALIDATION  acc: 0.5088757396449705

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_5.pth
[50] TRAIN  loss: 0.5399569900286282 acc: 0.8411927877947295
[50] VALIDATION  acc: 0.5621301775147929

[51] TRAIN  loss: 0.48834353121773866 acc: 0.8571428571428571
[51] VALIDATION  acc: 0.5295857988165681

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_6.pth
[52] TRAIN  loss: 0.5103736464195754 acc: 0.8474341192787794
[52] VALIDATION  acc: 0.4911242603550296

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_6.pth
[53] TRAIN  loss: 0.47244505247773844 acc: 0.863384188626907
[53] VALIDATION  acc: 0.5355029585798816

[54] TRAIN  loss: 0.4909876892596661 acc: 0.8578363384188626
[54] VALIDATION  acc: 0.5

[55] TRAIN  loss: 0.41855239285586915 acc: 0.8821081830790569
[55] VALIDATION  acc: 0.5207100591715976

[56] TRAIN  loss: 0.43002186884728016 acc: 0.8682385575589459
[56] VALIDATION  acc: 0.5295857988165681

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_6.pth
[57] TRAIN  loss: 0.3487367100257849 acc: 0.9070735090152566
[57] VALIDATION  acc: 0.5443786982248521

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_6.pth
[58] TRAIN  loss: 0.43219619053301317 acc: 0.871012482662968
[58] VALIDATION  acc: 0.5502958579881657

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_6.pth
[59] TRAIN  loss: 0.373459888875582 acc: 0.891123439667129
[59] VALIDATION  acc: 0.5710059171597633

[60] TRAIN  loss: 0.3325728178926874 acc: 0.9042995839112344
[60] VALIDATION  acc: 0.5384615384615384

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_6.pth
[61] TRAIN  loss: 0.2874165008302882 acc: 0.9167822468793343
[61] VALIDATION  acc: 0.5739644970414202

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_7.pth
[62] TRAIN  loss: 0.3044189586063628 acc: 0.912621359223301
[62] VALIDATION  acc: 0.5414201183431953

[63] TRAIN  loss: 0.2789599996733598 acc: 0.9223300970873787
[63] VALIDATION  acc: 0.5236686390532544

[64] TRAIN  loss: 0.31577837908126727 acc: 0.9056865464632455
[64] VALIDATION  acc: 0.47928994082840237

[65] TRAIN  loss: 0.3801664444846398 acc: 0.8862690707350902
[65] VALIDATION  acc: 0.4526627218934911

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_7.pth
[66] TRAIN  loss: 0.30525883576389007 acc: 0.9112343966712899
[66] VALIDATION  acc: 0.5680473372781065

[67] TRAIN  loss: 0.24032824066587552 acc: 0.9361997226074896
[67] VALIDATION  acc: 0.5650887573964497

[68] TRAIN  loss: 0.3088823952726247 acc: 0.9070735090152566
[68] VALIDATION  acc: 0.5562130177514792

[69] TRAIN  loss: 0.2885925745123761 acc: 0.9098474341192788
[69] VALIDATION  acc: 0.5680473372781065

[70] TRAIN  loss: 0.24935329819902044 acc: 0.9306518723994452
[70] VALIDATION  acc: 0.5532544378698225

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_7.pth
[71] TRAIN  loss: 0.16786123704671893 acc: 0.9611650485436893
[71] VALIDATION  acc: 0.5857988165680473

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_8.pth
[72] TRAIN  loss: 0.2133137919682843 acc: 0.941747572815534
[72] VALIDATION  acc: 0.5828402366863905

[73] TRAIN  loss: 0.2148129838073885 acc: 0.9361997226074896
[73] VALIDATION  acc: 0.5562130177514792

[74] TRAIN  loss: 0.1671787432550371 acc: 0.9576976421636616
[74] VALIDATION  acc: 0.5710059171597633

[75] TRAIN  loss: 0.1971272248438115 acc: 0.9500693481276006
[75] VALIDATION  acc: 0.5562130177514792

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_8.pth
[76] TRAIN  loss: 0.20006360994635283 acc: 0.9424410540915396
[76] VALIDATION  acc: 0.6124260355029586

[77] TRAIN  loss: 0.13224483853843497 acc: 0.9625520110957004
[77] VALIDATION  acc: 0.5828402366863905

[78] TRAIN  loss: 0.16105860705662134 acc: 0.9597780859916782
[78] VALIDATION  acc: 0.4970414201183432

[79] TRAIN  loss: 0.2529464505466766 acc: 0.9292649098474342
[79] VALIDATION  acc: 0.591715976331361

[80] TRAIN  loss: 0.1990807016163003 acc: 0.941747572815534
[80] VALIDATION  acc: 0.5325443786982249

[81] TRAIN  loss: 0.15772230467214457 acc: 0.9563106796116505
[81] VALIDATION  acc: 0.5887573964497042

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_9.pth
[82] TRAIN  loss: 0.0951906057523858 acc: 0.9778085991678225
[82] VALIDATION  acc: 0.5621301775147929

[83] TRAIN  loss: 0.13458387401570865 acc: 0.9618585298196949
[83] VALIDATION  acc: 0.5473372781065089

[84] TRAIN  loss: 0.1963811810114061 acc: 0.9438280166435506
[84] VALIDATION  acc: 0.5473372781065089

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_9.pth
[85] TRAIN  loss: 0.1076995788582114 acc: 0.9729542302357836
[85] VALIDATION  acc: 0.5650887573964497

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_9.pth
[86] TRAIN  loss: 0.05995149964023635 acc: 0.9895977808599168
[86] VALIDATION  acc: 0.591715976331361

[87] TRAIN  loss: 0.1457781654623814 acc: 0.9639389736477115
[87] VALIDATION  acc: 0.5088757396449705

[88] TRAIN  loss: 0.16546848047159862 acc: 0.955617198335645
[88] VALIDATION  acc: 0.5384615384615384

[89] TRAIN  loss: 0.1529802818514073 acc: 0.9625520110957004
[89] VALIDATION  acc: 0.5739644970414202

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_9.pth
[90] TRAIN  loss: 0.1588281866779161 acc: 0.9625520110957004
[90] VALIDATION  acc: 0.5976331360946746

[91] TRAIN  loss: 0.19296028145641247 acc: 0.9452149791955617
[91] VALIDATION  acc: 0.5384615384615384

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_10.pth
[92] TRAIN  loss: 0.2069743404279509 acc: 0.941747572815534
[92] VALIDATION  acc: 0.5414201183431953

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_10.pth
[93] TRAIN  loss: 0.1842707877099674 acc: 0.9459084604715673
[93] VALIDATION  acc: 0.5976331360946746

[94] TRAIN  loss: 0.14333352523225107 acc: 0.9667128987517337
[94] VALIDATION  acc: 0.5769230769230769

[95] TRAIN  loss: 0.0748994751547306 acc: 0.984743411927878
[95] VALIDATION  acc: 0.5857988165680473

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_10.pth
[96] TRAIN  loss: 0.05743210876110913 acc: 0.9875173370319001
[96] VALIDATION  acc: 0.6094674556213018

[97] TRAIN  loss: 0.05069897237968316 acc: 0.9882108183079057
[97] VALIDATION  acc: 0.606508875739645

[98] TRAIN  loss: 0.04275342473718993 acc: 0.9902912621359223
[98] VALIDATION  acc: 0.5946745562130178

[99] TRAIN  loss: 0.1464876351802482 acc: 0.9563106796116505
[99] VALIDATION  acc: 0.5857988165680473

[100] TRAIN  loss: 0.12356023604561553 acc: 0.9660194174757282
[100] VALIDATION  acc: 0.5857988165680473

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_10.pth
[101] TRAIN  loss: 0.06580929693799603 acc: 0.986130374479889
[101] VALIDATION  acc: 0.6242603550295858

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_11.pth
[102] TRAIN  loss: 0.042480328663556007 acc: 0.9916782246879334
[102] VALIDATION  acc: 0.6272189349112426

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_11.pth
[103] TRAIN  loss: 0.04768060486398081 acc: 0.9916782246879334
[103] VALIDATION  acc: 0.6301775147928994

[104] TRAIN  loss: 0.04842509148195086 acc: 0.9868238557558946
[104] VALIDATION  acc: 0.5946745562130178

[105] TRAIN  loss: 0.034558326761161905 acc: 0.9937586685159501
[105] VALIDATION  acc: 0.621301775147929

[106] TRAIN  loss: 0.04509082035332383 acc: 0.9909847434119279
[106] VALIDATION  acc: 0.5976331360946746

[107] TRAIN  loss: 0.030283110885748973 acc: 0.992371705963939
[107] VALIDATION  acc: 0.6124260355029586

[108] TRAIN  loss: 0.020319815754504787 acc: 0.9958391123439667
[108] VALIDATION  acc: 0.6124260355029586

[109] TRAIN  loss: 0.030365739342246827 acc: 0.9937586685159501
[109] VALIDATION  acc: 0.606508875739645

[110] TRAIN  loss: 0.043177664317710154 acc: 0.9875173370319001
[110] VALIDATION  acc: 0.5857988165680473

[111] TRAIN  loss: 0.030647355236282044 acc: 0.9951456310679612
[111] VALIDATION  acc: 0.6124260355029586

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_12.pth
[112] TRAIN  loss: 0.02462297854447352 acc: 0.9944521497919556
[112] VALIDATION  acc: 0.6301775147928994

[113] TRAIN  loss: 0.02806377918864547 acc: 0.9930651872399445
[113] VALIDATION  acc: 0.6242603550295858

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_12.pth
[114] TRAIN  loss: 0.01751080755567473 acc: 0.9958391123439667
[114] VALIDATION  acc: 0.6331360946745562

[115] TRAIN  loss: 0.01672356851028103 acc: 0.9958391123439667
[115] VALIDATION  acc: 0.6272189349112426

[116] TRAIN  loss: 0.01929249602670125 acc: 0.9958391123439667
[116] VALIDATION  acc: 0.6242603550295858

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_12.pth
[117] TRAIN  loss: 0.014129516125766703 acc: 0.9965325936199723
[117] VALIDATION  acc: 0.636094674556213

[118] TRAIN  loss: 0.015130339577937293 acc: 0.9958391123439667
[118] VALIDATION  acc: 0.6242603550295858

[119] TRAIN  loss: 0.014031662205283013 acc: 0.9965325936199723
[119] VALIDATION  acc: 0.6272189349112426

[120] TRAIN  loss: 0.01574732973019918 acc: 0.9958391123439667
[120] VALIDATION  acc: 0.6301775147928994

[121] TRAIN  loss: 0.016443658389624628 acc: 0.9958391123439667
[121] VALIDATION  acc: 0.6331360946745562

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_13.pth
[122] TRAIN  loss: 0.01570583514224327 acc: 0.9944521497919556
[122] VALIDATION  acc: 0.6301775147928994

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_13.pth
[123] TRAIN  loss: 0.013745913573569569 acc: 0.9965325936199723
[123] VALIDATION  acc: 0.6420118343195266

[124] TRAIN  loss: 0.012779011449472391 acc: 0.9958391123439667
[124] VALIDATION  acc: 0.6390532544378699

[125] TRAIN  loss: 0.014719004721962282 acc: 0.9965325936199723
[125] VALIDATION  acc: 0.6390532544378699

[126] TRAIN  loss: 0.013805588768068465 acc: 0.9965325936199723
[126] VALIDATION  acc: 0.6301775147928994

[127] TRAIN  loss: 0.013092964555619393 acc: 0.9958391123439667
[127] VALIDATION  acc: 0.6331360946745562

[128] TRAIN  loss: 0.01300493816652735 acc: 0.9958391123439667
[128] VALIDATION  acc: 0.6331360946745562

[129] TRAIN  loss: 0.012767933479240766 acc: 0.9951456310679612
[129] VALIDATION  acc: 0.6242603550295858

[130] TRAIN  loss: 0.01403384003257421 acc: 0.9951456310679612
[130] VALIDATION  acc: 0.6301775147928994

[131] TRAIN  loss: 0.012180135222160151 acc: 0.9958391123439667
[131] VALIDATION  acc: 0.6272189349112426

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_14.pth
[132] TRAIN  loss: 0.011121648822436946 acc: 0.9958391123439667
[132] VALIDATION  acc: 0.6183431952662722

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_14.pth
[133] TRAIN  loss: 0.012504930406094458 acc: 0.9965325936199723
[133] VALIDATION  acc: 0.636094674556213

[134] TRAIN  loss: 0.012325257582199402 acc: 0.9944521497919556
[134] VALIDATION  acc: 0.6331360946745562

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_14.pth
[135] TRAIN  loss: 0.012212608986321127 acc: 0.9965325936199723
[135] VALIDATION  acc: 0.6390532544378699

[136] TRAIN  loss: 0.012471146102891425 acc: 0.9951456310679612
[136] VALIDATION  acc: 0.6390532544378699

[137] TRAIN  loss: 0.011595016787746841 acc: 0.9965325936199723
[137] VALIDATION  acc: 0.636094674556213

[138] TRAIN  loss: 0.012661163716762434 acc: 0.9951456310679612
[138] VALIDATION  acc: 0.6390532544378699

[139] TRAIN  loss: 0.011956838858425672 acc: 0.9965325936199723
[139] VALIDATION  acc: 0.6301775147928994

[140] TRAIN  loss: 0.011956113181978112 acc: 0.9958391123439667
[140] VALIDATION  acc: 0.621301775147929

[141] TRAIN  loss: 0.012207063574556809 acc: 0.9958391123439667
[141] VALIDATION  acc: 0.6331360946745562

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_15.pth
[142] TRAIN  loss: 0.011586592485955647 acc: 0.9958391123439667
[142] VALIDATION  acc: 0.6331360946745562

[143] TRAIN  loss: 0.0111210563135174 acc: 0.9958391123439667
[143] VALIDATION  acc: 0.6331360946745562

[144] TRAIN  loss: 0.011452576983026779 acc: 0.9958391123439667
[144] VALIDATION  acc: 0.6331360946745562

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_15.pth
[145] TRAIN  loss: 0.011861662199840547 acc: 0.9944521497919556
[145] VALIDATION  acc: 0.6420118343195266

[146] TRAIN  loss: 0.011642758445216634 acc: 0.9951456310679612
[146] VALIDATION  acc: 0.6331360946745562

[147] TRAIN  loss: 0.012395964630346389 acc: 0.9951456310679612
[147] VALIDATION  acc: 0.6420118343195266

[148] TRAIN  loss: 0.010890433906509955 acc: 0.9965325936199723
[148] VALIDATION  acc: 0.6390532544378699

[149] TRAIN  loss: 0.012594919363110219 acc: 0.9951456310679612
[149] VALIDATION  acc: 0.6331360946745562

[150] TRAIN  loss: 0.008953758804745374 acc: 0.9965325936199723
[150] VALIDATION  acc: 0.6331360946745562

[151] TRAIN  loss: 0.011340303560867845 acc: 0.9944521497919556
[151] VALIDATION  acc: 0.636094674556213

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_16.pth
[152] TRAIN  loss: 0.011061862210048673 acc: 0.9951456310679612
[152] VALIDATION  acc: 0.6301775147928994

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_16.pth
[153] TRAIN  loss: 0.010735034426997699 acc: 0.9965325936199723
[153] VALIDATION  acc: 0.6331360946745562

[154] TRAIN  loss: 0.01087607627930579 acc: 0.9951456310679612
[154] VALIDATION  acc: 0.6331360946745562

[155] TRAIN  loss: 0.010517254401764176 acc: 0.9965325936199723
[155] VALIDATION  acc: 0.6272189349112426

[156] TRAIN  loss: 0.01040211458875522 acc: 0.9958391123439667
[156] VALIDATION  acc: 0.6301775147928994

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_16.pth
[157] TRAIN  loss: 0.010499653838139621 acc: 0.9958391123439667
[157] VALIDATION  acc: 0.6420118343195266

[158] TRAIN  loss: 0.01145151478839291 acc: 0.9944521497919556
[158] VALIDATION  acc: 0.6301775147928994

[159] TRAIN  loss: 0.010828976187497041 acc: 0.9958391123439667
[159] VALIDATION  acc: 0.6272189349112426

[160] TRAIN  loss: 0.009563728743238235 acc: 0.9972260748959778
[160] VALIDATION  acc: 0.6272189349112426

[161] TRAIN  loss: 0.01164245225916554 acc: 0.9951456310679612
[161] VALIDATION  acc: 0.6331360946745562

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_17.pth
[162] TRAIN  loss: 0.010736066808233781 acc: 0.9965325936199723
[162] VALIDATION  acc: 0.636094674556213

[163] TRAIN  loss: 0.010390030739529188 acc: 0.9951456310679612
[163] VALIDATION  acc: 0.636094674556213

[164] TRAIN  loss: 0.010985281052707354 acc: 0.9951456310679612
[164] VALIDATION  acc: 0.6301775147928994

[165] TRAIN  loss: 0.010301283119877202 acc: 0.9958391123439667
[165] VALIDATION  acc: 0.6301775147928994

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_17.pth
[166] TRAIN  loss: 0.010108962968145542 acc: 0.9958391123439667
[166] VALIDATION  acc: 0.6390532544378699

[167] TRAIN  loss: 0.009781398492569664 acc: 0.9965325936199723
[167] VALIDATION  acc: 0.6301775147928994

[168] TRAIN  loss: 0.009609750486954664 acc: 0.9965325936199723
[168] VALIDATION  acc: 0.6242603550295858

[169] TRAIN  loss: 0.009411086131036684 acc: 0.9965325936199723
[169] VALIDATION  acc: 0.6301775147928994

[170] TRAIN  loss: 0.01048698093796606 acc: 0.9951456310679612
[170] VALIDATION  acc: 0.6331360946745562

[171] TRAIN  loss: 0.009709772050336546 acc: 0.9958391123439667
[171] VALIDATION  acc: 0.6242603550295858

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_18.pth
[172] TRAIN  loss: 0.009846967278043068 acc: 0.9951456310679612
[172] VALIDATION  acc: 0.6301775147928994

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_18.pth
[173] TRAIN  loss: 0.00926739974584582 acc: 0.9965325936199723
[173] VALIDATION  acc: 0.636094674556213

[174] TRAIN  loss: 0.00984825746409733 acc: 0.9951456310679612
[174] VALIDATION  acc: 0.6331360946745562

[175] TRAIN  loss: 0.008271626940649753 acc: 0.9972260748959778
[175] VALIDATION  acc: 0.636094674556213

[176] TRAIN  loss: 0.00935468747948372 acc: 0.9958391123439667
[176] VALIDATION  acc: 0.6301775147928994

[177] TRAIN  loss: 0.0090240404471474 acc: 0.9958391123439667
[177] VALIDATION  acc: 0.636094674556213

[178] TRAIN  loss: 0.010503931764211761 acc: 0.9951456310679612
[178] VALIDATION  acc: 0.636094674556213

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_18.pth
[179] TRAIN  loss: 0.009257292008758784 acc: 0.9951456310679612
[179] VALIDATION  acc: 0.6390532544378699

[180] TRAIN  loss: 0.008958479839981544 acc: 0.9965325936199723
[180] VALIDATION  acc: 0.6331360946745562

[181] TRAIN  loss: 0.007602802278288613 acc: 0.9972260748959778
[181] VALIDATION  acc: 0.6331360946745562

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_19.pth
[182] TRAIN  loss: 0.009756665897341145 acc: 0.9972260748959778
[182] VALIDATION  acc: 0.6301775147928994

[183] TRAIN  loss: 0.009918440943482326 acc: 0.9958391123439667
[183] VALIDATION  acc: 0.6242603550295858

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_19.pth
[184] TRAIN  loss: 0.008463845682122667 acc: 0.9965325936199723
[184] VALIDATION  acc: 0.6331360946745562

[185] TRAIN  loss: 0.009473424595295876 acc: 0.9958391123439667
[185] VALIDATION  acc: 0.6331360946745562

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_19.pth
[186] TRAIN  loss: 0.009946958764296404 acc: 0.9951456310679612
[186] VALIDATION  acc: 0.636094674556213

[187] TRAIN  loss: 0.008823550576591172 acc: 0.9972260748959778
[187] VALIDATION  acc: 0.6331360946745562

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_19.pth
[188] TRAIN  loss: 0.008622376646732863 acc: 0.9951456310679612
[188] VALIDATION  acc: 0.650887573964497

[189] TRAIN  loss: 0.009079652085907412 acc: 0.9958391123439667
[189] VALIDATION  acc: 0.636094674556213

[190] TRAIN  loss: 0.00939951098884643 acc: 0.9965325936199723
[190] VALIDATION  acc: 0.6420118343195266

[191] TRAIN  loss: 0.008447975875386067 acc: 0.9958391123439667
[191] VALIDATION  acc: 0.6420118343195266

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_20.pth
[192] TRAIN  loss: 0.009632702010509375 acc: 0.9958391123439667
[192] VALIDATION  acc: 0.6331360946745562

[193] TRAIN  loss: 0.008002446056003532 acc: 0.9965325936199723
[193] VALIDATION  acc: 0.6301775147928994

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_20.pth
[194] TRAIN  loss: 0.00927529751507777 acc: 0.9965325936199723
[194] VALIDATION  acc: 0.6420118343195266

[195] TRAIN  loss: 0.00929380784972398 acc: 0.9951456310679612
[195] VALIDATION  acc: 0.6390532544378699

[196] TRAIN  loss: 0.009737134106627094 acc: 0.9951456310679612
[196] VALIDATION  acc: 0.6331360946745562

[197] TRAIN  loss: 0.009480134484754888 acc: 0.9958391123439667
[197] VALIDATION  acc: 0.6390532544378699

[198] TRAIN  loss: 0.008767755971055726 acc: 0.9965325936199723
[198] VALIDATION  acc: 0.6331360946745562

[199] TRAIN  loss: 0.009824591744229146 acc: 0.9958391123439667
[199] VALIDATION  acc: 0.6390532544378699

[200] TRAIN  loss: 0.009539304701888008 acc: 0.9951456310679612
[200] VALIDATION  acc: 0.636094674556213

[201] TRAIN  loss: 0.008863935771255512 acc: 0.9965325936199723
[201] VALIDATION  acc: 0.6331360946745562

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_21.pth
[202] TRAIN  loss: 0.008530239515944364 acc: 0.9958391123439667
[202] VALIDATION  acc: 0.6390532544378699

[203] TRAIN  loss: 0.007920800105848596 acc: 0.9944521497919556
[203] VALIDATION  acc: 0.6331360946745562

[204] TRAIN  loss: 0.00786432387284096 acc: 0.9972260748959778
[204] VALIDATION  acc: 0.6301775147928994

[205] TRAIN  loss: 0.008897233316479155 acc: 0.9958391123439667
[205] VALIDATION  acc: 0.6301775147928994

[206] TRAIN  loss: 0.008955278207033136 acc: 0.9951456310679612
[206] VALIDATION  acc: 0.636094674556213

[207] TRAIN  loss: 0.00907884312990356 acc: 0.9958391123439667
[207] VALIDATION  acc: 0.6390532544378699

[208] TRAIN  loss: 0.008773243283342325 acc: 0.9958391123439667
[208] VALIDATION  acc: 0.636094674556213

[209] TRAIN  loss: 0.009355204374613261 acc: 0.9944521497919556
[209] VALIDATION  acc: 0.636094674556213

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_21.pth
[210] TRAIN  loss: 0.007941384155901624 acc: 0.9951456310679612
[210] VALIDATION  acc: 0.6420118343195266

[211] TRAIN  loss: 0.00784335621261592 acc: 0.9965325936199723
[211] VALIDATION  acc: 0.6331360946745562

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_22.pth
[212] TRAIN  loss: 0.008490920773171554 acc: 0.9965325936199723
[212] VALIDATION  acc: 0.6390532544378699

[213] TRAIN  loss: 0.007549414527254337 acc: 0.9958391123439667
[213] VALIDATION  acc: 0.6331360946745562

[214] TRAIN  loss: 0.008164121914741475 acc: 0.9972260748959778
[214] VALIDATION  acc: 0.6331360946745562

[215] TRAIN  loss: 0.007584303548527375 acc: 0.9951456310679612
[215] VALIDATION  acc: 0.6390532544378699

[216] TRAIN  loss: 0.009207066045278623 acc: 0.9944521497919556
[216] VALIDATION  acc: 0.6331360946745562

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_22.pth
[217] TRAIN  loss: 0.008037200658707689 acc: 0.9965325936199723
[217] VALIDATION  acc: 0.6420118343195266

[218] TRAIN  loss: 0.009783280570767307 acc: 0.9958391123439667
[218] VALIDATION  acc: 0.6301775147928994

[219] TRAIN  loss: 0.008712052458539248 acc: 0.9951456310679612
[219] VALIDATION  acc: 0.636094674556213

[220] TRAIN  loss: 0.007370442028276533 acc: 0.9951456310679612
[220] VALIDATION  acc: 0.6390532544378699

[221] TRAIN  loss: 0.008565557044750522 acc: 0.9944521497919556
[221] VALIDATION  acc: 0.6331360946745562

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_23.pth
[222] TRAIN  loss: 0.009129132903153567 acc: 0.9958391123439667
[222] VALIDATION  acc: 0.6331360946745562

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_23.pth
[223] TRAIN  loss: 0.007482455238256715 acc: 0.9965325936199723
[223] VALIDATION  acc: 0.636094674556213

[224] TRAIN  loss: 0.00834293450275311 acc: 0.9958391123439667
[224] VALIDATION  acc: 0.636094674556213

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_23.pth
[225] TRAIN  loss: 0.006864643102154243 acc: 0.9972260748959778
[225] VALIDATION  acc: 0.6390532544378699

[226] TRAIN  loss: 0.007975136923696596 acc: 0.9965325936199723
[226] VALIDATION  acc: 0.6331360946745562

[227] TRAIN  loss: 0.008257788087699666 acc: 0.9965325936199723
[227] VALIDATION  acc: 0.6331360946745562

[228] TRAIN  loss: 0.007952741395899306 acc: 0.9951456310679612
[228] VALIDATION  acc: 0.6331360946745562

[229] TRAIN  loss: 0.00865790428002172 acc: 0.9958391123439667
[229] VALIDATION  acc: 0.6301775147928994

[230] TRAIN  loss: 0.008194769534573465 acc: 0.9958391123439667
[230] VALIDATION  acc: 0.6301775147928994

[231] TRAIN  loss: 0.007720616812837411 acc: 0.9958391123439667
[231] VALIDATION  acc: 0.6331360946745562

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_24.pth
[232] TRAIN  loss: 0.008209488355753563 acc: 0.9958391123439667
[232] VALIDATION  acc: 0.6301775147928994

[233] TRAIN  loss: 0.0075462889048677284 acc: 0.9958391123439667
[233] VALIDATION  acc: 0.621301775147929

[234] TRAIN  loss: 0.007469170300894509 acc: 0.9972260748959778
[234] VALIDATION  acc: 0.6301775147928994

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_24.pth
[235] TRAIN  loss: 0.008093594703555198 acc: 0.9958391123439667
[235] VALIDATION  acc: 0.636094674556213

[236] TRAIN  loss: 0.008145171348625453 acc: 0.9958391123439667
[236] VALIDATION  acc: 0.636094674556213

[237] TRAIN  loss: 0.008554471279601837 acc: 0.9951456310679612
[237] VALIDATION  acc: 0.636094674556213

[238] TRAIN  loss: 0.006738954555702134 acc: 0.9972260748959778
[238] VALIDATION  acc: 0.636094674556213

[239] TRAIN  loss: 0.006632516931894165 acc: 0.9979195561719834
[239] VALIDATION  acc: 0.6301775147928994

[240] TRAIN  loss: 0.007487424019635204 acc: 0.9958391123439667
[240] VALIDATION  acc: 0.6242603550295858

[241] TRAIN  loss: 0.00641420778650698 acc: 0.9972260748959778
[241] VALIDATION  acc: 0.6301775147928994

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_25.pth
[242] TRAIN  loss: 0.00828546560733129 acc: 0.9958391123439667
[242] VALIDATION  acc: 0.6301775147928994

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_25.pth
[243] TRAIN  loss: 0.007230931522315841 acc: 0.9972260748959778
[243] VALIDATION  acc: 0.6479289940828402

[244] TRAIN  loss: 0.007270586348511267 acc: 0.9965325936199723
[244] VALIDATION  acc: 0.6390532544378699

[245] TRAIN  loss: 0.00854302703931387 acc: 0.9944521497919556
[245] VALIDATION  acc: 0.6420118343195266

[246] TRAIN  loss: 0.008679800343593147 acc: 0.9958391123439667
[246] VALIDATION  acc: 0.6390532544378699

[247] TRAIN  loss: 0.009160796202013696 acc: 0.9944521497919556
[247] VALIDATION  acc: 0.6331360946745562

[248] TRAIN  loss: 0.008025916782185586 acc: 0.9958391123439667
[248] VALIDATION  acc: 0.6331360946745562

[249] TRAIN  loss: 0.007867575500082408 acc: 0.9958391123439667
[249] VALIDATION  acc: 0.6390532544378699

[250] TRAIN  loss: 0.007293272514258854 acc: 0.9958391123439667
[250] VALIDATION  acc: 0.6390532544378699

[251] TRAIN  loss: 0.00791876172211352 acc: 0.9951456310679612
[251] VALIDATION  acc: 0.6331360946745562

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_26.pth
[252] TRAIN  loss: 0.0077784425891009755 acc: 0.9965325936199723
[252] VALIDATION  acc: 0.6301775147928994

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_26.pth
[253] TRAIN  loss: 0.006990276862638584 acc: 0.9951456310679612
[253] VALIDATION  acc: 0.6331360946745562

[254] TRAIN  loss: 0.007972004321590313 acc: 0.9951456310679612
[254] VALIDATION  acc: 0.6331360946745562

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_26.pth
[255] TRAIN  loss: 0.007458706424618923 acc: 0.9965325936199723
[255] VALIDATION  acc: 0.636094674556213

[256] TRAIN  loss: 0.008017427949704298 acc: 0.9972260748959778
[256] VALIDATION  acc: 0.6331360946745562

[257] TRAIN  loss: 0.007713635480443709 acc: 0.9958391123439667
[257] VALIDATION  acc: 0.6242603550295858

[258] TRAIN  loss: 0.007685874086085488 acc: 0.9965325936199723
[258] VALIDATION  acc: 0.6301775147928994

[259] TRAIN  loss: 0.007680119577672131 acc: 0.9944521497919556
[259] VALIDATION  acc: 0.6331360946745562

[260] TRAIN  loss: 0.0075375588670777306 acc: 0.9958391123439667
[260] VALIDATION  acc: 0.636094674556213

[261] TRAIN  loss: 0.006684286421647021 acc: 0.9965325936199723
[261] VALIDATION  acc: 0.6301775147928994

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_27.pth
[262] TRAIN  loss: 0.006426896646783697 acc: 0.9972260748959778
[262] VALIDATION  acc: 0.6242603550295858

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_27.pth
[263] TRAIN  loss: 0.008171582157779836 acc: 0.9951456310679612
[263] VALIDATION  acc: 0.6331360946745562

[264] TRAIN  loss: 0.007259381127152157 acc: 0.9958391123439667
[264] VALIDATION  acc: 0.6301775147928994

[265] TRAIN  loss: 0.007156396965475776 acc: 0.9958391123439667
[265] VALIDATION  acc: 0.6331360946745562

[266] TRAIN  loss: 0.008113784987796361 acc: 0.9965325936199723
[266] VALIDATION  acc: 0.6301775147928994

[267] TRAIN  loss: 0.0071103526979023075 acc: 0.9951456310679612
[267] VALIDATION  acc: 0.6331360946745562

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_27.pth
[268] TRAIN  loss: 0.007042348955222624 acc: 0.9965325936199723
[268] VALIDATION  acc: 0.636094674556213

[269] TRAIN  loss: 0.0070386203641723665 acc: 0.9965325936199723
[269] VALIDATION  acc: 0.6331360946745562

[270] TRAIN  loss: 0.007317455810015254 acc: 0.9965325936199723
[270] VALIDATION  acc: 0.6301775147928994

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_27.pth
[271] TRAIN  loss: 0.006608600390583116 acc: 0.9958391123439667
[271] VALIDATION  acc: 0.6390532544378699

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_28.pth
[272] TRAIN  loss: 0.005930364002526956 acc: 0.9958391123439667
[272] VALIDATION  acc: 0.6390532544378699

[273] TRAIN  loss: 0.007444016732316336 acc: 0.9958391123439667
[273] VALIDATION  acc: 0.6331360946745562

[274] TRAIN  loss: 0.00746922264425216 acc: 0.9951456310679612
[274] VALIDATION  acc: 0.636094674556213

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_28.pth
[275] TRAIN  loss: 0.007370316538521145 acc: 0.9951456310679612
[275] VALIDATION  acc: 0.6420118343195266

[276] TRAIN  loss: 0.007616384407765572 acc: 0.9958391123439667
[276] VALIDATION  acc: 0.6331360946745562

[277] TRAIN  loss: 0.007929368852470694 acc: 0.9958391123439667
[277] VALIDATION  acc: 0.6331360946745562

[278] TRAIN  loss: 0.006687492706896718 acc: 0.9965325936199723
[278] VALIDATION  acc: 0.6331360946745562

[279] TRAIN  loss: 0.006805505481142203 acc: 0.9972260748959778
[279] VALIDATION  acc: 0.6331360946745562

[280] TRAIN  loss: 0.007059133972924758 acc: 0.9965325936199723
[280] VALIDATION  acc: 0.6301775147928994

[281] TRAIN  loss: 0.006884123432706946 acc: 0.9958391123439667
[281] VALIDATION  acc: 0.6301775147928994

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_29.pth
[282] TRAIN  loss: 0.006718650301862481 acc: 0.9972260748959778
[282] VALIDATION  acc: 0.6390532544378699

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_29.pth
[283] TRAIN  loss: 0.007304217972701842 acc: 0.9951456310679612
[283] VALIDATION  acc: 0.6449704142011834

[284] TRAIN  loss: 0.00776930921990057 acc: 0.9958391123439667
[284] VALIDATION  acc: 0.6301775147928994

[285] TRAIN  loss: 0.007192615321309985 acc: 0.9965325936199723
[285] VALIDATION  acc: 0.6331360946745562

[286] TRAIN  loss: 0.007197419015655506 acc: 0.9958391123439667
[286] VALIDATION  acc: 0.636094674556213

[287] TRAIN  loss: 0.006887633977622271 acc: 0.9958391123439667
[287] VALIDATION  acc: 0.6390532544378699

[288] TRAIN  loss: 0.006520204784951937 acc: 0.9951456310679612
[288] VALIDATION  acc: 0.6331360946745562

[289] TRAIN  loss: 0.007282237570753257 acc: 0.9944521497919556
[289] VALIDATION  acc: 0.6331360946745562

[290] TRAIN  loss: 0.007061852425260627 acc: 0.9965325936199723
[290] VALIDATION  acc: 0.6301775147928994

[291] TRAIN  loss: 0.0075380529366527995 acc: 0.9958391123439667
[291] VALIDATION  acc: 0.6301775147928994

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_30.pth
[292] TRAIN  loss: 0.007449736973969024 acc: 0.9972260748959778
[292] VALIDATION  acc: 0.636094674556213

[293] TRAIN  loss: 0.007660332271750554 acc: 0.9958391123439667
[293] VALIDATION  acc: 0.6301775147928994

[294] TRAIN  loss: 0.006180256568574266 acc: 0.9972260748959778
[294] VALIDATION  acc: 0.6301775147928994

[295] TRAIN  loss: 0.006278159310047326 acc: 0.9979195561719834
[295] VALIDATION  acc: 0.6272189349112426

[296] TRAIN  loss: 0.0073004051498328955 acc: 0.9972260748959778
[296] VALIDATION  acc: 0.6331360946745562

[297] TRAIN  loss: 0.00672933906023196 acc: 0.9965325936199723
[297] VALIDATION  acc: 0.6331360946745562

[298] TRAIN  loss: 0.0069470294287543545 acc: 0.9965325936199723
[298] VALIDATION  acc: 0.6331360946745562

[299] TRAIN  loss: 0.006875419924100355 acc: 0.9965325936199723
[299] VALIDATION  acc: 0.6331360946745562

[300] TRAIN  loss: 0.007287033159742545 acc: 0.9944521497919556
[300] VALIDATION  acc: 0.6272189349112426

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_30.pth
[301] TRAIN  loss: 0.007130646316696223 acc: 0.9958391123439667
[301] VALIDATION  acc: 0.6390532544378699

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_31.pth
[302] TRAIN  loss: 0.007343921402798704 acc: 0.9951456310679612
[302] VALIDATION  acc: 0.636094674556213

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_31.pth
[303] TRAIN  loss: 0.00732671098470514 acc: 0.9951456310679612
[303] VALIDATION  acc: 0.6390532544378699

[304] TRAIN  loss: 0.006940574428669598 acc: 0.9958391123439667
[304] VALIDATION  acc: 0.6331360946745562

[305] TRAIN  loss: 0.00767473930671576 acc: 0.9944521497919556
[305] VALIDATION  acc: 0.6331360946745562

[306] TRAIN  loss: 0.0076619696368205965 acc: 0.9951456310679612
[306] VALIDATION  acc: 0.636094674556213

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_31.pth
[307] TRAIN  loss: 0.006623505973031277 acc: 0.9951456310679612
[307] VALIDATION  acc: 0.6420118343195266

[308] TRAIN  loss: 0.007069713835076684 acc: 0.9951456310679612
[308] VALIDATION  acc: 0.6331360946745562

[309] TRAIN  loss: 0.00798217519024923 acc: 0.9951456310679612
[309] VALIDATION  acc: 0.6390532544378699

[310] TRAIN  loss: 0.006709221043004286 acc: 0.9958391123439667
[310] VALIDATION  acc: 0.636094674556213

[311] TRAIN  loss: 0.006111919142967812 acc: 0.9965325936199723
[311] VALIDATION  acc: 0.6390532544378699

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_32.pth
[312] TRAIN  loss: 0.008065189992066103 acc: 0.9951456310679612
[312] VALIDATION  acc: 0.636094674556213

[313] TRAIN  loss: 0.007403887827796942 acc: 0.9951456310679612
[313] VALIDATION  acc: 0.6331360946745562

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_32.pth
[314] TRAIN  loss: 0.00713162249779993 acc: 0.9958391123439667
[314] VALIDATION  acc: 0.6420118343195266

[315] TRAIN  loss: 0.005970550058598484 acc: 0.9958391123439667
[315] VALIDATION  acc: 0.636094674556213

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_32.pth
[316] TRAIN  loss: 0.005825497038447909 acc: 0.9972260748959778
[316] VALIDATION  acc: 0.6479289940828402

[317] TRAIN  loss: 0.007191767775746159 acc: 0.9958391123439667
[317] VALIDATION  acc: 0.636094674556213

[318] TRAIN  loss: 0.007266321196394389 acc: 0.9944521497919556
[318] VALIDATION  acc: 0.6449704142011834

[319] TRAIN  loss: 0.006697890414877082 acc: 0.9951456310679612
[319] VALIDATION  acc: 0.6301775147928994

[320] TRAIN  loss: 0.007638329545917711 acc: 0.9951456310679612
[320] VALIDATION  acc: 0.6272189349112426

[321] TRAIN  loss: 0.006767359593680904 acc: 0.9951456310679612
[321] VALIDATION  acc: 0.6331360946745562

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_33.pth
[322] TRAIN  loss: 0.006192985015176786 acc: 0.9958391123439667
[322] VALIDATION  acc: 0.6272189349112426

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_33.pth
[323] TRAIN  loss: 0.006904542930118845 acc: 0.9951456310679612
[323] VALIDATION  acc: 0.6331360946745562

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_33.pth
[324] TRAIN  loss: 0.007226706185452529 acc: 0.9958391123439667
[324] VALIDATION  acc: 0.6390532544378699

[325] TRAIN  loss: 0.006621968526817704 acc: 0.9965325936199723
[325] VALIDATION  acc: 0.6331360946745562

[326] TRAIN  loss: 0.005971654931065621 acc: 0.9965325936199723
[326] VALIDATION  acc: 0.6301775147928994

[327] TRAIN  loss: 0.006941381365880295 acc: 0.9951456310679612
[327] VALIDATION  acc: 0.636094674556213

[328] TRAIN  loss: 0.007532646054789688 acc: 0.9951456310679612
[328] VALIDATION  acc: 0.6301775147928994

[329] TRAIN  loss: 0.006746148449324292 acc: 0.9965325936199723
[329] VALIDATION  acc: 0.6390532544378699

[330] TRAIN  loss: 0.006444849790715023 acc: 0.9958391123439667
[330] VALIDATION  acc: 0.6331360946745562

[331] TRAIN  loss: 0.006749350858358027 acc: 0.9944521497919556
[331] VALIDATION  acc: 0.636094674556213

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_34.pth
[332] TRAIN  loss: 0.006558603465255878 acc: 0.9965325936199723
[332] VALIDATION  acc: 0.636094674556213

[333] TRAIN  loss: 0.0065174313438271965 acc: 0.9972260748959778
[333] VALIDATION  acc: 0.636094674556213

[334] TRAIN  loss: 0.006299207705884938 acc: 0.9958391123439667
[334] VALIDATION  acc: 0.6301775147928994

[335] TRAIN  loss: 0.007489867074106873 acc: 0.9965325936199723
[335] VALIDATION  acc: 0.6301775147928994

[336] TRAIN  loss: 0.006673018006363293 acc: 0.9951456310679612
[336] VALIDATION  acc: 0.6331360946745562

[337] TRAIN  loss: 0.006887750225352355 acc: 0.9958391123439667
[337] VALIDATION  acc: 0.636094674556213

[338] TRAIN  loss: 0.006240610819061982 acc: 0.9958391123439667
[338] VALIDATION  acc: 0.636094674556213

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_34.pth
[339] TRAIN  loss: 0.00752014729857646 acc: 0.9958391123439667
[339] VALIDATION  acc: 0.6390532544378699

[340] TRAIN  loss: 0.005676695458563051 acc: 0.9979195561719834
[340] VALIDATION  acc: 0.6301775147928994

[341] TRAIN  loss: 0.007274004836214574 acc: 0.9958391123439667
[341] VALIDATION  acc: 0.6390532544378699

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_35.pth
[342] TRAIN  loss: 0.00699395480430733 acc: 0.9951456310679612
[342] VALIDATION  acc: 0.6331360946745562

[343] TRAIN  loss: 0.0073022068616753364 acc: 0.9951456310679612
[343] VALIDATION  acc: 0.6301775147928994

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_35.pth
[344] TRAIN  loss: 0.0055369363899381505 acc: 0.9965325936199723
[344] VALIDATION  acc: 0.636094674556213

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_35.pth
[345] TRAIN  loss: 0.0066124771598101 acc: 0.9965325936199723
[345] VALIDATION  acc: 0.6390532544378699

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_v_35.pth
[346] TRAIN  loss: 0.0068224047255762785 acc: 0.9958391123439667
[346] VALIDATION  acc: 0.6449704142011834

[347] TRAIN  loss: 0.006902057500739978 acc: 0.9951456310679612
[347] VALIDATION  acc: 0.636094674556213

[348] TRAIN  loss: 0.00746919524579617 acc: 0.9958391123439667
[348] VALIDATION  acc: 0.636094674556213

[349] TRAIN  loss: 0.006438902346881516 acc: 0.9965325936199723
[349] VALIDATION  acc: 0.6390532544378699

[350] TRAIN  loss: 0.007455561074121621 acc: 0.9951456310679612
[350] VALIDATION  acc: 0.6449704142011834


Testing checkpointed models starting...

Label accuracies statistics:
{0: 1.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0, 10: 0.0, 11: 0.0, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.0, 19: 0.0, 20: 0.0, 21: 0.0, 22: 0.0, 23: 0.0, 24: 0.0, 25: 0.0, 26: 0.0, 27: 0.0, 28: 0.0, 29: 0.0, 30: 0.0, 31: 0.0, 32: 0.0, 33: 0.0, 34: 0.0, 35: 0.0, 36: 0.0, 37: 0.0, 38: 0.0, 39: 0.0, 40: 0.0, 41: 0.5, 42: 0.0, 43: 0.0, 44: 0.0, 45: 0.0, 46: 0.0, 47: 0.0, 48: 0.0, 49: 0.0, 50: 0.5, 51: 0.0, 52: 0.0, 53: 0.0, 54: 0.0, 55: 0.0, 56: 0.0, 57: 0.0, 58: 0.0, 59: 0.0, 60: 0.0, 61: 0.0, 62: 0.0, 63: 0.0, 64: 0.0, 65: 0.0, 66: 0.0, 67: 0.0, 68: 0.0, 69: 0.0, 70: 0.0, 71: 0.0, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.0, 77: 0.0, 78: 0.0, 79: 0.0, 80: 0.0, 81: 0.0, 82: 0.0, 83: 0.0, 84: 0.0, 85: 0.0, 86: 0.0, 87: 0.0, 88: 0.0, 89: 0.0, 90: 0.0, 91: 0.0, 92: 0.0, 93: 0.0, 94: 0.0, 95: 0.0, 96: 0.0, 97: 0.0, 98: 0.0, 99: 0.0}

checkpoint_t_0  ->  0.023255813953488372
Label accuracies statistics:
{0: 1.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0, 10: 0.0, 11: 0.0, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.0, 19: 0.0, 20: 0.0, 21: 0.0, 22: 0.0, 23: 0.0, 24: 0.0, 25: 0.0, 26: 0.0, 27: 0.0, 28: 0.0, 29: 0.0, 30: 0.0, 31: 0.0, 32: 0.0, 33: 0.0, 34: 0.0, 35: 0.0, 36: 0.0, 37: 0.0, 38: 0.0, 39: 0.0, 40: 0.0, 41: 0.5, 42: 0.0, 43: 0.0, 44: 0.0, 45: 0.0, 46: 0.0, 47: 0.0, 48: 0.0, 49: 0.0, 50: 0.5, 51: 0.0, 52: 0.0, 53: 0.0, 54: 0.0, 55: 0.0, 56: 0.0, 57: 0.0, 58: 0.0, 59: 0.0, 60: 0.0, 61: 0.0, 62: 0.0, 63: 0.0, 64: 0.0, 65: 0.0, 66: 0.0, 67: 0.0, 68: 0.0, 69: 0.0, 70: 0.0, 71: 0.0, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.0, 77: 0.0, 78: 0.0, 79: 0.0, 80: 0.0, 81: 0.0, 82: 0.0, 83: 0.0, 84: 0.0, 85: 0.0, 86: 0.0, 87: 0.0, 88: 0.0, 89: 0.0, 90: 0.0, 91: 0.0, 92: 0.0, 93: 0.0, 94: 0.0, 95: 0.0, 96: 0.0, 97: 0.0, 98: 0.0, 99: 0.0}

checkpoint_v_0  ->  0.023255813953488372
Label accuracies statistics:
{0: 0.5, 1: 0.25, 2: 0.4, 3: 0.0, 4: 0.6666666666666666, 5: 0.0, 6: 0.0, 7: 0.3333333333333333, 8: 0.0, 9: 0.0, 10: 0.0, 11: 0.3333333333333333, 12: 0.3333333333333333, 13: 0.0, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 0.0, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.0, 20: 0.0, 21: 0.0, 22: 0.0, 23: 0.3333333333333333, 24: 1.0, 25: 0.0, 26: 0.0, 27: 0.0, 28: 0.6666666666666666, 29: 0.0, 30: 0.0, 31: 0.0, 32: 0.0, 33: 0.0, 34: 0.0, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.0, 39: 0.5, 40: 1.0, 41: 0.0, 42: 0.0, 43: 0.0, 44: 0.0, 45: 0.5, 46: 0.0, 47: 0.0, 48: 0.0, 49: 0.0, 50: 0.5, 51: 0.0, 52: 0.0, 53: 0.5, 54: 0.5, 55: 0.0, 56: 0.0, 57: 0.0, 58: 0.5, 59: 0.0, 60: 0.0, 61: 0.0, 62: 0.0, 63: 0.0, 64: 0.0, 65: 0.0, 66: 0.0, 67: 0.3333333333333333, 68: 0.0, 69: 0.0, 70: 0.0, 71: 0.6666666666666666, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.0, 76: 0.0, 77: 1.0, 78: 0.0, 79: 0.0, 80: 0.0, 81: 0.0, 82: 0.0, 83: 0.5, 84: 0.0, 85: 0.0, 86: 0.0, 87: 0.0, 88: 0.0, 89: 0.0, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.0, 94: 0.0, 95: 0.0, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_1  ->  0.17054263565891473
Label accuracies statistics:
{0: 0.5, 1: 0.25, 2: 0.4, 3: 0.0, 4: 0.6666666666666666, 5: 0.0, 6: 0.0, 7: 0.3333333333333333, 8: 0.0, 9: 0.0, 10: 0.0, 11: 0.3333333333333333, 12: 0.3333333333333333, 13: 0.0, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 0.0, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.0, 20: 0.0, 21: 0.0, 22: 0.0, 23: 0.3333333333333333, 24: 1.0, 25: 0.0, 26: 0.0, 27: 0.0, 28: 0.6666666666666666, 29: 0.0, 30: 0.0, 31: 0.0, 32: 0.0, 33: 0.0, 34: 0.0, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.0, 39: 0.5, 40: 1.0, 41: 0.0, 42: 0.0, 43: 0.0, 44: 0.0, 45: 0.5, 46: 0.0, 47: 0.0, 48: 0.0, 49: 0.0, 50: 0.5, 51: 0.0, 52: 0.0, 53: 0.5, 54: 0.5, 55: 0.0, 56: 0.0, 57: 0.0, 58: 0.5, 59: 0.0, 60: 0.0, 61: 0.0, 62: 0.0, 63: 0.0, 64: 0.0, 65: 0.0, 66: 0.0, 67: 0.3333333333333333, 68: 0.0, 69: 0.0, 70: 0.0, 71: 0.6666666666666666, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.0, 76: 0.0, 77: 1.0, 78: 0.0, 79: 0.0, 80: 0.0, 81: 0.0, 82: 0.0, 83: 0.5, 84: 0.0, 85: 0.0, 86: 0.0, 87: 0.0, 88: 0.0, 89: 0.0, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.0, 94: 0.0, 95: 0.0, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_1  ->  0.17054263565891473
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.4, 3: 0.25, 4: 0.6666666666666666, 5: 0.3333333333333333, 6: 1.0, 7: 0.6666666666666666, 8: 0.0, 9: 0.0, 10: 0.0, 11: 0.0, 12: 0.6666666666666666, 13: 0.3333333333333333, 14: 0.0, 15: 0.3333333333333333, 16: 0.3333333333333333, 17: 0.0, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.0, 21: 0.3333333333333333, 22: 0.0, 23: 0.6666666666666666, 24: 1.0, 25: 0.3333333333333333, 26: 0.0, 27: 0.6666666666666666, 28: 1.0, 29: 0.6666666666666666, 30: 0.0, 31: 0.3333333333333333, 32: 0.5, 33: 0.0, 34: 1.0, 35: 0.5, 36: 0.0, 37: 0.0, 38: 0.0, 39: 0.5, 40: 1.0, 41: 0.5, 42: 0.6666666666666666, 43: 0.0, 44: 0.0, 45: 1.0, 46: 0.3333333333333333, 47: 0.5, 48: 0.0, 49: 0.0, 50: 1.0, 51: 0.0, 52: 0.0, 53: 0.5, 54: 0.5, 55: 0.0, 56: 0.0, 57: 0.6666666666666666, 58: 0.5, 59: 0.3333333333333333, 60: 0.6666666666666666, 61: 0.0, 62: 0.5, 63: 0.5, 64: 0.0, 65: 0.6666666666666666, 66: 0.0, 67: 0.0, 68: 0.0, 69: 0.0, 70: 0.0, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.0, 77: 1.0, 78: 0.3333333333333333, 79: 0.0, 80: 0.0, 81: 0.5, 82: 0.5, 83: 0.5, 84: 1.0, 85: 0.0, 86: 0.0, 87: 0.0, 88: 0.3333333333333333, 89: 0.0, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.0, 94: 0.0, 95: 0.0, 96: 0.0, 97: 0.5, 98: 0.0, 99: 0.0}

checkpoint_t_2  ->  0.32945736434108525
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.4, 3: 0.25, 4: 0.6666666666666666, 5: 0.3333333333333333, 6: 1.0, 7: 0.6666666666666666, 8: 0.0, 9: 0.0, 10: 0.0, 11: 0.0, 12: 0.6666666666666666, 13: 0.3333333333333333, 14: 0.0, 15: 0.3333333333333333, 16: 0.3333333333333333, 17: 0.0, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.0, 21: 0.3333333333333333, 22: 0.0, 23: 0.6666666666666666, 24: 1.0, 25: 0.3333333333333333, 26: 0.0, 27: 0.6666666666666666, 28: 1.0, 29: 0.6666666666666666, 30: 0.0, 31: 0.3333333333333333, 32: 0.5, 33: 0.0, 34: 1.0, 35: 0.5, 36: 0.0, 37: 0.0, 38: 0.0, 39: 0.5, 40: 1.0, 41: 0.5, 42: 0.6666666666666666, 43: 0.0, 44: 0.0, 45: 1.0, 46: 0.3333333333333333, 47: 0.5, 48: 0.0, 49: 0.0, 50: 1.0, 51: 0.0, 52: 0.0, 53: 0.5, 54: 0.5, 55: 0.0, 56: 0.0, 57: 0.6666666666666666, 58: 0.5, 59: 0.3333333333333333, 60: 0.6666666666666666, 61: 0.0, 62: 0.5, 63: 0.5, 64: 0.0, 65: 0.6666666666666666, 66: 0.0, 67: 0.0, 68: 0.0, 69: 0.0, 70: 0.0, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.0, 77: 1.0, 78: 0.3333333333333333, 79: 0.0, 80: 0.0, 81: 0.5, 82: 0.5, 83: 0.5, 84: 1.0, 85: 0.0, 86: 0.0, 87: 0.0, 88: 0.3333333333333333, 89: 0.0, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.0, 94: 0.0, 95: 0.0, 96: 0.0, 97: 0.5, 98: 0.0, 99: 0.0}

checkpoint_v_2  ->  0.32945736434108525
Label accuracies statistics:
{0: 0.75, 1: 0.0, 2: 0.4, 3: 0.5, 4: 1.0, 5: 0.3333333333333333, 6: 1.0, 7: 1.0, 8: 0.0, 9: 0.0, 10: 0.0, 11: 0.0, 12: 0.6666666666666666, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.3333333333333333, 17: 0.0, 18: 0.3333333333333333, 19: 0.0, 20: 0.0, 21: 0.6666666666666666, 22: 0.3333333333333333, 23: 0.0, 24: 0.3333333333333333, 25: 0.3333333333333333, 26: 0.6666666666666666, 27: 0.3333333333333333, 28: 1.0, 29: 1.0, 30: 0.3333333333333333, 31: 0.0, 32: 0.5, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.0, 37: 0.5, 38: 0.3333333333333333, 39: 0.5, 40: 0.0, 41: 0.5, 42: 0.3333333333333333, 43: 0.3333333333333333, 44: 0.0, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.0, 52: 0.0, 53: 0.0, 54: 1.0, 55: 0.0, 56: 0.0, 57: 0.3333333333333333, 58: 0.0, 59: 0.3333333333333333, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 0.5, 67: 0.0, 68: 0.0, 69: 0.5, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.5, 75: 0.5, 76: 0.0, 77: 1.0, 78: 0.3333333333333333, 79: 0.5, 80: 0.0, 81: 0.5, 82: 0.5, 83: 0.0, 84: 0.5, 85: 0.0, 86: 0.0, 87: 0.0, 88: 0.3333333333333333, 89: 0.5, 90: 0.0, 91: 0.5, 92: 1.0, 93: 0.0, 94: 0.5, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_3  ->  0.3682170542635659
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.4, 3: 0.5, 4: 0.3333333333333333, 5: 0.3333333333333333, 6: 1.0, 7: 0.3333333333333333, 8: 0.3333333333333333, 9: 0.3333333333333333, 10: 0.0, 11: 0.6666666666666666, 12: 0.6666666666666666, 13: 0.0, 14: 0.3333333333333333, 15: 0.0, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 1.0, 20: 0.0, 21: 0.3333333333333333, 22: 0.3333333333333333, 23: 0.3333333333333333, 24: 0.3333333333333333, 25: 0.6666666666666666, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.0, 30: 0.3333333333333333, 31: 0.0, 32: 0.5, 33: 1.0, 34: 0.5, 35: 1.0, 36: 0.0, 37: 0.5, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 0.0, 42: 0.3333333333333333, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.3333333333333333, 47: 0.5, 48: 0.3333333333333333, 49: 0.0, 50: 1.0, 51: 0.0, 52: 1.0, 53: 0.5, 54: 1.0, 55: 0.5, 56: 0.0, 57: 0.3333333333333333, 58: 0.0, 59: 0.3333333333333333, 60: 0.6666666666666666, 61: 0.0, 62: 0.5, 63: 0.5, 64: 0.0, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.0, 69: 0.5, 70: 0.5, 71: 0.3333333333333333, 72: 0.5, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.3333333333333333, 77: 1.0, 78: 0.3333333333333333, 79: 0.5, 80: 0.0, 81: 0.5, 82: 0.5, 83: 0.5, 84: 1.0, 85: 0.5, 86: 0.3333333333333333, 87: 0.5, 88: 0.6666666666666666, 89: 0.5, 90: 0.0, 91: 0.5, 92: 1.0, 93: 0.0, 94: 0.0, 95: 0.0, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_3  ->  0.4186046511627907
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.6, 3: 0.25, 4: 1.0, 5: 0.3333333333333333, 6: 0.0, 7: 0.6666666666666666, 8: 0.6666666666666666, 9: 0.3333333333333333, 10: 0.3333333333333333, 11: 0.3333333333333333, 12: 0.6666666666666666, 13: 0.3333333333333333, 14: 0.0, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.0, 18: 0.3333333333333333, 19: 0.0, 20: 0.0, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 0.6666666666666666, 25: 0.6666666666666666, 26: 0.0, 27: 0.6666666666666666, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 0.0, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.0, 37: 0.5, 38: 0.6666666666666666, 39: 0.5, 40: 0.0, 41: 0.5, 42: 0.6666666666666666, 43: 0.3333333333333333, 44: 0.0, 45: 1.0, 46: 0.3333333333333333, 47: 0.5, 48: 0.6666666666666666, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.0, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.0, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 0.5, 67: 0.3333333333333333, 68: 0.0, 69: 0.5, 70: 0.5, 71: 0.3333333333333333, 72: 0.5, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 0.5, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 1.0, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.0, 94: 0.0, 95: 0.5, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_4  ->  0.4573643410852713
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.6, 3: 0.25, 4: 1.0, 5: 0.3333333333333333, 6: 0.0, 7: 0.6666666666666666, 8: 0.6666666666666666, 9: 0.3333333333333333, 10: 0.3333333333333333, 11: 0.3333333333333333, 12: 0.6666666666666666, 13: 0.3333333333333333, 14: 0.0, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.0, 18: 0.3333333333333333, 19: 0.0, 20: 0.0, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 0.6666666666666666, 25: 0.6666666666666666, 26: 0.0, 27: 0.6666666666666666, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 0.0, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.0, 37: 0.5, 38: 0.6666666666666666, 39: 0.5, 40: 0.0, 41: 0.5, 42: 0.6666666666666666, 43: 0.3333333333333333, 44: 0.0, 45: 1.0, 46: 0.3333333333333333, 47: 0.5, 48: 0.6666666666666666, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.0, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.0, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 0.5, 67: 0.3333333333333333, 68: 0.0, 69: 0.5, 70: 0.5, 71: 0.3333333333333333, 72: 0.5, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 0.5, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 1.0, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.0, 94: 0.0, 95: 0.5, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_4  ->  0.4573643410852713
Label accuracies statistics:
{0: 1.0, 1: 0.25, 2: 0.6, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.3333333333333333, 8: 0.6666666666666666, 9: 0.6666666666666666, 10: 0.6666666666666666, 11: 0.3333333333333333, 12: 0.6666666666666666, 13: 0.3333333333333333, 14: 0.0, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.0, 20: 0.0, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.3333333333333333, 24: 1.0, 25: 0.3333333333333333, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.3333333333333333, 30: 0.3333333333333333, 31: 0.3333333333333333, 32: 1.0, 33: 1.0, 34: 0.5, 35: 1.0, 36: 0.3333333333333333, 37: 0.5, 38: 0.6666666666666666, 39: 0.5, 40: 1.0, 41: 0.5, 42: 0.3333333333333333, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 0.6666666666666666, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.0, 53: 0.5, 54: 1.0, 55: 0.0, 56: 0.6666666666666666, 57: 0.3333333333333333, 58: 0.0, 59: 0.6666666666666666, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 0.5, 67: 0.6666666666666666, 68: 0.3333333333333333, 69: 0.5, 70: 0.5, 71: 0.6666666666666666, 72: 0.5, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 1.0, 78: 0.6666666666666666, 79: 0.5, 80: 0.0, 81: 0.5, 82: 0.5, 83: 0.0, 84: 0.5, 85: 0.0, 86: 0.3333333333333333, 87: 0.0, 88: 0.6666666666666666, 89: 0.5, 90: 0.0, 91: 0.5, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.0, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_5  ->  0.49612403100775193
Label accuracies statistics:
{0: 0.75, 1: 0.25, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.3333333333333333, 8: 0.6666666666666666, 9: 0.6666666666666666, 10: 0.6666666666666666, 11: 0.3333333333333333, 12: 0.6666666666666666, 13: 0.3333333333333333, 14: 0.6666666666666666, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 1.0, 20: 0.0, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.3333333333333333, 24: 0.6666666666666666, 25: 0.6666666666666666, 26: 0.0, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.3333333333333333, 31: 0.3333333333333333, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.6666666666666666, 37: 0.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 0.6666666666666666, 49: 0.0, 50: 1.0, 51: 0.0, 52: 1.0, 53: 0.0, 54: 1.0, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 0.5, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 0.5, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 0.5, 67: 0.3333333333333333, 68: 0.0, 69: 0.5, 70: 0.5, 71: 0.6666666666666666, 72: 0.0, 73: 0.5, 74: 0.0, 75: 1.0, 76: 0.6666666666666666, 77: 1.0, 78: 0.6666666666666666, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.6666666666666666, 87: 0.0, 88: 1.0, 89: 1.0, 90: 0.5, 91: 0.5, 92: 0.5, 93: 0.0, 94: 0.0, 95: 1.0, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.5}

checkpoint_v_5  ->  0.5542635658914729
Label accuracies statistics:
{0: 1.0, 1: 0.25, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 1.0, 8: 0.6666666666666666, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 0.3333333333333333, 13: 0.3333333333333333, 14: 0.0, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.3333333333333333, 20: 0.0, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 0.6666666666666666, 28: 1.0, 29: 1.0, 30: 0.3333333333333333, 31: 0.0, 32: 0.5, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.6666666666666666, 37: 0.5, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 0.5, 42: 0.3333333333333333, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 0.6666666666666666, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.0, 54: 0.0, 55: 0.0, 56: 0.0, 57: 0.3333333333333333, 58: 0.5, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 0.5, 67: 1.0, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.5, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 0.5, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.0, 91: 1.0, 92: 0.5, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_6  ->  0.5232558139534884
Label accuracies statistics:
{0: 1.0, 1: 0.25, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 1.0, 8: 0.6666666666666666, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 0.3333333333333333, 13: 0.3333333333333333, 14: 0.0, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.3333333333333333, 20: 0.0, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 0.6666666666666666, 28: 1.0, 29: 1.0, 30: 0.3333333333333333, 31: 0.0, 32: 0.5, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.6666666666666666, 37: 0.5, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 0.5, 42: 0.3333333333333333, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 0.6666666666666666, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.0, 54: 0.0, 55: 0.0, 56: 0.0, 57: 0.3333333333333333, 58: 0.5, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 0.5, 67: 1.0, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.5, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 0.5, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.0, 91: 1.0, 92: 0.5, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_6  ->  0.5232558139534884
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.6, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.3333333333333333, 8: 0.3333333333333333, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.3333333333333333, 14: 0.0, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.0, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 0.6666666666666666, 25: 1.0, 26: 0.0, 27: 0.6666666666666666, 28: 1.0, 29: 1.0, 30: 0.3333333333333333, 31: 0.3333333333333333, 32: 0.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.0, 37: 0.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 0.3333333333333333, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.0, 54: 0.5, 55: 0.5, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 0.5, 59: 0.6666666666666666, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 1.0, 71: 0.6666666666666666, 72: 0.5, 73: 0.5, 74: 0.0, 75: 1.0, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 0.5, 92: 0.5, 93: 0.0, 94: 0.0, 95: 0.5, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_7  ->  0.5426356589147286
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.6, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.3333333333333333, 8: 0.3333333333333333, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.3333333333333333, 14: 0.0, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.0, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 0.6666666666666666, 25: 1.0, 26: 0.0, 27: 0.6666666666666666, 28: 1.0, 29: 1.0, 30: 0.3333333333333333, 31: 0.3333333333333333, 32: 0.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.0, 37: 0.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 0.3333333333333333, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.0, 54: 0.5, 55: 0.5, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 0.5, 59: 0.6666666666666666, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 1.0, 71: 0.6666666666666666, 72: 0.5, 73: 0.5, 74: 0.0, 75: 1.0, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 0.5, 92: 0.5, 93: 0.0, 94: 0.0, 95: 0.5, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_7  ->  0.5426356589147286
Label accuracies statistics:
{0: 1.0, 1: 0.25, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 1.0, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.6666666666666666, 12: 0.3333333333333333, 13: 0.6666666666666666, 14: 0.3333333333333333, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 1.0, 20: 0.0, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.3333333333333333, 24: 1.0, 25: 1.0, 26: 0.0, 27: 0.6666666666666666, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 0.5, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.3333333333333333, 37: 0.0, 38: 0.0, 39: 0.5, 40: 1.0, 41: 0.0, 42: 0.3333333333333333, 43: 1.0, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 0.3333333333333333, 49: 0.0, 50: 0.5, 51: 0.3333333333333333, 52: 0.5, 53: 0.0, 54: 1.0, 55: 0.0, 56: 0.0, 57: 0.6666666666666666, 58: 0.0, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.0, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 1.0, 76: 0.6666666666666666, 77: 1.0, 78: 0.6666666666666666, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.6666666666666666, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.5, 94: 0.0, 95: 1.0, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_8  ->  0.5426356589147286
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.3333333333333333, 8: 0.3333333333333333, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.3333333333333333, 14: 0.3333333333333333, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.3333333333333333, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.3333333333333333, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 0.3333333333333333, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.3333333333333333, 37: 0.5, 38: 0.3333333333333333, 39: 0.5, 40: 0.5, 41: 1.0, 42: 0.3333333333333333, 43: 1.0, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 0.6666666666666666, 49: 0.0, 50: 1.0, 51: 0.0, 52: 0.5, 53: 0.0, 54: 1.0, 55: 0.0, 56: 0.6666666666666666, 57: 0.6666666666666666, 58: 0.5, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.6666666666666666, 72: 0.5, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.6666666666666666, 87: 0.0, 88: 0.6666666666666666, 89: 0.5, 90: 0.5, 91: 0.5, 92: 0.5, 93: 1.0, 94: 0.5, 95: 0.5, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_8  ->  0.5736434108527132
Label accuracies statistics:
{0: 1.0, 1: 0.25, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.6666666666666666, 8: 0.6666666666666666, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.3333333333333333, 14: 0.0, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.3333333333333333, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 0.6666666666666666, 28: 1.0, 29: 1.0, 30: 0.3333333333333333, 31: 0.0, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.3333333333333333, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.3333333333333333, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 0.6666666666666666, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.5, 54: 1.0, 55: 0.0, 56: 0.6666666666666666, 57: 0.6666666666666666, 58: 0.5, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 1.0, 67: 0.0, 68: 0.0, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.5, 73: 0.5, 74: 0.0, 75: 1.0, 76: 0.6666666666666666, 77: 1.0, 78: 0.6666666666666666, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.6666666666666666, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 0.5, 92: 0.5, 93: 0.0, 94: 0.5, 95: 0.5, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_9  ->  0.5658914728682171
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 0.6666666666666666, 7: 0.6666666666666666, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 0.6666666666666666, 13: 0.3333333333333333, 14: 0.3333333333333333, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.3333333333333333, 20: 0.0, 21: 0.6666666666666666, 22: 0.3333333333333333, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.0, 30: 0.3333333333333333, 31: 0.3333333333333333, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.0, 37: 0.5, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.3333333333333333, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 0.6666666666666666, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 1.0, 53: 0.5, 54: 1.0, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 0.0, 59: 0.3333333333333333, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.6666666666666666, 72: 0.0, 73: 0.5, 74: 0.0, 75: 1.0, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 1.0, 90: 0.5, 91: 0.5, 92: 0.5, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.3333333333333333, 97: 0.5, 98: 1.0, 99: 0.0}

checkpoint_v_9  ->  0.5503875968992248
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 0.6666666666666666, 7: 0.6666666666666666, 8: 0.6666666666666666, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 0.6666666666666666, 13: 0.3333333333333333, 14: 0.3333333333333333, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 1.0, 20: 0.0, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 0.6666666666666666, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 0.3333333333333333, 32: 0.5, 33: 1.0, 34: 0.5, 35: 1.0, 36: 0.3333333333333333, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 0.6666666666666666, 49: 0.0, 50: 1.0, 51: 0.0, 52: 0.5, 53: 1.0, 54: 1.0, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 0.5, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 1.0, 67: 0.0, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 1.0, 77: 1.0, 78: 0.6666666666666666, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.6666666666666666, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 0.5, 92: 0.5, 93: 0.0, 94: 0.5, 95: 0.5, 96: 0.6666666666666666, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_10  ->  0.5581395348837209
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 0.6666666666666666, 7: 0.6666666666666666, 8: 0.3333333333333333, 9: 0.3333333333333333, 10: 1.0, 11: 0.3333333333333333, 12: 0.6666666666666666, 13: 0.3333333333333333, 14: 0.0, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.3333333333333333, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 0.6666666666666666, 28: 1.0, 29: 1.0, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.3333333333333333, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.3333333333333333, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 0.6666666666666666, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 1.0, 53: 0.5, 54: 1.0, 55: 0.0, 56: 0.6666666666666666, 57: 0.6666666666666666, 58: 0.5, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 1.0, 67: 0.0, 68: 0.3333333333333333, 69: 1.0, 70: 1.0, 71: 0.6666666666666666, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 1.0, 78: 0.6666666666666666, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.5, 84: 1.0, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.0, 94: 0.0, 95: 0.5, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.5}

checkpoint_v_10  ->  0.5658914728682171
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.6666666666666666, 8: 0.6666666666666666, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.3333333333333333, 14: 0.0, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.0, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.3333333333333333, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 0.6666666666666666, 49: 0.0, 50: 1.0, 51: 0.6666666666666666, 52: 0.5, 53: 0.5, 54: 1.0, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 0.5, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.5, 73: 0.5, 74: 0.0, 75: 1.0, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.6666666666666666, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.0, 94: 0.5, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_11  ->  0.5775193798449613
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.6666666666666666, 8: 0.6666666666666666, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.3333333333333333, 14: 0.0, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.3333333333333333, 20: 0.0, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.3333333333333333, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.3333333333333333, 37: 0.5, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.3333333333333333, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 0.6666666666666666, 49: 0.0, 50: 1.0, 51: 0.6666666666666666, 52: 1.0, 53: 0.5, 54: 1.0, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 0.5, 59: 0.6666666666666666, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 1.0, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 1.0, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.6666666666666666, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 0.5, 92: 0.5, 93: 0.0, 94: 0.5, 95: 1.0, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_11  ->  0.5852713178294574
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.6666666666666666, 8: 0.6666666666666666, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 0.6666666666666666, 13: 0.3333333333333333, 14: 0.0, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.0, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.3333333333333333, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.3333333333333333, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 1.0, 53: 0.5, 54: 1.0, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 0.5, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.5, 73: 0.5, 74: 0.0, 75: 1.0, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.6666666666666666, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.0, 94: 0.5, 95: 1.0, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_12  ->  0.5891472868217055
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.6666666666666666, 8: 0.6666666666666666, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 0.6666666666666666, 13: 0.3333333333333333, 14: 0.0, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.0, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.3333333333333333, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.3333333333333333, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 1.0, 53: 0.5, 54: 1.0, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 0.5, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.5, 73: 0.5, 74: 0.0, 75: 1.0, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.6666666666666666, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.0, 94: 0.5, 95: 1.0, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_12  ->  0.5891472868217055
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.3333333333333333, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.3333333333333333, 14: 0.0, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 1.0, 20: 0.0, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.3333333333333333, 24: 1.0, 25: 1.0, 26: 0.0, 27: 0.6666666666666666, 28: 1.0, 29: 1.0, 30: 0.3333333333333333, 31: 0.3333333333333333, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.3333333333333333, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.3333333333333333, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 0.6666666666666666, 49: 0.0, 50: 1.0, 51: 0.6666666666666666, 52: 0.5, 53: 0.5, 54: 1.0, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 0.5, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.5, 73: 0.5, 74: 0.0, 75: 1.0, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.6666666666666666, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 0.5, 92: 0.5, 93: 0.0, 94: 0.5, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_13  ->  0.5891472868217055
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.3333333333333333, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.3333333333333333, 14: 0.0, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 1.0, 20: 0.0, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.3333333333333333, 24: 1.0, 25: 1.0, 26: 0.0, 27: 0.6666666666666666, 28: 1.0, 29: 1.0, 30: 0.3333333333333333, 31: 0.3333333333333333, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.3333333333333333, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.3333333333333333, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 0.6666666666666666, 49: 0.0, 50: 1.0, 51: 0.6666666666666666, 52: 0.5, 53: 0.5, 54: 1.0, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 0.5, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.5, 73: 0.5, 74: 0.0, 75: 1.0, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.6666666666666666, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 0.5, 92: 0.5, 93: 0.0, 94: 0.5, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_13  ->  0.5891472868217055
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.3333333333333333, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.3333333333333333, 14: 0.0, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.3333333333333333, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.3333333333333333, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.5, 54: 0.5, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 0.5, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 1.0, 71: 0.3333333333333333, 72: 0.5, 73: 0.5, 74: 0.0, 75: 1.0, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.0, 94: 0.5, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_14  ->  0.5775193798449613
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.3333333333333333, 8: 0.6666666666666666, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 0.6666666666666666, 13: 0.3333333333333333, 14: 0.0, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.3333333333333333, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.3333333333333333, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 0.6666666666666666, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.5, 54: 1.0, 55: 0.0, 56: 0.6666666666666666, 57: 0.6666666666666666, 58: 0.5, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.5, 73: 0.5, 74: 0.0, 75: 1.0, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.5, 84: 1.0, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 0.5, 92: 0.5, 93: 0.0, 94: 0.5, 95: 1.0, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_14  ->  0.5891472868217055
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.3333333333333333, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.3333333333333333, 14: 0.0, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.0, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 0.3333333333333333, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.3333333333333333, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.3333333333333333, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 0.6666666666666666, 49: 0.0, 50: 1.0, 51: 0.6666666666666666, 52: 0.5, 53: 0.0, 54: 1.0, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 0.0, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.6666666666666666, 72: 0.5, 73: 0.5, 74: 0.0, 75: 1.0, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.5, 94: 0.5, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_15  ->  0.5697674418604651
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.3333333333333333, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 0.6666666666666666, 13: 0.3333333333333333, 14: 0.0, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.3333333333333333, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 0.6666666666666666, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.5, 54: 1.0, 55: 0.0, 56: 0.6666666666666666, 57: 0.6666666666666666, 58: 0.5, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.5, 73: 0.5, 74: 0.0, 75: 1.0, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.6666666666666666, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.0, 94: 0.5, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_15  ->  0.5813953488372093
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.3333333333333333, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.3333333333333333, 14: 0.0, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.3333333333333333, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.3333333333333333, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 0.6666666666666666, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.5, 54: 1.0, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 0.5, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.5, 73: 0.5, 74: 0.0, 75: 1.0, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.5, 84: 1.0, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 0.5, 92: 0.5, 93: 0.0, 94: 0.5, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_16  ->  0.5891472868217055
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.3333333333333333, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.3333333333333333, 14: 0.0, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.3333333333333333, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.3333333333333333, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.3333333333333333, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.5, 54: 1.0, 55: 0.0, 56: 0.6666666666666666, 57: 0.6666666666666666, 58: 0.0, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.5, 73: 0.5, 74: 0.0, 75: 1.0, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.5, 84: 1.0, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.5, 94: 0.5, 95: 1.0, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_16  ->  0.5930232558139535
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.3333333333333333, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.3333333333333333, 14: 0.0, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.3333333333333333, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.3333333333333333, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.3333333333333333, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 0.6666666666666666, 49: 0.0, 50: 1.0, 51: 0.6666666666666666, 52: 0.5, 53: 0.5, 54: 1.0, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 0.5, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.5, 73: 0.5, 74: 0.0, 75: 1.0, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.5, 84: 1.0, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 0.5, 92: 0.5, 93: 0.0, 94: 0.5, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_17  ->  0.5891472868217055
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.3333333333333333, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.3333333333333333, 14: 0.0, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.3333333333333333, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 0.6666666666666666, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.5, 54: 1.0, 55: 0.0, 56: 0.6666666666666666, 57: 0.6666666666666666, 58: 0.0, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.5, 73: 0.5, 74: 0.0, 75: 1.0, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.5, 94: 0.5, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_17  ->  0.5813953488372093
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.3333333333333333, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.3333333333333333, 14: 0.0, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.3333333333333333, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.3333333333333333, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 0.6666666666666666, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.5, 54: 1.0, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.5, 73: 0.5, 74: 0.0, 75: 1.0, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.0, 94: 0.5, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_18  ->  0.5775193798449613
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.3333333333333333, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.3333333333333333, 14: 0.0, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.3333333333333333, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.3333333333333333, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 0.6666666666666666, 49: 0.0, 50: 1.0, 51: 0.6666666666666666, 52: 0.5, 53: 0.5, 54: 1.0, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 0.5, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.5, 73: 0.5, 74: 0.0, 75: 1.0, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.0, 94: 0.5, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_18  ->  0.5775193798449613
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.3333333333333333, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.3333333333333333, 14: 0.0, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.3333333333333333, 31: 0.3333333333333333, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.3333333333333333, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.3333333333333333, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 0.6666666666666666, 49: 0.0, 50: 1.0, 51: 0.6666666666666666, 52: 0.5, 53: 0.5, 54: 1.0, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.6666666666666666, 72: 0.5, 73: 0.5, 74: 0.0, 75: 1.0, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 0.5, 92: 0.5, 93: 0.5, 94: 0.5, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_19  ->  0.5968992248062015
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.3333333333333333, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.3333333333333333, 14: 0.0, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.3333333333333333, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 0.6666666666666666, 49: 0.0, 50: 1.0, 51: 0.6666666666666666, 52: 0.5, 53: 0.5, 54: 1.0, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 0.0, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.5, 73: 0.5, 74: 0.0, 75: 1.0, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 0.5, 92: 0.5, 93: 0.0, 94: 0.5, 95: 1.0, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_19  ->  0.5852713178294574
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.3333333333333333, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.3333333333333333, 14: 0.0, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.3333333333333333, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 0.6666666666666666, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.5, 54: 1.0, 55: 0.0, 56: 0.6666666666666666, 57: 0.6666666666666666, 58: 0.0, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.5, 73: 0.5, 74: 0.0, 75: 1.0, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.5, 84: 1.0, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.5, 94: 0.5, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_20  ->  0.5852713178294574
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.3333333333333333, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.3333333333333333, 14: 0.0, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.3333333333333333, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.3333333333333333, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.3333333333333333, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 0.6666666666666666, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.5, 54: 1.0, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 0.5, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.5, 73: 0.5, 74: 0.0, 75: 1.0, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 0.5, 92: 0.5, 93: 0.5, 94: 0.5, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_20  ->  0.5852713178294574
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.3333333333333333, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.3333333333333333, 14: 0.0, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.3333333333333333, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 0.6666666666666666, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.5, 54: 1.0, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 0.5, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.5, 73: 0.5, 74: 0.0, 75: 1.0, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 0.5, 92: 0.5, 93: 0.5, 94: 0.5, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_21  ->  0.5852713178294574
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.3333333333333333, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.3333333333333333, 14: 0.0, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.3333333333333333, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 0.6666666666666666, 49: 0.5, 50: 1.0, 51: 0.3333333333333333, 52: 1.0, 53: 0.5, 54: 1.0, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 0.5, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.5, 73: 0.5, 74: 0.0, 75: 1.0, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.0, 94: 0.5, 95: 1.0, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_21  ->  0.5891472868217055
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.3333333333333333, 8: 0.6666666666666666, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.3333333333333333, 14: 0.0, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.3333333333333333, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.3333333333333333, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 0.6666666666666666, 49: 0.0, 50: 1.0, 51: 0.6666666666666666, 52: 1.0, 53: 0.5, 54: 1.0, 55: 0.0, 56: 0.6666666666666666, 57: 0.6666666666666666, 58: 0.5, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.5, 73: 0.5, 74: 0.0, 75: 1.0, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.0, 94: 0.5, 95: 1.0, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_22  ->  0.5852713178294574
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.3333333333333333, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.3333333333333333, 14: 0.0, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.0, 37: 0.5, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.3333333333333333, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 0.6666666666666666, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.5, 54: 1.0, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.5, 73: 0.5, 74: 0.0, 75: 1.0, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.0, 94: 0.5, 95: 1.0, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_22  ->  0.5813953488372093
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.3333333333333333, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.3333333333333333, 14: 0.3333333333333333, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.3333333333333333, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.3333333333333333, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 0.6666666666666666, 49: 0.0, 50: 1.0, 51: 0.6666666666666666, 52: 0.5, 53: 0.5, 54: 1.0, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.5, 73: 0.5, 74: 0.0, 75: 1.0, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.5, 84: 1.0, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.5, 94: 0.5, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_23  ->  0.6007751937984496
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.3333333333333333, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.3333333333333333, 14: 0.3333333333333333, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.3333333333333333, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.3333333333333333, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 0.6666666666666666, 49: 0.0, 50: 1.0, 51: 0.6666666666666666, 52: 0.5, 53: 0.5, 54: 1.0, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.5, 73: 0.5, 74: 0.0, 75: 1.0, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.5, 84: 1.0, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.5, 94: 0.5, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_23  ->  0.6007751937984496
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.3333333333333333, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.3333333333333333, 14: 0.0, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.0, 37: 0.5, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.3333333333333333, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.5, 54: 1.0, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 0.5, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.5, 73: 0.5, 74: 0.0, 75: 1.0, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.0, 94: 0.5, 95: 1.0, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_24  ->  0.5813953488372093
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.3333333333333333, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.3333333333333333, 14: 0.0, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.0, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.3333333333333333, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 0.6666666666666666, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 1.0, 53: 0.5, 54: 1.0, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.5, 73: 0.5, 74: 0.0, 75: 1.0, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.5, 84: 1.0, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 0.5, 92: 0.5, 93: 0.0, 94: 0.5, 95: 1.0, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_24  ->  0.5930232558139535
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.3333333333333333, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.3333333333333333, 14: 0.0, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.3333333333333333, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.5, 54: 1.0, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.5, 73: 0.5, 74: 0.0, 75: 1.0, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 0.5, 92: 0.5, 93: 0.0, 94: 0.5, 95: 1.0, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_25  ->  0.5930232558139535
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.3333333333333333, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.3333333333333333, 14: 0.0, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.3333333333333333, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.5, 54: 1.0, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.5, 73: 0.5, 74: 0.0, 75: 1.0, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 0.5, 92: 0.5, 93: 0.0, 94: 0.5, 95: 1.0, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_25  ->  0.5930232558139535
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.3333333333333333, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.3333333333333333, 14: 0.0, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.3333333333333333, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 1.0, 53: 0.5, 54: 1.0, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 0.5, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.5, 73: 0.5, 74: 0.0, 75: 1.0, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 0.5, 92: 0.5, 93: 0.0, 94: 0.5, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_26  ->  0.5891472868217055
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.3333333333333333, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.6666666666666666, 14: 0.0, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.3333333333333333, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 0.6666666666666666, 49: 0.0, 50: 1.0, 51: 0.6666666666666666, 52: 0.5, 53: 0.5, 54: 1.0, 55: 0.0, 56: 0.6666666666666666, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.5, 73: 0.5, 74: 0.0, 75: 1.0, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 0.5, 92: 0.5, 93: 0.0, 94: 0.5, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_26  ->  0.5968992248062015
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.3333333333333333, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.3333333333333333, 14: 0.0, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.0, 37: 0.5, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.3333333333333333, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 0.6666666666666666, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.5, 54: 1.0, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 1.0, 67: 0.6666666666666666, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.5, 73: 0.5, 74: 0.0, 75: 1.0, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 0.5, 92: 0.5, 93: 0.5, 94: 0.5, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_27  ->  0.5891472868217055
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.3333333333333333, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.3333333333333333, 14: 0.0, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.3333333333333333, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 0.6666666666666666, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 1.0, 53: 0.5, 54: 1.0, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 0.5, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.5, 73: 0.5, 74: 0.0, 75: 1.0, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 0.5, 92: 0.5, 93: 0.0, 94: 0.5, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_27  ->  0.5852713178294574
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.3333333333333333, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.3333333333333333, 14: 0.0, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.3333333333333333, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 0.6666666666666666, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.5, 54: 1.0, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 0.5, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.5, 73: 0.5, 74: 0.0, 75: 1.0, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 0.5, 92: 0.5, 93: 0.0, 94: 0.5, 95: 1.0, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_28  ->  0.5852713178294574
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.3333333333333333, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.3333333333333333, 14: 0.0, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.3333333333333333, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 0.6666666666666666, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.5, 54: 1.0, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 0.5, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.5, 73: 0.5, 74: 0.0, 75: 1.0, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 0.5, 92: 0.5, 93: 0.0, 94: 0.5, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_28  ->  0.5813953488372093
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.3333333333333333, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.3333333333333333, 14: 0.0, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.3333333333333333, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 0.6666666666666666, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.5, 54: 1.0, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 0.5, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.5, 73: 0.5, 74: 0.0, 75: 1.0, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.5, 84: 1.0, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 0.5, 92: 0.5, 93: 0.0, 94: 0.5, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_29  ->  0.5852713178294574
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.3333333333333333, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.3333333333333333, 14: 0.0, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.3333333333333333, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 0.6666666666666666, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.5, 54: 1.0, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 0.0, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.5, 73: 0.5, 74: 0.0, 75: 1.0, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.5, 84: 1.0, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 0.5, 92: 0.5, 93: 0.0, 94: 0.5, 95: 1.0, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_29  ->  0.5852713178294574
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.3333333333333333, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.3333333333333333, 14: 0.0, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.0, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.3333333333333333, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 0.6666666666666666, 49: 0.0, 50: 1.0, 51: 0.6666666666666666, 52: 0.5, 53: 0.5, 54: 1.0, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 0.5, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.5, 73: 0.5, 74: 0.0, 75: 1.0, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.5, 84: 1.0, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.5, 94: 0.5, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_30  ->  0.5813953488372093
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.3333333333333333, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.3333333333333333, 14: 0.0, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.3333333333333333, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 0.6666666666666666, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.5, 54: 1.0, 55: 0.0, 56: 0.6666666666666666, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.5, 73: 0.5, 74: 0.0, 75: 1.0, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.5, 84: 1.0, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 0.5, 92: 0.5, 93: 0.0, 94: 0.5, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_30  ->  0.5930232558139535
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.3333333333333333, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.3333333333333333, 14: 0.0, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.3333333333333333, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 0.6666666666666666, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.5, 54: 1.0, 55: 0.0, 56: 0.6666666666666666, 57: 0.6666666666666666, 58: 0.5, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.5, 73: 0.5, 74: 0.0, 75: 1.0, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 0.5, 92: 0.5, 93: 0.0, 94: 0.5, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_31  ->  0.5852713178294574
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.3333333333333333, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.3333333333333333, 14: 0.0, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.3333333333333333, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 0.6666666666666666, 49: 0.5, 50: 1.0, 51: 0.6666666666666666, 52: 0.5, 53: 0.5, 54: 1.0, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.5, 73: 0.5, 74: 0.0, 75: 1.0, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.5, 84: 1.0, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 0.5, 92: 0.5, 93: 0.0, 94: 0.5, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_31  ->  0.5968992248062015
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.3333333333333333, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.6666666666666666, 14: 0.0, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.3333333333333333, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 0.6666666666666666, 49: 0.5, 50: 1.0, 51: 0.3333333333333333, 52: 1.0, 53: 0.5, 54: 1.0, 55: 0.0, 56: 0.6666666666666666, 57: 0.6666666666666666, 58: 0.5, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.5, 73: 0.5, 74: 0.0, 75: 1.0, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 0.5, 92: 0.5, 93: 0.0, 94: 0.5, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_32  ->  0.5968992248062015
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.3333333333333333, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.6666666666666666, 14: 0.0, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.3333333333333333, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 0.6666666666666666, 49: 0.5, 50: 1.0, 51: 0.3333333333333333, 52: 1.0, 53: 0.5, 54: 1.0, 55: 0.0, 56: 0.6666666666666666, 57: 0.6666666666666666, 58: 0.5, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.5, 73: 0.5, 74: 0.0, 75: 1.0, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 0.5, 92: 0.5, 93: 0.0, 94: 0.5, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_32  ->  0.5968992248062015
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.3333333333333333, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.3333333333333333, 14: 0.0, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.3333333333333333, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.6666666666666666, 52: 0.5, 53: 0.5, 54: 1.0, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.5, 73: 0.5, 74: 0.0, 75: 1.0, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.5, 84: 1.0, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 0.5, 92: 0.5, 93: 0.0, 94: 0.5, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_33  ->  0.5968992248062015
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.3333333333333333, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.3333333333333333, 14: 0.0, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.0, 37: 0.5, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.3333333333333333, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.5, 50: 1.0, 51: 0.3333333333333333, 52: 1.0, 53: 0.5, 54: 1.0, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 0.5, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.5, 73: 0.5, 74: 0.0, 75: 1.0, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.5, 84: 1.0, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 0.5, 92: 0.5, 93: 0.0, 94: 0.5, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_33  ->  0.5930232558139535
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.3333333333333333, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.3333333333333333, 14: 0.0, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.3333333333333333, 43: 1.0, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.5, 54: 1.0, 55: 0.0, 56: 0.6666666666666666, 57: 0.6666666666666666, 58: 0.5, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.5, 73: 0.5, 74: 0.0, 75: 1.0, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.5, 84: 1.0, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.0, 94: 0.5, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_34  ->  0.5930232558139535
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.3333333333333333, 8: 0.6666666666666666, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.3333333333333333, 14: 0.0, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.3333333333333333, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.6666666666666666, 52: 1.0, 53: 0.5, 54: 1.0, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 0.5, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.5, 73: 0.5, 74: 0.0, 75: 1.0, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.5, 84: 1.0, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 0.5, 92: 0.5, 93: 0.0, 94: 0.5, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_34  ->  0.5930232558139535
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.3333333333333333, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.3333333333333333, 14: 0.0, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.3333333333333333, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.6666666666666666, 52: 0.5, 53: 0.5, 54: 1.0, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.5, 73: 0.5, 74: 0.0, 75: 1.0, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.5, 84: 1.0, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.0, 94: 0.5, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_35  ->  0.5930232558139535
Label accuracies statistics:
{0: 1.0, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.3333333333333333, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.3333333333333333, 14: 0.0, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.3333333333333333, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.6666666666666666, 52: 0.5, 53: 0.5, 54: 1.0, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 0.5, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.5, 73: 0.5, 74: 0.0, 75: 1.0, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 0.5, 92: 0.5, 93: 0.0, 94: 0.5, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_35  ->  0.5891472868217055

The top result was recorded at 0.6007751937984496 testing accuracy. The best checkpoint is test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3NoPosEmb/checkpoint_t_23.

Any desired statistics have been plotted.
The experiment is finished.