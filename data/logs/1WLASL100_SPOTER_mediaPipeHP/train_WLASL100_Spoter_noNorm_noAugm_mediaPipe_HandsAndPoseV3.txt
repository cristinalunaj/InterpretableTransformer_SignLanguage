/PycharmProjects/spoter$ python3 train.py --experiment_name test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3 --epochs 350 --lr 0.001 --training_set_path /home/cristinalunaj/PycharmProjects/spoter/data/WLASL100/own_data/x-y/WLASL100_train.csv --validation_set_path /home/cristinalunaj/PycharmProjects/spoter/data/WLASL100/own_data/x-y/WLASL100_val.csv --testing_set_path /home/cristinalunaj/PycharmProjects/spoter/data/WLASL100/own_data/x-y/WLASL100_test.csv --hidden_dim 150 --n_heads 10
Using model originalSpoter
Starting test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3...


... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_0.pth
[1] TRAIN  loss: 4.72270280395566 acc: 0.016643550624133148
[1] VALIDATION  acc: 0.01775147928994083

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_1.pth
[2] TRAIN  loss: 4.535131753400361 acc: 0.023578363384188627
[2] VALIDATION  acc: 0.03254437869822485

[3] TRAIN  loss: 4.306171161291834 acc: 0.019417475728155338
[3] VALIDATION  acc: 0.023668639053254437

[4] TRAIN  loss: 4.2473146212745805 acc: 0.029819694868238558
[4] VALIDATION  acc: 0.03254437869822485

[5] TRAIN  loss: 4.174059264537531 acc: 0.03952843273231623
[5] VALIDATION  acc: 0.023668639053254437

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_1.pth
[6] TRAIN  loss: 4.070686770956989 acc: 0.046463245492371706
[6] VALIDATION  acc: 0.038461538461538464

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_1.pth
[7] TRAIN  loss: 3.9323088544086344 acc: 0.052704576976421634
[7] VALIDATION  acc: 0.07100591715976332

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_1.pth
[8] TRAIN  loss: 3.7953829958766243 acc: 0.07420249653259361
[8] VALIDATION  acc: 0.08284023668639054

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_1.pth
[9] TRAIN  loss: 3.6764011899740456 acc: 0.08529819694868239
[9] VALIDATION  acc: 0.08579881656804733

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_1.pth
[10] TRAIN  loss: 3.567036747684426 acc: 0.10124826629680998
[10] VALIDATION  acc: 0.09171597633136094

[11] TRAIN  loss: 3.4747906868732255 acc: 0.10402219140083217
[11] VALIDATION  acc: 0.09171597633136094

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_2.pth
[12] TRAIN  loss: 3.3892296690715997 acc: 0.1130374479889043
[12] VALIDATION  acc: 0.07988165680473373

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_2.pth
[13] TRAIN  loss: 3.3015098272927426 acc: 0.130374479889043
[13] VALIDATION  acc: 0.11538461538461539

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_2.pth
[14] TRAIN  loss: 3.209718527848446 acc: 0.13869625520110956
[14] VALIDATION  acc: 0.1242603550295858

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_2.pth
[15] TRAIN  loss: 3.14199558780858 acc: 0.16990291262135923
[15] VALIDATION  acc: 0.14201183431952663

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_2.pth
[16] TRAIN  loss: 3.0609838342947704 acc: 0.18723994452149792
[16] VALIDATION  acc: 0.15088757396449703

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_2.pth
[17] TRAIN  loss: 3.0020700104110944 acc: 0.18377253814147018
[17] VALIDATION  acc: 0.16863905325443787

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_2.pth
[18] TRAIN  loss: 2.890422245624492 acc: 0.20041608876560332
[18] VALIDATION  acc: 0.17159763313609466

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_2.pth
[19] TRAIN  loss: 2.817032346282356 acc: 0.23231622746185854
[19] VALIDATION  acc: 0.21893491124260356

[20] TRAIN  loss: 2.7424030079920976 acc: 0.24410540915395285
[20] VALIDATION  acc: 0.19822485207100593

[21] TRAIN  loss: 2.6492167030682015 acc: 0.2635228848821082
[21] VALIDATION  acc: 0.21597633136094674

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_3.pth
[22] TRAIN  loss: 2.582348201212043 acc: 0.2766990291262136
[22] VALIDATION  acc: 0.21893491124260356

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_3.pth
[23] TRAIN  loss: 2.503281336324225 acc: 0.3002773925104022
[23] VALIDATION  acc: 0.23668639053254437

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_3.pth
[24] TRAIN  loss: 2.4386304218874892 acc: 0.3259361997226075
[24] VALIDATION  acc: 0.24260355029585798

[25] TRAIN  loss: 2.328948852217313 acc: 0.33841886269070737
[25] VALIDATION  acc: 0.21005917159763313

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_3.pth
[26] TRAIN  loss: 2.280457288822503 acc: 0.36893203883495146
[26] VALIDATION  acc: 0.3165680473372781

[27] TRAIN  loss: 2.219886026630661 acc: 0.3682385575589459
[27] VALIDATION  acc: 0.28106508875739644

[28] TRAIN  loss: 2.1333531984509113 acc: 0.3897364771151179
[28] VALIDATION  acc: 0.28106508875739644

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_3.pth
[29] TRAIN  loss: 2.0219001854549004 acc: 0.41678224687933424
[29] VALIDATION  acc: 0.363905325443787

[30] TRAIN  loss: 1.9634941724670247 acc: 0.43828016643550627
[30] VALIDATION  acc: 0.3254437869822485

[31] TRAIN  loss: 1.898776264305791 acc: 0.44937586685159503
[31] VALIDATION  acc: 0.33727810650887574

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_4.pth
[32] TRAIN  loss: 1.8036062271022928 acc: 0.470873786407767
[32] VALIDATION  acc: 0.3757396449704142

[33] TRAIN  loss: 1.7445088303344383 acc: 0.4798890429958391
[33] VALIDATION  acc: 0.3165680473372781

[34] TRAIN  loss: 1.66073459510313 acc: 0.5104022191400832
[34] VALIDATION  acc: 0.3165680473372781

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_4.pth
[35] TRAIN  loss: 1.6180188875082213 acc: 0.515256588072122
[35] VALIDATION  acc: 0.41420118343195267

[36] TRAIN  loss: 1.517593617715076 acc: 0.5499306518723994
[36] VALIDATION  acc: 0.3994082840236686

[37] TRAIN  loss: 1.4506717135667304 acc: 0.5700416088765603
[37] VALIDATION  acc: 0.363905325443787

[38] TRAIN  loss: 1.4031433568370946 acc: 0.5804438280166435
[38] VALIDATION  acc: 0.3905325443786982

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_4.pth
[39] TRAIN  loss: 1.3810243223575507 acc: 0.5804438280166435
[39] VALIDATION  acc: 0.4319526627218935

[40] TRAIN  loss: 1.3153007848552543 acc: 0.5957004160887656
[40] VALIDATION  acc: 0.3905325443786982

[41] TRAIN  loss: 1.2419592655779232 acc: 0.6310679611650486
[41] VALIDATION  acc: 0.4230769230769231

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_5.pth
[42] TRAIN  loss: 1.2118081625941082 acc: 0.6449375866851595
[42] VALIDATION  acc: 0.41420118343195267

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_5.pth
[43] TRAIN  loss: 1.142315712902726 acc: 0.658113730929265
[43] VALIDATION  acc: 0.4526627218934911

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_5.pth
[44] TRAIN  loss: 1.0968171618982179 acc: 0.6608876560332871
[44] VALIDATION  acc: 0.47041420118343197

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_5.pth
[45] TRAIN  loss: 1.0360468126686184 acc: 0.6865464632454924
[45] VALIDATION  acc: 0.47337278106508873

[46] TRAIN  loss: 1.0337022486421823 acc: 0.6726768377253814
[46] VALIDATION  acc: 0.41420118343195267

[47] TRAIN  loss: 0.9950628016581927 acc: 0.687239944521498
[47] VALIDATION  acc: 0.4230769230769231

[48] TRAIN  loss: 0.9321781778359339 acc: 0.7059639389736477
[48] VALIDATION  acc: 0.3994082840236686

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_5.pth
[49] TRAIN  loss: 0.8811071970985734 acc: 0.739251040221914
[49] VALIDATION  acc: 0.4822485207100592

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_5.pth
[50] TRAIN  loss: 0.832987893716046 acc: 0.7565880721220527
[50] VALIDATION  acc: 0.4970414201183432

[51] TRAIN  loss: 0.7825349733254765 acc: 0.7447988904299584
[51] VALIDATION  acc: 0.44970414201183434

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_6.pth
[52] TRAIN  loss: 0.7983485589239193 acc: 0.7434119278779473
[52] VALIDATION  acc: 0.47928994082840237

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_6.pth
[53] TRAIN  loss: 0.7247095454499402 acc: 0.7836338418862691
[53] VALIDATION  acc: 0.5029585798816568

[54] TRAIN  loss: 0.6869005047139453 acc: 0.7829403606102635
[54] VALIDATION  acc: 0.4467455621301775

[55] TRAIN  loss: 0.6800467139935049 acc: 0.7884882108183079
[55] VALIDATION  acc: 0.48520710059171596

[56] TRAIN  loss: 0.6088628459414377 acc: 0.8183079056865464
[56] VALIDATION  acc: 0.48520710059171596

[57] TRAIN  loss: 0.6061878016657078 acc: 0.8203883495145631
[57] VALIDATION  acc: 0.47337278106508873

[58] TRAIN  loss: 0.5885087496103091 acc: 0.8280166435506241
[58] VALIDATION  acc: 0.4349112426035503

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_6.pth
[59] TRAIN  loss: 0.5154123740372779 acc: 0.8488210818307905
[59] VALIDATION  acc: 0.514792899408284

[60] TRAIN  loss: 0.4834360803277897 acc: 0.8522884882108183
[60] VALIDATION  acc: 0.5059171597633136

[61] TRAIN  loss: 0.4959094477013327 acc: 0.8578363384188626
[61] VALIDATION  acc: 0.4822485207100592

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_7.pth
[62] TRAIN  loss: 0.4054816290758803 acc: 0.891123439667129
[62] VALIDATION  acc: 0.5088757396449705

[63] TRAIN  loss: 0.4849241768820831 acc: 0.8550624133148405
[63] VALIDATION  acc: 0.4911242603550296

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_7.pth
[64] TRAIN  loss: 0.41377079155135915 acc: 0.875866851595007
[64] VALIDATION  acc: 0.5443786982248521

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_7.pth
[65] TRAIN  loss: 0.40147287043453495 acc: 0.8807212205270458
[65] VALIDATION  acc: 0.5562130177514792

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_7.pth
[66] TRAIN  loss: 0.32829909141601066 acc: 0.9056865464632455
[66] VALIDATION  acc: 0.5769230769230769

[67] TRAIN  loss: 0.3170657715324704 acc: 0.9230235783633842
[67] VALIDATION  acc: 0.5355029585798816

[68] TRAIN  loss: 0.2805104026932272 acc: 0.9216366158113731
[68] VALIDATION  acc: 0.5325443786982249

[69] TRAIN  loss: 0.40292870088534666 acc: 0.8841886269070736
[69] VALIDATION  acc: 0.46449704142011833

[70] TRAIN  loss: 0.32173473716502937 acc: 0.9029126213592233
[70] VALIDATION  acc: 0.5443786982248521

[71] TRAIN  loss: 0.3427943316880541 acc: 0.9029126213592233
[71] VALIDATION  acc: 0.5739644970414202

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_8.pth
[72] TRAIN  loss: 0.21543848148777037 acc: 0.9486823855755895
[72] VALIDATION  acc: 0.514792899408284

[73] TRAIN  loss: 0.24480049378032268 acc: 0.9292649098474342
[73] VALIDATION  acc: 0.5088757396449705

[74] TRAIN  loss: 0.2494406118625213 acc: 0.9368932038834952
[74] VALIDATION  acc: 0.5118343195266272

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_8.pth
[75] TRAIN  loss: 0.24195184498496874 acc: 0.934119278779473
[75] VALIDATION  acc: 0.5207100591715976

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_8.pth
[76] TRAIN  loss: 0.2094407352347937 acc: 0.9479889042995839
[76] VALIDATION  acc: 0.5710059171597633

[77] TRAIN  loss: 0.16273251425257068 acc: 0.963245492371706
[77] VALIDATION  acc: 0.5591715976331361

[78] TRAIN  loss: 0.2474413902918426 acc: 0.9292649098474342
[78] VALIDATION  acc: 0.46745562130177515

[79] TRAIN  loss: 0.25631331278089675 acc: 0.9285714285714286
[79] VALIDATION  acc: 0.5325443786982249

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_8.pth
[80] TRAIN  loss: 0.1320266532019813 acc: 0.9722607489597781
[80] VALIDATION  acc: 0.606508875739645

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_8.pth
[81] TRAIN  loss: 0.09257652024463518 acc: 0.984743411927878
[81] VALIDATION  acc: 0.6094674556213018

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_9.pth
[82] TRAIN  loss: 0.10202728517873609 acc: 0.9694868238557559
[82] VALIDATION  acc: 0.5680473372781065

[83] TRAIN  loss: 0.12004988343546448 acc: 0.9736477115117892
[83] VALIDATION  acc: 0.5414201183431953

[84] TRAIN  loss: 0.3152150216392253 acc: 0.9133148404993066
[84] VALIDATION  acc: 0.48520710059171596

[85] TRAIN  loss: 0.3292314141664858 acc: 0.9036061026352289
[85] VALIDATION  acc: 0.5325443786982249

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_9.pth
[86] TRAIN  loss: 0.12009873746749145 acc: 0.9736477115117892
[86] VALIDATION  acc: 0.5946745562130178

[87] TRAIN  loss: 0.058054150084794746 acc: 0.9902912621359223
[87] VALIDATION  acc: 0.5798816568047337

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_9.pth
[88] TRAIN  loss: 0.08061935759068599 acc: 0.9819694868238558
[88] VALIDATION  acc: 0.6005917159763313

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_9.pth
[89] TRAIN  loss: 0.06827969159857479 acc: 0.9868238557558946
[89] VALIDATION  acc: 0.6242603550295858

[90] TRAIN  loss: 0.0617180403465119 acc: 0.9854368932038835
[90] VALIDATION  acc: 0.6005917159763313

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_9.pth
[91] TRAIN  loss: 0.06108917851262918 acc: 0.9895977808599168
[91] VALIDATION  acc: 0.6390532544378699

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_10.pth
[92] TRAIN  loss: 0.04796204287333552 acc: 0.9895977808599168
[92] VALIDATION  acc: 0.5828402366863905

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_10.pth
[93] TRAIN  loss: 0.03817347994201136 acc: 0.9944521497919556
[93] VALIDATION  acc: 0.6242603550295858

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_10.pth
[94] TRAIN  loss: 0.03478965375507212 acc: 0.9944521497919556
[94] VALIDATION  acc: 0.6331360946745562

[95] TRAIN  loss: 0.03572598664920284 acc: 0.9937586685159501
[95] VALIDATION  acc: 0.6094674556213018

[96] TRAIN  loss: 0.04247110109056453 acc: 0.9909847434119279
[96] VALIDATION  acc: 0.6183431952662722

[97] TRAIN  loss: 0.03425405648401835 acc: 0.992371705963939
[97] VALIDATION  acc: 0.6094674556213018

[98] TRAIN  loss: 0.025925541576982996 acc: 0.9951456310679612
[98] VALIDATION  acc: 0.6183431952662722

[99] TRAIN  loss: 0.026988149059021874 acc: 0.9951456310679612
[99] VALIDATION  acc: 0.6301775147928994

[100] TRAIN  loss: 0.04460037228548493 acc: 0.9895977808599168
[100] VALIDATION  acc: 0.5887573964497042

[101] TRAIN  loss: 0.05966074140788438 acc: 0.984743411927878
[101] VALIDATION  acc: 0.5828402366863905

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_11.pth
[102] TRAIN  loss: 0.05744026123559627 acc: 0.9875173370319001
[102] VALIDATION  acc: 0.6331360946745562

[103] TRAIN  loss: 0.041042937319327746 acc: 0.9930651872399445
[103] VALIDATION  acc: 0.5946745562130178

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_11.pth
[104] TRAIN  loss: 0.03047557609474584 acc: 0.9944521497919556
[104] VALIDATION  acc: 0.6420118343195266

[105] TRAIN  loss: 0.025145198910638572 acc: 0.9951456310679612
[105] VALIDATION  acc: 0.6272189349112426

[106] TRAIN  loss: 0.021475519377312135 acc: 0.9958391123439667
[106] VALIDATION  acc: 0.6272189349112426

[107] TRAIN  loss: 0.02368112531098348 acc: 0.9937586685159501
[107] VALIDATION  acc: 0.6331360946745562

[108] TRAIN  loss: 0.019268796513910308 acc: 0.9951456310679612
[108] VALIDATION  acc: 0.621301775147929

[109] TRAIN  loss: 0.02134895132062682 acc: 0.9958391123439667
[109] VALIDATION  acc: 0.6183431952662722

[110] TRAIN  loss: 0.018911425238694796 acc: 0.9958391123439667
[110] VALIDATION  acc: 0.6420118343195266

[111] TRAIN  loss: 0.018076531518511952 acc: 0.9972260748959778
[111] VALIDATION  acc: 0.6272189349112426

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_12.pth
[112] TRAIN  loss: 0.018148803616715364 acc: 0.9958391123439667
[112] VALIDATION  acc: 0.6153846153846154

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_12.pth
[113] TRAIN  loss: 0.017114218092298596 acc: 0.9958391123439667
[113] VALIDATION  acc: 0.636094674556213

[114] TRAIN  loss: 0.018405269662931628 acc: 0.9958391123439667
[114] VALIDATION  acc: 0.636094674556213

[115] TRAIN  loss: 0.016806572493795923 acc: 0.9958391123439667
[115] VALIDATION  acc: 0.6183431952662722

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_12.pth
[116] TRAIN  loss: 0.017863995980543387 acc: 0.9958391123439667
[116] VALIDATION  acc: 0.6420118343195266

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_12.pth
[117] TRAIN  loss: 0.016210403454370685 acc: 0.9965325936199723
[117] VALIDATION  acc: 0.6449704142011834

[118] TRAIN  loss: 0.015877924921283634 acc: 0.9958391123439667
[118] VALIDATION  acc: 0.6331360946745562

[119] TRAIN  loss: 0.015527184201053592 acc: 0.9965325936199723
[119] VALIDATION  acc: 0.6420118343195266

[120] TRAIN  loss: 0.01754591992474807 acc: 0.9951456310679612
[120] VALIDATION  acc: 0.636094674556213

[121] TRAIN  loss: 0.01412418593926066 acc: 0.9965325936199723
[121] VALIDATION  acc: 0.6449704142011834

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_13.pth
[122] TRAIN  loss: 0.015556249183043321 acc: 0.9944521497919556
[122] VALIDATION  acc: 0.636094674556213

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_13.pth
[123] TRAIN  loss: 0.013944528004366566 acc: 0.9965325936199723
[123] VALIDATION  acc: 0.6420118343195266

[124] TRAIN  loss: 0.01546391643398172 acc: 0.9958391123439667
[124] VALIDATION  acc: 0.6331360946745562

[125] TRAIN  loss: 0.014681564167398803 acc: 0.9965325936199723
[125] VALIDATION  acc: 0.6420118343195266

[126] TRAIN  loss: 0.013971871489981233 acc: 0.9958391123439667
[126] VALIDATION  acc: 0.6390532544378699

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_13.pth
[127] TRAIN  loss: 0.014798614344642441 acc: 0.9951456310679612
[127] VALIDATION  acc: 0.6449704142011834

[128] TRAIN  loss: 0.014422440668245088 acc: 0.9958391123439667
[128] VALIDATION  acc: 0.6390532544378699

[129] TRAIN  loss: 0.013530828703625803 acc: 0.9951456310679612
[129] VALIDATION  acc: 0.6242603550295858

[130] TRAIN  loss: 0.01473074059100231 acc: 0.9951456310679612
[130] VALIDATION  acc: 0.636094674556213

[131] TRAIN  loss: 0.013969494847945456 acc: 0.9958391123439667
[131] VALIDATION  acc: 0.6331360946745562

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_14.pth
[132] TRAIN  loss: 0.013979353539357217 acc: 0.9958391123439667
[132] VALIDATION  acc: 0.636094674556213

[133] TRAIN  loss: 0.013237003454298811 acc: 0.9965325936199723
[133] VALIDATION  acc: 0.636094674556213

[134] TRAIN  loss: 0.014092117963535886 acc: 0.9944521497919556
[134] VALIDATION  acc: 0.6331360946745562

[135] TRAIN  loss: 0.01235795866763581 acc: 0.9965325936199723
[135] VALIDATION  acc: 0.6331360946745562

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_14.pth
[136] TRAIN  loss: 0.012568697810662915 acc: 0.9951456310679612
[136] VALIDATION  acc: 0.6479289940828402

[137] TRAIN  loss: 0.013879580160887669 acc: 0.9965325936199723
[137] VALIDATION  acc: 0.636094674556213

[138] TRAIN  loss: 0.012761387374206387 acc: 0.9958391123439667
[138] VALIDATION  acc: 0.6272189349112426

[139] TRAIN  loss: 0.012599429109678881 acc: 0.9958391123439667
[139] VALIDATION  acc: 0.6420118343195266

[140] TRAIN  loss: 0.013680750445948608 acc: 0.9951456310679612
[140] VALIDATION  acc: 0.6420118343195266

[141] TRAIN  loss: 0.011674865557807794 acc: 0.9958391123439667
[141] VALIDATION  acc: 0.6420118343195266

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_15.pth
[142] TRAIN  loss: 0.011905088080990195 acc: 0.9958391123439667
[142] VALIDATION  acc: 0.6390532544378699

[143] TRAIN  loss: 0.011398043968673924 acc: 0.9958391123439667
[143] VALIDATION  acc: 0.6301775147928994

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_15.pth
[144] TRAIN  loss: 0.013230378854437409 acc: 0.9951456310679612
[144] VALIDATION  acc: 0.6449704142011834

[145] TRAIN  loss: 0.012222510517461257 acc: 0.9951456310679612
[145] VALIDATION  acc: 0.6420118343195266

[146] TRAIN  loss: 0.012421394743773849 acc: 0.9951456310679612
[146] VALIDATION  acc: 0.6420118343195266

[147] TRAIN  loss: 0.01147025418325328 acc: 0.9951456310679612
[147] VALIDATION  acc: 0.6420118343195266

[148] TRAIN  loss: 0.010869887615997656 acc: 0.9979195561719834
[148] VALIDATION  acc: 0.6331360946745562

[149] TRAIN  loss: 0.011599282132098859 acc: 0.9958391123439667
[149] VALIDATION  acc: 0.6420118343195266

[150] TRAIN  loss: 0.011059969225891926 acc: 0.9965325936199723
[150] VALIDATION  acc: 0.636094674556213

[151] TRAIN  loss: 0.011317554678752258 acc: 0.9958391123439667
[151] VALIDATION  acc: 0.6331360946745562

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_16.pth
[152] TRAIN  loss: 0.011238396550121332 acc: 0.9958391123439667
[152] VALIDATION  acc: 0.6449704142011834

[153] TRAIN  loss: 0.011792603832293023 acc: 0.9958391123439667
[153] VALIDATION  acc: 0.6420118343195266

[154] TRAIN  loss: 0.012034217010580918 acc: 0.9951456310679612
[154] VALIDATION  acc: 0.6242603550295858

[155] TRAIN  loss: 0.012354403245093265 acc: 0.9958391123439667
[155] VALIDATION  acc: 0.636094674556213

[156] TRAIN  loss: 0.011243439366444868 acc: 0.9958391123439667
[156] VALIDATION  acc: 0.6390532544378699

[157] TRAIN  loss: 0.011313146899290248 acc: 0.9958391123439667
[157] VALIDATION  acc: 0.636094674556213

[158] TRAIN  loss: 0.011764531226275843 acc: 0.9944521497919556
[158] VALIDATION  acc: 0.6420118343195266

[159] TRAIN  loss: 0.010912224461087 acc: 0.9958391123439667
[159] VALIDATION  acc: 0.6390532544378699

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_16.pth
[160] TRAIN  loss: 0.010055935443410066 acc: 0.9972260748959778
[160] VALIDATION  acc: 0.6479289940828402

[161] TRAIN  loss: 0.012143948235275029 acc: 0.9951456310679612
[161] VALIDATION  acc: 0.621301775147929

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_17.pth
[162] TRAIN  loss: 0.011461096069883379 acc: 0.9965325936199723
[162] VALIDATION  acc: 0.650887573964497

[163] TRAIN  loss: 0.010789259066679302 acc: 0.9958391123439667
[163] VALIDATION  acc: 0.6301775147928994

[164] TRAIN  loss: 0.010015082640559496 acc: 0.9958391123439667
[164] VALIDATION  acc: 0.6420118343195266

[165] TRAIN  loss: 0.010103095183019809 acc: 0.9958391123439667
[165] VALIDATION  acc: 0.636094674556213

[166] TRAIN  loss: 0.0105452257775849 acc: 0.9958391123439667
[166] VALIDATION  acc: 0.6390532544378699

[167] TRAIN  loss: 0.012165538237526065 acc: 0.9958391123439667
[167] VALIDATION  acc: 0.6420118343195266

[168] TRAIN  loss: 0.009581615592675327 acc: 0.9965325936199723
[168] VALIDATION  acc: 0.6479289940828402

[169] TRAIN  loss: 0.010522486668573928 acc: 0.9958391123439667
[169] VALIDATION  acc: 0.6449704142011834

[170] TRAIN  loss: 0.011209252670230653 acc: 0.9951456310679612
[170] VALIDATION  acc: 0.6390532544378699

[171] TRAIN  loss: 0.009592739501496956 acc: 0.9958391123439667
[171] VALIDATION  acc: 0.6301775147928994

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_18.pth
[172] TRAIN  loss: 0.010223855626446114 acc: 0.9944521497919556
[172] VALIDATION  acc: 0.6301775147928994

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_18.pth
[173] TRAIN  loss: 0.010570353468690015 acc: 0.9958391123439667
[173] VALIDATION  acc: 0.650887573964497

[174] TRAIN  loss: 0.01090529693587321 acc: 0.9951456310679612
[174] VALIDATION  acc: 0.6301775147928994

[175] TRAIN  loss: 0.009753182661259368 acc: 0.9972260748959778
[175] VALIDATION  acc: 0.6301775147928994

[176] TRAIN  loss: 0.011214138643630269 acc: 0.9958391123439667
[176] VALIDATION  acc: 0.6272189349112426

[177] TRAIN  loss: 0.009402286608023027 acc: 0.9965325936199723
[177] VALIDATION  acc: 0.6272189349112426

[178] TRAIN  loss: 0.011198851727875209 acc: 0.9951456310679612
[178] VALIDATION  acc: 0.6479289940828402

[179] TRAIN  loss: 0.010180997188441116 acc: 0.9951456310679612
[179] VALIDATION  acc: 0.636094674556213

[180] TRAIN  loss: 0.008898608913645068 acc: 0.9965325936199723
[180] VALIDATION  acc: 0.636094674556213

[181] TRAIN  loss: 0.009665800181579816 acc: 0.9972260748959778
[181] VALIDATION  acc: 0.6331360946745562

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_19.pth
[182] TRAIN  loss: 0.008838805692536329 acc: 0.9972260748959778
[182] VALIDATION  acc: 0.6420118343195266

[183] TRAIN  loss: 0.008839827386420007 acc: 0.9958391123439667
[183] VALIDATION  acc: 0.6420118343195266

[184] TRAIN  loss: 0.009927969024033543 acc: 0.9951456310679612
[184] VALIDATION  acc: 0.6301775147928994

[185] TRAIN  loss: 0.0093677480604652 acc: 0.9958391123439667
[185] VALIDATION  acc: 0.6420118343195266

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_19.pth
[186] TRAIN  loss: 0.009384667137540048 acc: 0.9951456310679612
[186] VALIDATION  acc: 0.6479289940828402

[187] TRAIN  loss: 0.009744481311931957 acc: 0.9972260748959778
[187] VALIDATION  acc: 0.6242603550295858

[188] TRAIN  loss: 0.009542854630545182 acc: 0.9958391123439667
[188] VALIDATION  acc: 0.6390532544378699

[189] TRAIN  loss: 0.010147389702260107 acc: 0.9951456310679612
[189] VALIDATION  acc: 0.636094674556213

[190] TRAIN  loss: 0.009505346209058168 acc: 0.9965325936199723
[190] VALIDATION  acc: 0.6479289940828402

[191] TRAIN  loss: 0.009660616101883256 acc: 0.9951456310679612
[191] VALIDATION  acc: 0.636094674556213

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_20.pth
[192] TRAIN  loss: 0.00845502709282285 acc: 0.9972260748959778
[192] VALIDATION  acc: 0.6272189349112426

[193] TRAIN  loss: 0.008647176515198059 acc: 0.9965325936199723
[193] VALIDATION  acc: 0.6272189349112426

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_20.pth
[194] TRAIN  loss: 0.009277543639790024 acc: 0.9958391123439667
[194] VALIDATION  acc: 0.6420118343195266

[195] TRAIN  loss: 0.009761627570278077 acc: 0.9951456310679612
[195] VALIDATION  acc: 0.636094674556213

[196] TRAIN  loss: 0.00882347314501265 acc: 0.9958391123439667
[196] VALIDATION  acc: 0.636094674556213

[197] TRAIN  loss: 0.009009776789278933 acc: 0.9958391123439667
[197] VALIDATION  acc: 0.6331360946745562

[198] TRAIN  loss: 0.008052877051786343 acc: 0.9965325936199723
[198] VALIDATION  acc: 0.6390532544378699

[199] TRAIN  loss: 0.008787556180141362 acc: 0.9958391123439667
[199] VALIDATION  acc: 0.6390532544378699

[200] TRAIN  loss: 0.010467238806265367 acc: 0.9951456310679612
[200] VALIDATION  acc: 0.6420118343195266

[201] TRAIN  loss: 0.00925332702503455 acc: 0.9965325936199723
[201] VALIDATION  acc: 0.6242603550295858

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_21.pth
[202] TRAIN  loss: 0.009223591808470911 acc: 0.9958391123439667
[202] VALIDATION  acc: 0.636094674556213

[203] TRAIN  loss: 0.009660274264265524 acc: 0.9944521497919556
[203] VALIDATION  acc: 0.6272189349112426

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_21.pth
[204] TRAIN  loss: 0.008915354113053577 acc: 0.9951456310679612
[204] VALIDATION  acc: 0.6420118343195266

[205] TRAIN  loss: 0.010225523065241349 acc: 0.9944521497919556
[205] VALIDATION  acc: 0.6390532544378699

[206] TRAIN  loss: 0.008324718669893436 acc: 0.9951456310679612
[206] VALIDATION  acc: 0.6331360946745562

[207] TRAIN  loss: 0.009783931275944393 acc: 0.9951456310679612
[207] VALIDATION  acc: 0.6331360946745562

[208] TRAIN  loss: 0.00803766059957859 acc: 0.9965325936199723
[208] VALIDATION  acc: 0.6420118343195266

[209] TRAIN  loss: 0.008073289964484353 acc: 0.9958391123439667
[209] VALIDATION  acc: 0.6301775147928994

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_21.pth
[210] TRAIN  loss: 0.009156614473294553 acc: 0.9958391123439667
[210] VALIDATION  acc: 0.6449704142011834

[211] TRAIN  loss: 0.008601875388585502 acc: 0.9958391123439667
[211] VALIDATION  acc: 0.6331360946745562

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_22.pth
[212] TRAIN  loss: 0.009210951850447737 acc: 0.9958391123439667
[212] VALIDATION  acc: 0.636094674556213

[213] TRAIN  loss: 0.008599725993183517 acc: 0.9965325936199723
[213] VALIDATION  acc: 0.636094674556213

[214] TRAIN  loss: 0.00818455067837048 acc: 0.9965325936199723
[214] VALIDATION  acc: 0.636094674556213

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_22.pth
[215] TRAIN  loss: 0.008095481247028715 acc: 0.9965325936199723
[215] VALIDATION  acc: 0.6390532544378699

[216] TRAIN  loss: 0.009886060016085118 acc: 0.9958391123439667
[216] VALIDATION  acc: 0.636094674556213

[217] TRAIN  loss: 0.008702976675276242 acc: 0.9958391123439667
[217] VALIDATION  acc: 0.636094674556213

[218] TRAIN  loss: 0.009606489145076119 acc: 0.9965325936199723
[218] VALIDATION  acc: 0.6390532544378699

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_22.pth
[219] TRAIN  loss: 0.00918216444342042 acc: 0.9944521497919556
[219] VALIDATION  acc: 0.6449704142011834

[220] TRAIN  loss: 0.008287912443900725 acc: 0.9951456310679612
[220] VALIDATION  acc: 0.636094674556213

[221] TRAIN  loss: 0.00863976994650545 acc: 0.9951456310679612
[221] VALIDATION  acc: 0.6272189349112426

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_23.pth
[222] TRAIN  loss: 0.008953011820913275 acc: 0.9958391123439667
[222] VALIDATION  acc: 0.636094674556213

[223] TRAIN  loss: 0.00786137118136824 acc: 0.9965325936199723
[223] VALIDATION  acc: 0.636094674556213

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_23.pth
[224] TRAIN  loss: 0.007379116633550207 acc: 0.9965325936199723
[224] VALIDATION  acc: 0.6420118343195266

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_23.pth
[225] TRAIN  loss: 0.008320608663023287 acc: 0.9972260748959778
[225] VALIDATION  acc: 0.6449704142011834

[226] TRAIN  loss: 0.008691296929935715 acc: 0.9958391123439667
[226] VALIDATION  acc: 0.6449704142011834

[227] TRAIN  loss: 0.00851109147944812 acc: 0.9958391123439667
[227] VALIDATION  acc: 0.6301775147928994

[228] TRAIN  loss: 0.00833040317795593 acc: 0.9944521497919556
[228] VALIDATION  acc: 0.6390532544378699

[229] TRAIN  loss: 0.008609839318049583 acc: 0.9958391123439667
[229] VALIDATION  acc: 0.6390532544378699

[230] TRAIN  loss: 0.007925713502640248 acc: 0.9958391123439667
[230] VALIDATION  acc: 0.6390532544378699

[231] TRAIN  loss: 0.008218294922426518 acc: 0.9965325936199723
[231] VALIDATION  acc: 0.6390532544378699

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_24.pth
[232] TRAIN  loss: 0.008464858601282193 acc: 0.9958391123439667
[232] VALIDATION  acc: 0.6420118343195266

[233] TRAIN  loss: 0.007835192041078316 acc: 0.9958391123439667
[233] VALIDATION  acc: 0.6420118343195266

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_24.pth
[234] TRAIN  loss: 0.007664329306221973 acc: 0.9979195561719834
[234] VALIDATION  acc: 0.6479289940828402

[235] TRAIN  loss: 0.007572907041160278 acc: 0.9965325936199723
[235] VALIDATION  acc: 0.6420118343195266

[236] TRAIN  loss: 0.00833816549307666 acc: 0.9958391123439667
[236] VALIDATION  acc: 0.6390532544378699

[237] TRAIN  loss: 0.009728167680121502 acc: 0.9951456310679612
[237] VALIDATION  acc: 0.6449704142011834

[238] TRAIN  loss: 0.007376844691777545 acc: 0.9951456310679612
[238] VALIDATION  acc: 0.6420118343195266

[239] TRAIN  loss: 0.008831191454576604 acc: 0.9951456310679612
[239] VALIDATION  acc: 0.6331360946745562

[240] TRAIN  loss: 0.007870684097023376 acc: 0.9965325936199723
[240] VALIDATION  acc: 0.6449704142011834

[241] TRAIN  loss: 0.008571466123271894 acc: 0.9958391123439667
[241] VALIDATION  acc: 0.6420118343195266

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_25.pth
[242] TRAIN  loss: 0.008893251074927706 acc: 0.9958391123439667
[242] VALIDATION  acc: 0.6390532544378699

[243] TRAIN  loss: 0.00825052421149522 acc: 0.9965325936199723
[243] VALIDATION  acc: 0.6331360946745562

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_25.pth
[244] TRAIN  loss: 0.008771149485805577 acc: 0.9958391123439667
[244] VALIDATION  acc: 0.6420118343195266

[245] TRAIN  loss: 0.008217640958503424 acc: 0.9965325936199723
[245] VALIDATION  acc: 0.636094674556213

[246] TRAIN  loss: 0.008169481517777641 acc: 0.9965325936199723
[246] VALIDATION  acc: 0.6390532544378699

[247] TRAIN  loss: 0.00783941813992411 acc: 0.9944521497919556
[247] VALIDATION  acc: 0.6420118343195266

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_25.pth
[248] TRAIN  loss: 0.007440855833806539 acc: 0.9958391123439667
[248] VALIDATION  acc: 0.6449704142011834

[249] TRAIN  loss: 0.008030478652604535 acc: 0.9965325936199723
[249] VALIDATION  acc: 0.636094674556213

[250] TRAIN  loss: 0.007425173023600694 acc: 0.9965325936199723
[250] VALIDATION  acc: 0.6449704142011834

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_25.pth
[251] TRAIN  loss: 0.007947252910334265 acc: 0.9951456310679612
[251] VALIDATION  acc: 0.6479289940828402

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_26.pth
[252] TRAIN  loss: 0.007973835005508837 acc: 0.9972260748959778
[252] VALIDATION  acc: 0.6479289940828402

[253] TRAIN  loss: 0.00812441084410955 acc: 0.9951456310679612
[253] VALIDATION  acc: 0.6479289940828402

[254] TRAIN  loss: 0.00813029688462303 acc: 0.9958391123439667
[254] VALIDATION  acc: 0.6420118343195266

[255] TRAIN  loss: 0.007228890628274474 acc: 0.9965325936199723
[255] VALIDATION  acc: 0.636094674556213

[256] TRAIN  loss: 0.007052187709213766 acc: 0.9972260748959778
[256] VALIDATION  acc: 0.6479289940828402

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_26.pth
[257] TRAIN  loss: 0.007281761356547206 acc: 0.9958391123439667
[257] VALIDATION  acc: 0.650887573964497

[258] TRAIN  loss: 0.008087328239499468 acc: 0.9951456310679612
[258] VALIDATION  acc: 0.6479289940828402

[259] TRAIN  loss: 0.009114206606508196 acc: 0.9958391123439667
[259] VALIDATION  acc: 0.650887573964497

[260] TRAIN  loss: 0.00884099722813533 acc: 0.9951456310679612
[260] VALIDATION  acc: 0.6479289940828402

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_26.pth
[261] TRAIN  loss: 0.006628207455544166 acc: 0.9972260748959778
[261] VALIDATION  acc: 0.6538461538461539

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_27.pth
[262] TRAIN  loss: 0.005913786048146453 acc: 0.9979195561719834
[262] VALIDATION  acc: 0.6568047337278107

[263] TRAIN  loss: 0.007720312919262951 acc: 0.9958391123439667
[263] VALIDATION  acc: 0.6390532544378699

[264] TRAIN  loss: 0.00813669384768372 acc: 0.9958391123439667
[264] VALIDATION  acc: 0.6449704142011834

[265] TRAIN  loss: 0.007335393314724759 acc: 0.9965325936199723
[265] VALIDATION  acc: 0.6420118343195266

[266] TRAIN  loss: 0.007592668771767913 acc: 0.9958391123439667
[266] VALIDATION  acc: 0.6479289940828402

[267] TRAIN  loss: 0.006627198182537546 acc: 0.9965325936199723
[267] VALIDATION  acc: 0.6420118343195266

[268] TRAIN  loss: 0.008029130282407556 acc: 0.9965325936199723
[268] VALIDATION  acc: 0.6420118343195266

[269] TRAIN  loss: 0.007366640658072661 acc: 0.9965325936199723
[269] VALIDATION  acc: 0.6479289940828402

[270] TRAIN  loss: 0.007258896787886257 acc: 0.9951456310679612
[270] VALIDATION  acc: 0.6479289940828402

[271] TRAIN  loss: 0.007211985442869634 acc: 0.9958391123439667
[271] VALIDATION  acc: 0.6538461538461539

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_28.pth
[272] TRAIN  loss: 0.007171839852815944 acc: 0.9951456310679612
[272] VALIDATION  acc: 0.636094674556213

[273] TRAIN  loss: 0.008218653753966626 acc: 0.9951456310679612
[273] VALIDATION  acc: 0.636094674556213

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_28.pth
[274] TRAIN  loss: 0.007138962901484617 acc: 0.9951456310679612
[274] VALIDATION  acc: 0.6390532544378699

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_28.pth
[275] TRAIN  loss: 0.007745205959544214 acc: 0.9951456310679612
[275] VALIDATION  acc: 0.6449704142011834

[276] TRAIN  loss: 0.007010094248151028 acc: 0.9958391123439667
[276] VALIDATION  acc: 0.6449704142011834

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_28.pth
[277] TRAIN  loss: 0.007773621537976226 acc: 0.9958391123439667
[277] VALIDATION  acc: 0.6479289940828402

[278] TRAIN  loss: 0.006614999891111319 acc: 0.9965325936199723
[278] VALIDATION  acc: 0.6420118343195266

[279] TRAIN  loss: 0.007631342482410633 acc: 0.9951456310679612
[279] VALIDATION  acc: 0.6331360946745562

[280] TRAIN  loss: 0.00719291028676474 acc: 0.9965325936199723
[280] VALIDATION  acc: 0.6479289940828402

[281] TRAIN  loss: 0.0068092638532117325 acc: 0.9965325936199723
[281] VALIDATION  acc: 0.6390532544378699

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_29.pth
[282] TRAIN  loss: 0.006964777082769699 acc: 0.9951456310679612
[282] VALIDATION  acc: 0.6390532544378699

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_29.pth
[283] TRAIN  loss: 0.008068832543691458 acc: 0.9951456310679612
[283] VALIDATION  acc: 0.6449704142011834

[284] TRAIN  loss: 0.007307701430601933 acc: 0.9965325936199723
[284] VALIDATION  acc: 0.6390532544378699

[285] TRAIN  loss: 0.00764328657753541 acc: 0.9972260748959778
[285] VALIDATION  acc: 0.6449704142011834

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_29.pth
[286] TRAIN  loss: 0.007290046871409703 acc: 0.9958391123439667
[286] VALIDATION  acc: 0.6479289940828402

[287] TRAIN  loss: 0.00653855575948302 acc: 0.9958391123439667
[287] VALIDATION  acc: 0.6420118343195266

[288] TRAIN  loss: 0.007075562789966086 acc: 0.9951456310679612
[288] VALIDATION  acc: 0.6390532544378699

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_29.pth
[289] TRAIN  loss: 0.007256897393263153 acc: 0.9965325936199723
[289] VALIDATION  acc: 0.650887573964497

[290] TRAIN  loss: 0.007909820795397229 acc: 0.9965325936199723
[290] VALIDATION  acc: 0.6449704142011834

[291] TRAIN  loss: 0.00720223319889437 acc: 0.9958391123439667
[291] VALIDATION  acc: 0.636094674556213

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_30.pth
[292] TRAIN  loss: 0.006718739021534211 acc: 0.9972260748959778
[292] VALIDATION  acc: 0.6449704142011834

[293] TRAIN  loss: 0.0067156308189355125 acc: 0.9965325936199723
[293] VALIDATION  acc: 0.636094674556213

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_30.pth
[294] TRAIN  loss: 0.0074748657782451955 acc: 0.9965325936199723
[294] VALIDATION  acc: 0.6538461538461539

[295] TRAIN  loss: 0.006710511086248957 acc: 0.9965325936199723
[295] VALIDATION  acc: 0.6449704142011834

[296] TRAIN  loss: 0.006395894704401245 acc: 0.9958391123439667
[296] VALIDATION  acc: 0.6449704142011834

[297] TRAIN  loss: 0.007438623346499347 acc: 0.9958391123439667
[297] VALIDATION  acc: 0.6449704142011834

[298] TRAIN  loss: 0.008162680959109055 acc: 0.9965325936199723
[298] VALIDATION  acc: 0.636094674556213

[299] TRAIN  loss: 0.007333909822244628 acc: 0.9958391123439667
[299] VALIDATION  acc: 0.6449704142011834

[300] TRAIN  loss: 0.00753655129934214 acc: 0.9951456310679612
[300] VALIDATION  acc: 0.6449704142011834

[301] TRAIN  loss: 0.007566045144145661 acc: 0.9958391123439667
[301] VALIDATION  acc: 0.6390532544378699

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_31.pth
[302] TRAIN  loss: 0.00737238386640161 acc: 0.9958391123439667
[302] VALIDATION  acc: 0.636094674556213

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_31.pth
[303] TRAIN  loss: 0.007191425891475513 acc: 0.9965325936199723
[303] VALIDATION  acc: 0.6420118343195266

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_31.pth
[304] TRAIN  loss: 0.006892221560167888 acc: 0.9965325936199723
[304] VALIDATION  acc: 0.650887573964497

[305] TRAIN  loss: 0.00709938567140174 acc: 0.9958391123439667
[305] VALIDATION  acc: 0.6390532544378699

[306] TRAIN  loss: 0.0067960995653876385 acc: 0.9958391123439667
[306] VALIDATION  acc: 0.6420118343195266

[307] TRAIN  loss: 0.007092981547663465 acc: 0.9951456310679612
[307] VALIDATION  acc: 0.6449704142011834

[308] TRAIN  loss: 0.007338458388827366 acc: 0.9951456310679612
[308] VALIDATION  acc: 0.6420118343195266

[309] TRAIN  loss: 0.007087362696157204 acc: 0.9958391123439667
[309] VALIDATION  acc: 0.6390532544378699

[310] TRAIN  loss: 0.006588197520442348 acc: 0.9965325936199723
[310] VALIDATION  acc: 0.6449704142011834

[311] TRAIN  loss: 0.008225084893027734 acc: 0.9951456310679612
[311] VALIDATION  acc: 0.6420118343195266

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_32.pth
[312] TRAIN  loss: 0.006759349029998349 acc: 0.9958391123439667
[312] VALIDATION  acc: 0.6420118343195266

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_32.pth
[313] TRAIN  loss: 0.007203920436478507 acc: 0.9958391123439667
[313] VALIDATION  acc: 0.650887573964497

[314] TRAIN  loss: 0.006131613799004706 acc: 0.9958391123439667
[314] VALIDATION  acc: 0.6449704142011834

[315] TRAIN  loss: 0.00695137665927137 acc: 0.9958391123439667
[315] VALIDATION  acc: 0.6420118343195266

[316] TRAIN  loss: 0.0072392865639788985 acc: 0.9965325936199723
[316] VALIDATION  acc: 0.6479289940828402

[317] TRAIN  loss: 0.0072923884942312075 acc: 0.9965325936199723
[317] VALIDATION  acc: 0.6449704142011834

[318] TRAIN  loss: 0.006732745126306395 acc: 0.9951456310679612
[318] VALIDATION  acc: 0.6420118343195266

[319] TRAIN  loss: 0.006185935242940959 acc: 0.9965325936199723
[319] VALIDATION  acc: 0.650887573964497

[320] TRAIN  loss: 0.007085311066400011 acc: 0.9965325936199723
[320] VALIDATION  acc: 0.6449704142011834

[321] TRAIN  loss: 0.007452825932351098 acc: 0.9944521497919556
[321] VALIDATION  acc: 0.6449704142011834

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_33.pth
[322] TRAIN  loss: 0.006614595039881025 acc: 0.9965325936199723
[322] VALIDATION  acc: 0.6479289940828402

[323] TRAIN  loss: 0.007202265947101633 acc: 0.9951456310679612
[323] VALIDATION  acc: 0.6479289940828402

[324] TRAIN  loss: 0.006616160857909225 acc: 0.9965325936199723
[324] VALIDATION  acc: 0.6420118343195266

[325] TRAIN  loss: 0.007532144036412573 acc: 0.9972260748959778
[325] VALIDATION  acc: 0.6449704142011834

[326] TRAIN  loss: 0.0069437368616798644 acc: 0.9958391123439667
[326] VALIDATION  acc: 0.6479289940828402

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_33.pth
[327] TRAIN  loss: 0.006622154443110946 acc: 0.9958391123439667
[327] VALIDATION  acc: 0.6538461538461539

[328] TRAIN  loss: 0.0060130285506178535 acc: 0.9972260748959778
[328] VALIDATION  acc: 0.650887573964497

[329] TRAIN  loss: 0.006682623985877441 acc: 0.9958391123439667
[329] VALIDATION  acc: 0.650887573964497

[330] TRAIN  loss: 0.007436246947971 acc: 0.9951456310679612
[330] VALIDATION  acc: 0.6538461538461539

[331] TRAIN  loss: 0.007487677653059088 acc: 0.9951456310679612
[331] VALIDATION  acc: 0.650887573964497

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_34.pth
[332] TRAIN  loss: 0.006811861305368375 acc: 0.9951456310679612
[332] VALIDATION  acc: 0.6538461538461539

[333] TRAIN  loss: 0.006731628323970764 acc: 0.9965325936199723
[333] VALIDATION  acc: 0.650887573964497

[334] TRAIN  loss: 0.0074532179293811986 acc: 0.9958391123439667
[334] VALIDATION  acc: 0.650887573964497

[335] TRAIN  loss: 0.007009451876286633 acc: 0.9951456310679612
[335] VALIDATION  acc: 0.6479289940828402

[336] TRAIN  loss: 0.006707310635830354 acc: 0.9958391123439667
[336] VALIDATION  acc: 0.636094674556213

[337] TRAIN  loss: 0.006891041492704674 acc: 0.9958391123439667
[337] VALIDATION  acc: 0.6449704142011834

[338] TRAIN  loss: 0.007098280706887685 acc: 0.9965325936199723
[338] VALIDATION  acc: 0.6390532544378699

[339] TRAIN  loss: 0.007459531343639846 acc: 0.9958391123439667
[339] VALIDATION  acc: 0.6390532544378699

[340] TRAIN  loss: 0.006712154488257223 acc: 0.9965325936199723
[340] VALIDATION  acc: 0.6449704142011834

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_34.pth
[341] TRAIN  loss: 0.0067671890663836476 acc: 0.9965325936199723
[341] VALIDATION  acc: 0.6568047337278107

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_35.pth
[342] TRAIN  loss: 0.007397238375668623 acc: 0.9958391123439667
[342] VALIDATION  acc: 0.6390532544378699

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_35.pth
[343] TRAIN  loss: 0.00821275715719917 acc: 0.9958391123439667
[343] VALIDATION  acc: 0.6479289940828402

[344] TRAIN  loss: 0.007232886543335777 acc: 0.9951456310679612
[344] VALIDATION  acc: 0.6479289940828402

[345] TRAIN  loss: 0.006639306099990559 acc: 0.9965325936199723
[345] VALIDATION  acc: 0.6449704142011834

... Saving checkpoint: out-checkpoints/test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_35.pth
[346] TRAIN  loss: 0.006392944709854048 acc: 0.9958391123439667
[346] VALIDATION  acc: 0.650887573964497

[347] TRAIN  loss: 0.008204987509522758 acc: 0.9944521497919556
[347] VALIDATION  acc: 0.6479289940828402

[348] TRAIN  loss: 0.0069160187531615794 acc: 0.9951456310679612
[348] VALIDATION  acc: 0.6479289940828402

[349] TRAIN  loss: 0.006755764258266131 acc: 0.9958391123439667
[349] VALIDATION  acc: 0.6449704142011834

[350] TRAIN  loss: 0.007138753770789445 acc: 0.9951456310679612
[350] VALIDATION  acc: 0.6479289940828402


Testing checkpointed models starting...

Label accuracies statistics:
{0: 1.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0, 10: 0.0, 11: 0.0, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.0, 19: 0.0, 20: 0.0, 21: 0.0, 22: 0.0, 23: 0.0, 24: 0.0, 25: 0.0, 26: 0.0, 27: 0.0, 28: 0.0, 29: 0.0, 30: 0.0, 31: 0.0, 32: 0.0, 33: 0.0, 34: 0.0, 35: 0.0, 36: 0.0, 37: 0.0, 38: 0.0, 39: 0.0, 40: 0.0, 41: 0.0, 42: 0.0, 43: 0.0, 44: 0.0, 45: 0.0, 46: 0.0, 47: 0.0, 48: 0.0, 49: 0.0, 50: 0.0, 51: 0.0, 52: 0.0, 53: 0.0, 54: 0.0, 55: 0.0, 56: 0.0, 57: 0.0, 58: 0.0, 59: 0.0, 60: 0.0, 61: 0.0, 62: 0.0, 63: 0.0, 64: 0.0, 65: 0.0, 66: 0.0, 67: 0.0, 68: 0.0, 69: 0.0, 70: 0.0, 71: 0.0, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.0, 77: 0.0, 78: 0.0, 79: 0.0, 80: 0.0, 81: 0.0, 82: 0.0, 83: 0.0, 84: 0.0, 85: 0.0, 86: 0.0, 87: 0.0, 88: 0.0, 89: 0.0, 90: 0.0, 91: 0.0, 92: 0.0, 93: 0.0, 94: 0.0, 95: 0.0, 96: 0.0, 97: 0.0, 98: 0.0, 99: 0.0}

checkpoint_t_0  ->  0.015503875968992248
Label accuracies statistics:
{0: 1.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0, 10: 0.0, 11: 0.0, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.0, 19: 0.0, 20: 0.0, 21: 0.0, 22: 0.0, 23: 0.0, 24: 0.0, 25: 0.0, 26: 0.0, 27: 0.0, 28: 0.0, 29: 0.0, 30: 0.0, 31: 0.0, 32: 0.0, 33: 0.0, 34: 0.0, 35: 0.0, 36: 0.0, 37: 0.0, 38: 0.0, 39: 0.0, 40: 0.0, 41: 0.0, 42: 0.0, 43: 0.0, 44: 0.0, 45: 0.0, 46: 0.0, 47: 0.0, 48: 0.0, 49: 0.0, 50: 0.0, 51: 0.0, 52: 0.0, 53: 0.0, 54: 0.0, 55: 0.0, 56: 0.0, 57: 0.0, 58: 0.0, 59: 0.0, 60: 0.0, 61: 0.0, 62: 0.0, 63: 0.0, 64: 0.0, 65: 0.0, 66: 0.0, 67: 0.0, 68: 0.0, 69: 0.0, 70: 0.0, 71: 0.0, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.0, 77: 0.0, 78: 0.0, 79: 0.0, 80: 0.0, 81: 0.0, 82: 0.0, 83: 0.0, 84: 0.0, 85: 0.0, 86: 0.0, 87: 0.0, 88: 0.0, 89: 0.0, 90: 0.0, 91: 0.0, 92: 0.0, 93: 0.0, 94: 0.0, 95: 0.0, 96: 0.0, 97: 0.0, 98: 0.0, 99: 0.0}

checkpoint_v_0  ->  0.015503875968992248
Label accuracies statistics:
{0: 0.5, 1: 0.0, 2: 0.0, 3: 0.0, 4: 1.0, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0, 10: 0.0, 11: 0.0, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.6666666666666666, 16: 0.0, 17: 0.3333333333333333, 18: 0.0, 19: 0.0, 20: 0.0, 21: 0.0, 22: 0.0, 23: 0.0, 24: 1.0, 25: 0.0, 26: 0.0, 27: 0.0, 28: 0.0, 29: 0.0, 30: 0.0, 31: 0.0, 32: 0.0, 33: 0.0, 34: 0.0, 35: 0.5, 36: 0.3333333333333333, 37: 0.0, 38: 0.0, 39: 0.0, 40: 0.5, 41: 0.0, 42: 0.0, 43: 0.0, 44: 0.0, 45: 0.0, 46: 0.0, 47: 0.0, 48: 0.0, 49: 0.5, 50: 0.0, 51: 0.0, 52: 0.0, 53: 0.0, 54: 0.0, 55: 0.0, 56: 0.0, 57: 0.0, 58: 0.0, 59: 0.0, 60: 0.0, 61: 0.0, 62: 0.0, 63: 0.0, 64: 0.0, 65: 0.0, 66: 0.0, 67: 0.0, 68: 0.0, 69: 0.0, 70: 0.0, 71: 0.0, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.0, 77: 1.0, 78: 0.0, 79: 0.0, 80: 0.0, 81: 0.0, 82: 0.0, 83: 0.0, 84: 0.0, 85: 0.0, 86: 0.0, 87: 0.0, 88: 0.0, 89: 0.0, 90: 0.0, 91: 0.0, 92: 0.5, 93: 0.0, 94: 0.0, 95: 0.0, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_1  ->  0.07751937984496124
Label accuracies statistics:
{0: 0.5, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.3333333333333333, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0, 10: 0.0, 11: 0.0, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.3333333333333333, 16: 0.0, 17: 0.3333333333333333, 18: 0.0, 19: 0.0, 20: 0.0, 21: 0.0, 22: 0.0, 23: 0.6666666666666666, 24: 0.0, 25: 0.0, 26: 0.0, 27: 0.6666666666666666, 28: 1.0, 29: 0.6666666666666666, 30: 0.0, 31: 0.0, 32: 0.0, 33: 0.0, 34: 0.5, 35: 0.0, 36: 0.0, 37: 0.0, 38: 0.0, 39: 0.0, 40: 0.5, 41: 0.0, 42: 0.0, 43: 0.0, 44: 0.0, 45: 0.0, 46: 0.0, 47: 0.0, 48: 0.0, 49: 0.0, 50: 0.0, 51: 0.0, 52: 0.0, 53: 0.0, 54: 0.0, 55: 0.0, 56: 0.0, 57: 0.0, 58: 0.0, 59: 0.6666666666666666, 60: 0.0, 61: 0.0, 62: 0.0, 63: 0.5, 64: 0.0, 65: 0.0, 66: 0.0, 67: 0.0, 68: 0.0, 69: 1.0, 70: 0.5, 71: 0.0, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.0, 77: 0.0, 78: 0.0, 79: 0.0, 80: 0.0, 81: 0.0, 82: 0.0, 83: 0.0, 84: 0.0, 85: 0.0, 86: 0.0, 87: 0.0, 88: 0.0, 89: 0.0, 90: 0.0, 91: 0.5, 92: 0.0, 93: 0.0, 94: 0.0, 95: 0.0, 96: 0.0, 97: 0.0, 98: 0.0, 99: 0.0}

checkpoint_v_1  ->  0.08914728682170543
Label accuracies statistics:
{0: 0.75, 1: 0.25, 2: 0.2, 3: 0.0, 4: 0.6666666666666666, 5: 0.0, 6: 1.0, 7: 1.0, 8: 0.0, 9: 0.0, 10: 0.0, 11: 0.0, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.3333333333333333, 16: 0.0, 17: 0.6666666666666666, 18: 0.0, 19: 0.6666666666666666, 20: 0.0, 21: 0.3333333333333333, 22: 0.0, 23: 0.6666666666666666, 24: 1.0, 25: 0.0, 26: 0.0, 27: 0.3333333333333333, 28: 1.0, 29: 1.0, 30: 0.0, 31: 0.3333333333333333, 32: 0.0, 33: 0.0, 34: 0.5, 35: 0.5, 36: 0.0, 37: 0.0, 38: 0.0, 39: 0.0, 40: 1.0, 41: 0.0, 42: 0.3333333333333333, 43: 0.0, 44: 0.0, 45: 0.0, 46: 0.0, 47: 0.5, 48: 0.0, 49: 0.0, 50: 0.5, 51: 0.0, 52: 0.0, 53: 0.5, 54: 0.5, 55: 0.0, 56: 0.0, 57: 0.6666666666666666, 58: 0.0, 59: 0.3333333333333333, 60: 0.0, 61: 0.0, 62: 0.5, 63: 0.0, 64: 0.0, 65: 0.0, 66: 0.0, 67: 0.0, 68: 0.0, 69: 0.0, 70: 0.0, 71: 0.0, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.0, 77: 0.5, 78: 0.0, 79: 0.0, 80: 0.0, 81: 0.5, 82: 0.5, 83: 0.0, 84: 0.5, 85: 0.0, 86: 0.0, 87: 0.0, 88: 0.3333333333333333, 89: 0.0, 90: 0.5, 91: 1.0, 92: 0.5, 93: 0.0, 94: 0.0, 95: 0.0, 96: 0.0, 97: 0.5, 98: 0.0, 99: 0.0}

checkpoint_t_2  ->  0.2131782945736434
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.0, 3: 0.0, 4: 0.6666666666666666, 5: 0.3333333333333333, 6: 0.6666666666666666, 7: 0.3333333333333333, 8: 0.3333333333333333, 9: 0.3333333333333333, 10: 0.3333333333333333, 11: 0.3333333333333333, 12: 0.3333333333333333, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.3333333333333333, 17: 0.6666666666666666, 18: 0.0, 19: 0.0, 20: 0.0, 21: 0.0, 22: 0.0, 23: 0.6666666666666666, 24: 0.3333333333333333, 25: 0.0, 26: 0.0, 27: 0.0, 28: 0.3333333333333333, 29: 0.6666666666666666, 30: 0.0, 31: 0.3333333333333333, 32: 0.0, 33: 0.0, 34: 0.0, 35: 0.5, 36: 0.0, 37: 0.5, 38: 0.0, 39: 0.5, 40: 1.0, 41: 0.0, 42: 0.0, 43: 0.0, 44: 0.0, 45: 0.0, 46: 0.0, 47: 0.0, 48: 0.0, 49: 0.0, 50: 0.5, 51: 0.0, 52: 1.0, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.0, 57: 0.0, 58: 1.0, 59: 0.0, 60: 0.0, 61: 0.0, 62: 0.0, 63: 0.0, 64: 0.0, 65: 0.6666666666666666, 66: 0.0, 67: 0.0, 68: 0.0, 69: 0.0, 70: 0.5, 71: 0.0, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.0, 77: 1.0, 78: 0.0, 79: 0.0, 80: 0.0, 81: 0.5, 82: 0.0, 83: 0.0, 84: 0.5, 85: 0.0, 86: 0.0, 87: 0.0, 88: 0.0, 89: 0.0, 90: 0.0, 91: 0.0, 92: 0.0, 93: 0.0, 94: 0.0, 95: 0.0, 96: 0.0, 97: 0.5, 98: 0.0, 99: 0.0}

checkpoint_v_2  ->  0.1821705426356589
Label accuracies statistics:
{0: 0.5, 1: 0.25, 2: 0.4, 3: 0.25, 4: 0.6666666666666666, 5: 0.3333333333333333, 6: 0.6666666666666666, 7: 0.3333333333333333, 8: 0.3333333333333333, 9: 0.0, 10: 0.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.3333333333333333, 14: 0.0, 15: 0.6666666666666666, 16: 0.0, 17: 0.3333333333333333, 18: 0.0, 19: 0.0, 20: 0.0, 21: 0.3333333333333333, 22: 0.0, 23: 0.3333333333333333, 24: 0.3333333333333333, 25: 0.0, 26: 0.3333333333333333, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 0.3333333333333333, 32: 0.5, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.0, 37: 0.5, 38: 0.0, 39: 0.5, 40: 0.5, 41: 0.5, 42: 0.6666666666666666, 43: 0.0, 44: 0.0, 45: 0.5, 46: 0.0, 47: 0.0, 48: 0.6666666666666666, 49: 1.0, 50: 1.0, 51: 0.0, 52: 0.5, 53: 0.0, 54: 1.0, 55: 0.0, 56: 0.0, 57: 0.0, 58: 1.0, 59: 0.3333333333333333, 60: 0.6666666666666666, 61: 0.0, 62: 0.5, 63: 0.5, 64: 0.0, 65: 0.3333333333333333, 66: 0.0, 67: 0.3333333333333333, 68: 0.0, 69: 0.5, 70: 0.0, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.0, 77: 1.0, 78: 0.0, 79: 0.0, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.5, 88: 0.6666666666666666, 89: 0.0, 90: 0.5, 91: 0.5, 92: 1.0, 93: 0.0, 94: 0.5, 95: 0.0, 96: 0.0, 97: 0.5, 98: 1.0, 99: 0.0}

checkpoint_t_3  ->  0.3488372093023256
Label accuracies statistics:
{0: 1.0, 1: 0.0, 2: 0.4, 3: 0.5, 4: 0.6666666666666666, 5: 0.0, 6: 0.6666666666666666, 7: 0.0, 8: 0.3333333333333333, 9: 0.3333333333333333, 10: 0.0, 11: 0.0, 12: 0.3333333333333333, 13: 0.0, 14: 0.0, 15: 0.3333333333333333, 16: 0.3333333333333333, 17: 0.6666666666666666, 18: 0.3333333333333333, 19: 0.0, 20: 0.0, 21: 0.3333333333333333, 22: 0.0, 23: 0.3333333333333333, 24: 1.0, 25: 0.6666666666666666, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.0, 31: 0.0, 32: 0.5, 33: 0.5, 34: 1.0, 35: 1.0, 36: 0.0, 37: 0.5, 38: 0.0, 39: 0.0, 40: 1.0, 41: 0.0, 42: 0.3333333333333333, 43: 0.0, 44: 0.5, 45: 0.5, 46: 0.3333333333333333, 47: 0.0, 48: 0.3333333333333333, 49: 0.5, 50: 1.0, 51: 0.0, 52: 0.5, 53: 0.0, 54: 1.0, 55: 0.5, 56: 0.0, 57: 0.0, 58: 0.5, 59: 0.6666666666666666, 60: 0.0, 61: 0.0, 62: 0.5, 63: 0.5, 64: 0.0, 65: 0.6666666666666666, 66: 0.5, 67: 0.0, 68: 0.0, 69: 0.0, 70: 0.0, 71: 0.6666666666666666, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.0, 77: 1.0, 78: 0.0, 79: 0.0, 80: 0.0, 81: 0.5, 82: 0.5, 83: 0.5, 84: 1.0, 85: 0.0, 86: 0.3333333333333333, 87: 0.5, 88: 0.3333333333333333, 89: 0.0, 90: 0.5, 91: 0.5, 92: 1.0, 93: 0.0, 94: 0.0, 95: 0.0, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_3  ->  0.32558139534883723
Label accuracies statistics:
{0: 0.5, 1: 0.25, 2: 0.4, 3: 0.25, 4: 0.6666666666666666, 5: 0.6666666666666666, 6: 0.3333333333333333, 7: 0.3333333333333333, 8: 0.3333333333333333, 9: 0.0, 10: 0.3333333333333333, 11: 0.3333333333333333, 12: 1.0, 13: 0.3333333333333333, 14: 0.0, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 1.0, 20: 0.0, 21: 0.3333333333333333, 22: 0.0, 23: 0.6666666666666666, 24: 1.0, 25: 0.0, 26: 0.0, 27: 0.6666666666666666, 28: 1.0, 29: 1.0, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 0.0, 33: 0.5, 34: 1.0, 35: 1.0, 36: 0.0, 37: 0.0, 38: 0.3333333333333333, 39: 0.0, 40: 0.5, 41: 0.5, 42: 0.6666666666666666, 43: 0.3333333333333333, 44: 0.0, 45: 1.0, 46: 0.3333333333333333, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.6666666666666666, 52: 0.0, 53: 1.0, 54: 0.5, 55: 0.0, 56: 0.3333333333333333, 57: 1.0, 58: 1.0, 59: 1.0, 60: 0.3333333333333333, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.0, 66: 0.0, 67: 0.0, 68: 0.0, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.0, 77: 0.5, 78: 0.3333333333333333, 79: 0.5, 80: 0.0, 81: 0.5, 82: 0.5, 83: 0.0, 84: 0.0, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 0.6666666666666666, 89: 1.0, 90: 0.5, 91: 0.5, 92: 0.5, 93: 0.5, 94: 0.0, 95: 0.0, 96: 0.3333333333333333, 97: 0.5, 98: 1.0, 99: 0.0}

checkpoint_t_4  ->  0.4186046511627907
Label accuracies statistics:
{0: 0.5, 1: 0.5, 2: 0.6, 3: 0.25, 4: 0.6666666666666666, 5: 0.3333333333333333, 6: 0.6666666666666666, 7: 0.6666666666666666, 8: 1.0, 9: 0.0, 10: 1.0, 11: 0.0, 12: 0.6666666666666666, 13: 0.0, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.0, 18: 0.3333333333333333, 19: 0.3333333333333333, 20: 0.0, 21: 0.6666666666666666, 22: 0.0, 23: 0.0, 24: 1.0, 25: 0.6666666666666666, 26: 0.0, 27: 0.6666666666666666, 28: 1.0, 29: 1.0, 30: 0.0, 31: 0.0, 32: 0.5, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.0, 37: 0.5, 38: 0.0, 39: 0.5, 40: 0.5, 41: 0.5, 42: 0.3333333333333333, 43: 1.0, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 0.5, 51: 0.6666666666666666, 52: 0.0, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.3333333333333333, 57: 0.0, 58: 0.5, 59: 1.0, 60: 0.3333333333333333, 61: 0.0, 62: 0.5, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 0.5, 67: 1.0, 68: 0.0, 69: 0.5, 70: 0.0, 71: 0.3333333333333333, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.5, 76: 0.0, 77: 1.0, 78: 0.3333333333333333, 79: 0.0, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 1.0, 85: 0.0, 86: 0.6666666666666666, 87: 0.0, 88: 1.0, 89: 0.0, 90: 0.0, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.5, 98: 1.0, 99: 0.0}

checkpoint_v_4  ->  0.43410852713178294
Label accuracies statistics:
{0: 0.75, 1: 0.25, 2: 0.6, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.3333333333333333, 8: 0.3333333333333333, 9: 0.3333333333333333, 10: 0.3333333333333333, 11: 0.0, 12: 1.0, 13: 0.6666666666666666, 14: 0.0, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 1.0, 20: 0.0, 21: 0.3333333333333333, 22: 0.0, 23: 0.3333333333333333, 24: 0.6666666666666666, 25: 0.3333333333333333, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 0.5, 33: 0.5, 34: 1.0, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.0, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.3333333333333333, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.3333333333333333, 47: 0.5, 48: 0.6666666666666666, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.0, 54: 1.0, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 0.5, 59: 0.6666666666666666, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 0.5, 67: 0.3333333333333333, 68: 0.0, 69: 0.5, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.0, 77: 0.5, 78: 0.6666666666666666, 79: 0.5, 80: 0.0, 81: 0.5, 82: 0.5, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.6666666666666666, 87: 0.5, 88: 1.0, 89: 1.0, 90: 0.5, 91: 1.0, 92: 0.0, 93: 0.0, 94: 0.0, 95: 0.0, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.5}

checkpoint_t_5  ->  0.4806201550387597
Label accuracies statistics:
{0: 0.75, 1: 0.25, 2: 0.6, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.3333333333333333, 8: 0.3333333333333333, 9: 0.3333333333333333, 10: 0.3333333333333333, 11: 0.0, 12: 1.0, 13: 0.6666666666666666, 14: 0.0, 15: 0.6666666666666666, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 1.0, 20: 0.0, 21: 0.3333333333333333, 22: 0.0, 23: 0.3333333333333333, 24: 0.6666666666666666, 25: 0.3333333333333333, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 0.5, 33: 0.5, 34: 1.0, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.0, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.3333333333333333, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.3333333333333333, 47: 0.5, 48: 0.6666666666666666, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.0, 54: 1.0, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 0.5, 59: 0.6666666666666666, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 0.5, 67: 0.3333333333333333, 68: 0.0, 69: 0.5, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.0, 77: 0.5, 78: 0.6666666666666666, 79: 0.5, 80: 0.0, 81: 0.5, 82: 0.5, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.6666666666666666, 87: 0.5, 88: 1.0, 89: 1.0, 90: 0.5, 91: 1.0, 92: 0.0, 93: 0.0, 94: 0.0, 95: 0.0, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.5}

checkpoint_v_5  ->  0.4806201550387597
Label accuracies statistics:
{0: 0.75, 1: 0.25, 2: 0.8, 3: 0.5, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 1.0, 8: 0.6666666666666666, 9: 0.3333333333333333, 10: 1.0, 11: 0.0, 12: 1.0, 13: 0.6666666666666666, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 0.3333333333333333, 17: 1.0, 18: 0.3333333333333333, 19: 1.0, 20: 0.0, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 0.6666666666666666, 25: 0.3333333333333333, 26: 0.3333333333333333, 27: 0.6666666666666666, 28: 1.0, 29: 0.3333333333333333, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 0.0, 33: 0.0, 34: 1.0, 35: 1.0, 36: 0.6666666666666666, 37: 0.5, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 0.5, 42: 0.6666666666666666, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.3333333333333333, 47: 0.5, 48: 0.3333333333333333, 49: 0.0, 50: 1.0, 51: 0.6666666666666666, 52: 1.0, 53: 1.0, 54: 0.5, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 0.5, 59: 0.6666666666666666, 60: 0.3333333333333333, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 0.5, 67: 0.3333333333333333, 68: 0.0, 69: 0.5, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.5, 75: 0.5, 76: 0.3333333333333333, 77: 0.5, 78: 0.6666666666666666, 79: 0.5, 80: 0.0, 81: 0.5, 82: 0.5, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.5, 88: 1.0, 89: 0.5, 90: 0.0, 91: 0.5, 92: 1.0, 93: 0.0, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.5}

checkpoint_t_6  ->  0.5232558139534884
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 1.0, 8: 0.3333333333333333, 9: 0.3333333333333333, 10: 0.3333333333333333, 11: 0.0, 12: 0.6666666666666666, 13: 0.0, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.0, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.0, 21: 0.6666666666666666, 22: 0.3333333333333333, 23: 0.0, 24: 0.6666666666666666, 25: 0.3333333333333333, 26: 0.0, 27: 0.6666666666666666, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 0.5, 33: 1.0, 34: 0.0, 35: 1.0, 36: 0.3333333333333333, 37: 1.0, 38: 0.6666666666666666, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 1.0, 44: 0.0, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 0.6666666666666666, 49: 0.5, 50: 0.5, 51: 1.0, 52: 0.5, 53: 0.5, 54: 0.5, 55: 0.0, 56: 0.0, 57: 0.0, 58: 0.5, 59: 1.0, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 0.5, 67: 0.3333333333333333, 68: 0.0, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 1.0, 78: 0.6666666666666666, 79: 0.5, 80: 0.0, 81: 0.5, 82: 0.5, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.6666666666666666, 87: 0.5, 88: 1.0, 89: 0.5, 90: 0.5, 91: 0.5, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.0, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_6  ->  0.49612403100775193
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.8, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 1.0, 8: 0.3333333333333333, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.6666666666666666, 14: 0.0, 15: 1.0, 16: 0.6666666666666666, 17: 0.0, 18: 0.3333333333333333, 19: 1.0, 20: 0.0, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.3333333333333333, 24: 0.6666666666666666, 25: 0.3333333333333333, 26: 0.0, 27: 0.3333333333333333, 28: 1.0, 29: 1.0, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 0.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.0, 39: 0.5, 40: 1.0, 41: 0.0, 42: 0.6666666666666666, 43: 1.0, 44: 0.5, 45: 0.5, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 0.5, 51: 0.3333333333333333, 52: 0.0, 53: 0.5, 54: 0.5, 55: 0.0, 56: 0.6666666666666666, 57: 0.3333333333333333, 58: 1.0, 59: 0.6666666666666666, 60: 0.6666666666666666, 61: 0.0, 62: 0.5, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 0.5, 67: 0.3333333333333333, 68: 0.0, 69: 1.0, 70: 0.0, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 0.5, 78: 1.0, 79: 1.0, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.0, 91: 0.5, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_7  ->  0.5232558139534884
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.6, 3: 0.25, 4: 1.0, 5: 1.0, 6: 1.0, 7: 0.6666666666666666, 8: 1.0, 9: 0.3333333333333333, 10: 1.0, 11: 1.0, 12: 0.6666666666666666, 13: 0.3333333333333333, 14: 0.0, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.0, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 0.3333333333333333, 26: 0.0, 27: 0.6666666666666666, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 0.5, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.0, 37: 0.5, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 1.0, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 0.6666666666666666, 49: 0.0, 50: 1.0, 51: 0.6666666666666666, 52: 0.5, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.0, 57: 0.3333333333333333, 58: 0.5, 59: 1.0, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.3333333333333333, 66: 1.0, 67: 0.0, 68: 0.0, 69: 0.5, 70: 0.5, 71: 0.3333333333333333, 72: 0.5, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 0.5, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 0.5, 83: 0.5, 84: 0.5, 85: 0.5, 86: 1.0, 87: 0.5, 88: 1.0, 89: 0.5, 90: 0.0, 91: 0.5, 92: 1.0, 93: 0.0, 94: 0.5, 95: 0.5, 96: 0.3333333333333333, 97: 0.5, 98: 0.0, 99: 0.0}

checkpoint_v_7  ->  0.5348837209302325
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.3333333333333333, 8: 0.3333333333333333, 9: 0.6666666666666666, 10: 1.0, 11: 0.6666666666666666, 12: 1.0, 13: 0.3333333333333333, 14: 0.0, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.0, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 1.0, 32: 0.0, 33: 1.0, 34: 0.0, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.0, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 0.5, 67: 0.3333333333333333, 68: 0.0, 69: 0.5, 70: 0.0, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 1.0, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_8  ->  0.5387596899224806
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.4, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.3333333333333333, 8: 0.3333333333333333, 9: 0.6666666666666666, 10: 1.0, 11: 0.6666666666666666, 12: 1.0, 13: 0.3333333333333333, 14: 0.0, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.0, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 1.0, 32: 0.0, 33: 1.0, 34: 0.0, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.0, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 0.5, 67: 0.3333333333333333, 68: 0.0, 69: 0.5, 70: 0.0, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 1.0, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_8  ->  0.5387596899224806
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.6, 3: 0.5, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 1.0, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.6666666666666666, 12: 1.0, 13: 1.0, 14: 0.0, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.0, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 0.6666666666666666, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 1.0, 33: 1.0, 34: 0.5, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.0, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.3333333333333333, 43: 1.0, 44: 0.5, 45: 1.0, 46: 0.0, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.5, 54: 0.5, 55: 0.0, 56: 0.0, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.6666666666666666, 66: 0.5, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 0.5, 78: 0.6666666666666666, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.5, 86: 1.0, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_9  ->  0.5736434108527132
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.6, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 1.0, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.3333333333333333, 14: 0.6666666666666666, 15: 0.0, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 1.0, 20: 0.0, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 1.0, 33: 1.0, 34: 0.5, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 1.0, 44: 0.5, 45: 1.0, 46: 0.3333333333333333, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.0, 57: 0.3333333333333333, 58: 1.0, 59: 1.0, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.0, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_9  ->  0.5736434108527132
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.8, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.6666666666666666, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 0.6666666666666666, 13: 0.6666666666666666, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 1.0, 20: 0.0, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 0.6666666666666666, 26: 0.0, 27: 0.6666666666666666, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 1.0, 32: 0.5, 33: 0.0, 34: 1.0, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.0, 39: 0.5, 40: 0.5, 41: 1.0, 42: 0.6666666666666666, 43: 1.0, 44: 0.5, 45: 1.0, 46: 0.0, 47: 0.5, 48: 0.6666666666666666, 49: 0.0, 50: 0.5, 51: 0.0, 52: 1.0, 53: 1.0, 54: 0.5, 55: 0.0, 56: 0.0, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 1.0, 61: 0.0, 62: 0.5, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 0.5, 67: 0.3333333333333333, 68: 0.0, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 0.5, 78: 0.6666666666666666, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 1.0, 85: 0.5, 86: 0.6666666666666666, 87: 0.5, 88: 1.0, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.0, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_10  ->  0.5426356589147286
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.6, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.3333333333333333, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.6666666666666666, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 1.0, 20: 0.0, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.5, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.0, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.3333333333333333, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.6666666666666666, 52: 0.5, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.0, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.0, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 0.5, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 1.0, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_10  ->  0.5775193798449613
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.6, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 1.0, 8: 0.6666666666666666, 9: 0.6666666666666666, 10: 1.0, 11: 0.6666666666666666, 12: 1.0, 13: 0.3333333333333333, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.3333333333333333, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 1.0, 33: 1.0, 34: 0.5, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.0, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.0, 57: 0.3333333333333333, 58: 1.0, 59: 1.0, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.0, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_11  ->  0.562015503875969
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.6, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 1.0, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.3333333333333333, 14: 0.0, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.0, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 0.3333333333333333, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 1.0, 33: 1.0, 34: 0.0, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 0.5, 41: 1.0, 42: 0.3333333333333333, 43: 1.0, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 0.5, 51: 0.6666666666666666, 52: 0.5, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.0, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 1.0, 78: 0.6666666666666666, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.6666666666666666, 87: 0.5, 88: 1.0, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.0, 95: 0.5, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_11  ->  0.562015503875969
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.6, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 1.0, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.3333333333333333, 14: 0.0, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 1.0, 20: 0.0, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 1.0, 33: 1.0, 34: 0.5, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.0, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.0, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 0.5, 78: 0.6666666666666666, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 1.0, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_12  ->  0.5697674418604651
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.6, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 1.0, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.3333333333333333, 14: 0.0, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 1.0, 20: 0.0, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 1.0, 33: 1.0, 34: 0.5, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.0, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.0, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 0.5, 78: 0.6666666666666666, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 1.0, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_12  ->  0.5697674418604651
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.6, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 1.0, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.6666666666666666, 12: 1.0, 13: 0.3333333333333333, 14: 0.0, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.5, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.6666666666666666, 52: 0.5, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.0, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 0.5, 78: 0.6666666666666666, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.5, 88: 1.0, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_13  ->  0.5813953488372093
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.6, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.6666666666666666, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.6666666666666666, 12: 1.0, 13: 0.3333333333333333, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.0, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 0.6666666666666666, 32: 1.0, 33: 1.0, 34: 0.5, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.0, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 0.6666666666666666, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.0, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_13  ->  0.5658914728682171
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.6, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 1.0, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.6666666666666666, 12: 1.0, 13: 0.6666666666666666, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.0, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.5, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.0, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 1.0, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.0, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.0, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 0.5, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_14  ->  0.5775193798449613
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.8, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.3333333333333333, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.6666666666666666, 12: 1.0, 13: 0.3333333333333333, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 1.0, 20: 0.0, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.5, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.0, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 1.0, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.0, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 0.5, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.5, 88: 1.0, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.3333333333333333, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_14  ->  0.5852713178294574
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.8, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.6666666666666666, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.6666666666666666, 12: 1.0, 13: 0.6666666666666666, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.5, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.0, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.0, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.0, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_15  ->  0.5813953488372093
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.8, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.6666666666666666, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.6666666666666666, 12: 1.0, 13: 0.3333333333333333, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.5, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 1.0, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 1.0, 67: 0.6666666666666666, 68: 0.0, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 0.5, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.5, 88: 1.0, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_15  ->  0.5930232558139535
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.8, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.6666666666666666, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.6666666666666666, 12: 1.0, 13: 0.3333333333333333, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.0, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.5, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 1.0, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.0, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 0.5, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.5, 88: 1.0, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_16  ->  0.5852713178294574
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.8, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.6666666666666666, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.6666666666666666, 12: 1.0, 13: 0.3333333333333333, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.0, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.5, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 1.0, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.0, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 0.5, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.5, 88: 1.0, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_16  ->  0.5852713178294574
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.6, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.6666666666666666, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.6666666666666666, 12: 1.0, 13: 0.3333333333333333, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 1.0, 20: 0.0, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.5, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.0, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.0, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.0, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 0.5, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_17  ->  0.5697674418604651
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.6, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.6666666666666666, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.6666666666666666, 12: 1.0, 13: 0.3333333333333333, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 1.0, 20: 0.0, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.5, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.0, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.0, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.0, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 0.5, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_17  ->  0.5697674418604651
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.8, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.6666666666666666, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.6666666666666666, 12: 1.0, 13: 0.3333333333333333, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 1.0, 20: 0.0, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.5, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.6666666666666666, 52: 0.5, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.0, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.0, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 0.5, 78: 0.6666666666666666, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_18  ->  0.5775193798449613
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.8, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.6666666666666666, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.6666666666666666, 12: 1.0, 13: 1.0, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 1.0, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.5, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.0, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.6666666666666666, 52: 0.5, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.0, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 1.0, 67: 0.6666666666666666, 68: 0.0, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.5, 88: 1.0, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_18  ->  0.6007751937984496
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.8, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.6666666666666666, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.6666666666666666, 12: 1.0, 13: 0.6666666666666666, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 1.0, 20: 0.0, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.5, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.0, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 1.0, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.6666666666666666, 52: 0.5, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 1.0, 67: 0.6666666666666666, 68: 0.0, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 0.5, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.5, 88: 1.0, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_19  ->  0.5968992248062015
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.8, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 1.0, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.6666666666666666, 12: 1.0, 13: 0.3333333333333333, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 1.0, 20: 0.0, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.5, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.0, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 1.0, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.6666666666666666, 52: 0.5, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.0, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 1.0, 67: 0.6666666666666666, 68: 0.0, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 0.5, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_19  ->  0.5891472868217055
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.6, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.6666666666666666, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.6666666666666666, 12: 1.0, 13: 0.3333333333333333, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 1.0, 20: 0.0, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 1.0, 32: 0.5, 33: 1.0, 34: 0.5, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.0, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.0, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 0.5, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_20  ->  0.5697674418604651
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.6, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.6666666666666666, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.3333333333333333, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.0, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.5, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 1.0, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.0, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.0, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 0.5, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_20  ->  0.5697674418604651
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.6, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.6666666666666666, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.6666666666666666, 12: 1.0, 13: 0.3333333333333333, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 1.0, 20: 0.0, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.5, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.0, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 0.5, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_21  ->  0.5775193798449613
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.6, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.6666666666666666, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.6666666666666666, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 1.0, 20: 0.0, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.5, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.6666666666666666, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.0, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 0.5, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_21  ->  0.5813953488372093
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.6, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.6666666666666666, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.6666666666666666, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 1.0, 20: 0.0, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.5, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.0, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.6666666666666666, 52: 0.5, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.0, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 0.5, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_22  ->  0.5775193798449613
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.8, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.6666666666666666, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.6666666666666666, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 1.0, 20: 0.0, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.5, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.6666666666666666, 52: 0.5, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.0, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 0.5, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_22  ->  0.5852713178294574
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.8, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 1.0, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.6666666666666666, 12: 1.0, 13: 1.0, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 1.0, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.5, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.0, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.3333333333333333, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.6666666666666666, 52: 0.5, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 1.0, 67: 0.6666666666666666, 68: 0.0, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 0.5, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_23  ->  0.5968992248062015
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.8, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 1.0, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.6666666666666666, 12: 1.0, 13: 1.0, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 1.0, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.5, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.0, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.3333333333333333, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.6666666666666666, 52: 0.5, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 1.0, 67: 0.6666666666666666, 68: 0.0, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 0.5, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_23  ->  0.5968992248062015
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.6, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.6666666666666666, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.6666666666666666, 12: 1.0, 13: 0.3333333333333333, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.5, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.0, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.0, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 0.5, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_24  ->  0.5736434108527132
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.6, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.6666666666666666, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.6666666666666666, 12: 1.0, 13: 0.3333333333333333, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.5, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.0, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.0, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 0.5, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_24  ->  0.5736434108527132
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.6, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.6666666666666666, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.6666666666666666, 12: 1.0, 13: 0.6666666666666666, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 1.0, 20: 0.0, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.3333333333333333, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.5, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 1.0, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.0, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 0.5, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_25  ->  0.5891472868217055
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.8, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.6666666666666666, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.6666666666666666, 12: 1.0, 13: 0.6666666666666666, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 1.0, 20: 0.0, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.5, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 1.0, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.0, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.0, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 0.5, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_25  ->  0.5852713178294574
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.6, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.6666666666666666, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.6666666666666666, 12: 1.0, 13: 0.6666666666666666, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.5, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.0, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 1.0, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.0, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 1.0, 67: 0.6666666666666666, 68: 0.0, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 0.5, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_26  ->  0.5813953488372093
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.6, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.6666666666666666, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.6666666666666666, 12: 1.0, 13: 0.3333333333333333, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 1.0, 20: 0.0, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.5, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.6666666666666666, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 1.0, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.0, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 0.5, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_26  ->  0.5852713178294574
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.8, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.6666666666666666, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.6666666666666666, 12: 1.0, 13: 0.6666666666666666, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 1.0, 20: 0.0, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.5, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.0, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 1.0, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.0, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 0.5, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_27  ->  0.5852713178294574
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.8, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.6666666666666666, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.6666666666666666, 12: 1.0, 13: 0.6666666666666666, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 1.0, 20: 0.0, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.5, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.0, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 1.0, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.0, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 0.5, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_27  ->  0.5852713178294574
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.8, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.6666666666666666, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.6666666666666666, 12: 1.0, 13: 0.3333333333333333, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 1.0, 20: 0.0, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.3333333333333333, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.5, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.0, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 1.0, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.0, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 0.5, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_28  ->  0.5852713178294574
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.6, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.6666666666666666, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.6666666666666666, 12: 1.0, 13: 0.6666666666666666, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.5, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.0, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.0, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.0, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 0.5, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_28  ->  0.5736434108527132
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.6, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.6666666666666666, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.6666666666666666, 12: 1.0, 13: 0.6666666666666666, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 1.0, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.5, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.0, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 0.5, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_29  ->  0.5852713178294574
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.8, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.6666666666666666, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.6666666666666666, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 1.0, 20: 0.0, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.5, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.0, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.0, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 1.0, 67: 0.6666666666666666, 68: 0.0, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 0.5, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_29  ->  0.5775193798449613
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.6, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.6666666666666666, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.6666666666666666, 12: 1.0, 13: 0.3333333333333333, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 0.6666666666666666, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.5, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.6666666666666666, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 1.0, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.0, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 1.0, 67: 0.6666666666666666, 68: 0.0, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 0.5, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_30  ->  0.5852713178294574
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.6, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.6666666666666666, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.6666666666666666, 12: 1.0, 13: 0.6666666666666666, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 1.0, 20: 0.0, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.5, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.0, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 1.0, 67: 0.6666666666666666, 68: 0.0, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 0.5, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_30  ->  0.5813953488372093
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.6, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.6666666666666666, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.6666666666666666, 12: 1.0, 13: 0.6666666666666666, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 1.0, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.5, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.0, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.0, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 0.5, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_31  ->  0.5813953488372093
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.6, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.6666666666666666, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.6666666666666666, 12: 1.0, 13: 0.6666666666666666, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 1.0, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.5, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 1.0, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.0, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 0.5, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_31  ->  0.5891472868217055
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.6, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.6666666666666666, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.3333333333333333, 12: 1.0, 13: 0.6666666666666666, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 1.0, 20: 0.0, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.5, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 1.0, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.0, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.0, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 0.5, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_32  ->  0.5775193798449613
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.6, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.6666666666666666, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.6666666666666666, 12: 1.0, 13: 0.6666666666666666, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 1.0, 20: 0.0, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.5, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.0, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 1.0, 67: 0.6666666666666666, 68: 0.0, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 0.5, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_32  ->  0.5813953488372093
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.6, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.6666666666666666, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.6666666666666666, 12: 1.0, 13: 0.6666666666666666, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 1.0, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 0.6666666666666666, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.5, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.0, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 1.0, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.6666666666666666, 52: 0.5, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 1.0, 67: 0.6666666666666666, 68: 0.0, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 0.5, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_33  ->  0.5891472868217055
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.6, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.6666666666666666, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.6666666666666666, 12: 1.0, 13: 0.6666666666666666, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 1.0, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.5, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 1.0, 67: 0.6666666666666666, 68: 0.0, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 0.5, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_33  ->  0.5891472868217055
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.8, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.6666666666666666, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.6666666666666666, 12: 1.0, 13: 0.6666666666666666, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 1.0, 20: 0.0, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.5, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.0, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 0.5, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_34  ->  0.5852713178294574
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.8, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.6666666666666666, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.6666666666666666, 12: 1.0, 13: 0.6666666666666666, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 1.0, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.5, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 1.0, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 1.0, 67: 0.6666666666666666, 68: 0.0, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 0.5, 78: 1.0, 79: 1.0, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_34  ->  0.6007751937984496
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.6, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.6666666666666666, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.6666666666666666, 12: 1.0, 13: 0.6666666666666666, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 1.0, 20: 0.0, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.5, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.3333333333333333, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 1.0, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.0, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 0.5, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_t_35  ->  0.5852713178294574
Label accuracies statistics:
{0: 0.75, 1: 0.5, 2: 0.6, 3: 0.25, 4: 1.0, 5: 0.6666666666666666, 6: 1.0, 7: 0.6666666666666666, 8: 1.0, 9: 0.6666666666666666, 10: 1.0, 11: 0.6666666666666666, 12: 1.0, 13: 0.6666666666666666, 14: 0.3333333333333333, 15: 0.3333333333333333, 16: 0.6666666666666666, 17: 0.3333333333333333, 18: 0.3333333333333333, 19: 1.0, 20: 0.3333333333333333, 21: 0.6666666666666666, 22: 0.6666666666666666, 23: 0.0, 24: 1.0, 25: 1.0, 26: 0.0, 27: 1.0, 28: 1.0, 29: 0.6666666666666666, 30: 0.3333333333333333, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.5, 35: 1.0, 36: 0.0, 37: 1.0, 38: 0.6666666666666666, 39: 0.5, 40: 1.0, 41: 1.0, 42: 0.6666666666666666, 43: 0.6666666666666666, 44: 0.5, 45: 1.0, 46: 0.6666666666666666, 47: 0.5, 48: 1.0, 49: 0.0, 50: 1.0, 51: 0.3333333333333333, 52: 0.5, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.3333333333333333, 57: 0.6666666666666666, 58: 1.0, 59: 1.0, 60: 1.0, 61: 0.0, 62: 1.0, 63: 1.0, 64: 0.0, 65: 0.6666666666666666, 66: 1.0, 67: 0.3333333333333333, 68: 0.0, 69: 1.0, 70: 0.5, 71: 0.3333333333333333, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.5, 76: 0.6666666666666666, 77: 0.5, 78: 1.0, 79: 0.5, 80: 0.0, 81: 0.5, 82: 1.0, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.3333333333333333, 87: 0.0, 88: 1.0, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.0}

checkpoint_v_35  ->  0.5891472868217055

The top result was recorded at 0.6007751937984496 testing accuracy. The best checkpoint is test_WLASL100_Spoter_noNorm_noAugm_mediaPipe_HandsAndPoseV3/checkpoint_v_18.
